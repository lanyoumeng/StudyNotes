

# myblog项目

## 开发启动：

air (热启动) make（自动执行）

swagger serve -F=swagger --no-open --port 65534 ./api/openapi/openapi.yaml （启动API在线文档）

用户管理： 支持 用户注册、用户登录、获取用户列表、获取用户详情、更新用户信息、修改用户密码、注销用户 7 种用户操作； 博客管理： 支持 创建博客、获取博客列表、获取博客详情、更新博客内容、删除博客、批量删除博客 6 种博客操作。

------



# 抖音项目

## 介绍

**项目介绍：**使用Kratos框架开发的微服务短视频平台，用户可通过此平台观看视频和投稿，并进行点赞和评论，关注作者并发送消息

**api文档**：https://console-docs.apipost.cn/preview/599a053c1085c274/9b93e21dcae61608

**技术栈：**Apisix，Docker，Kratos，Etcd，Kafka，Prometheus ，Grafana，Jaeger，ELK，Grpc，Redis，FFmpeg，Gorm，Oss，Jwt

**技术亮点：**

1. ELK+Kafka实现日志的收集和可视化处理
2. 使用Kafka进行流量削峰和异步处理，显著减少了响应时间
3. 利用阿里云Oss存储视频和封面，使用FFmpeg压缩视频和提取封面
4. 通过Jaeger和Prometheus对服务进行追踪监控，使用Grafana提供可视化界面
5. 使用Redis缓存信息，提高性能和响应时间。使用Flink CDC+Kafka保证Redis和Mysql的最终一致性
6. Apisix作为微服务网关，统一入口，对外提供http服务，内部使用grpc通信。基于Apisix实现负载均衡和流量控制
7. 基于Etcd作为服务的注册和发现中心，nacos作为配置中心，使用JWT验证身份、 Bcrypt加密密码、Validator验证数据合法性
8. 采用Docker Compose进行部署，简化环境变量和配置管理，提高可移植性

------



## 目录

以video为例

```
├── flink
│   ├── flink-1.18.0
│   └── job
└── video
    ├── api
    ├── cmd
    │   └── video
    ├── configs
    ├── internal
    │   ├── biz
    │   ├── conf
    │   ├── data
    │   ├── mocks
    │   │   └── mrepo
    │   ├── pkg
    │   │   ├── aliyun
    │   │   ├── errno
    │   │   ├── model
    │   │   └── vkafka
    │   ├── server
    │   └── service
    ├── pkg
    │   ├── token
    │   └── tool
    ├── store
    │   └── video
    └── third_party
```





------



## 技术选型

| 名称                                                         | 用途                                                         | 功能                                            | 端口                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |
| grpc/ kratos                                                 | 微服务服务框架                                               | ✓                                               |                                                              |
| Gorm                                                         | ORM框架                                                      | ✓                                               |                                                              |
| jwt                                                          | 鉴权                                                         | ✓                                               |                                                              |
| Mysql                                                        | 持久化数据库                                                 | ✓                                               |                                                              |
| Redis                                                        | 缓存                                                         | ✓                                               |                                                              |
| Fink cdc                                                     | mysql-redis同步                                              | ✓                                               | 控制面板：8081                                               |
| oss                                                          | 存储                                                         | ✓                                               |                                                              |
| kafka                                                        | 消息队列                                                     | 日志收集✓ 、    发布视频异步✓、评论异步消息异步 | kafdrop(9000:9000)×                                          |
| etcd                                                         | 服务注册中心                                                 | ✓                                               | etcd集群分开部署                                             |
| nacos                                                        | 配置中心                                                     | ✓                                               | http://localhost:8848/nacos 初始账号密码为 nacos/nacos Data Id 必须加.yaml user.yaml |
| swagger                                                      | API文档                                                      |                                                 |                                                              |
| FFmpeg                                                       | 视频压缩、裁剪视频封面                                       | ✓                                               |                                                              |
| APISIX(UI： [Dashboard](https://apisix.apache.org/zh/docs/dashboard/USER_GUIDE/)) | API 网关，专门用于对 API 流量进行管理、路由和流量控制 API 的动态路由、限流、鉴权、监控 | ✓                                               | 9091被Prometheus采集 <br />dashboard （3001:3001）           |
| Prometheus ，grafana                                         | 监控和可观测性软件工具：Prometheus收集系统的性能指标， 然后Grafana创建仪表板进行可视化展示， | ✓                                               | "9090:9090" <br />3000:3000                                  |
| Jaeger                                                       | Tracing链路追踪工具                                          | ✓                                               | ui:16686                                                     |
| Elasticsearch(UI:elastic), Logstash, Kibana                  | Logging日志收集和可视化工具                                  | ✓                                               | ui:5601                                                      |
| docker-compose                                               | 部署                                                         | ✓                                               |                                                              |
|                                                              |                                                              |                                                 |                                                              |
| K8s                                                          | 部署                                                         |                                                 |                                                              |
| CI/CD                                                        | github-action                                                |                                                 |                                                              |



------



## 数据库设计

通过索引加快访问速度

![image-20240906231045066](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409062310409.png)

------



## 缓存

读：

先从redis读，没有去mysql去取，读取到的数据写入redis+过期时间，否则，从redis返回

写：

使用flinkcdc+分布式锁解决一致性问题

mysql-->flink cdc-->kafka-->订阅处理redis



### 缓存设计

| 服务                               | 数据信息                                                    | 数据类型                | **key**                               | **value**                                                    | 创建时机 | 更新（刷新过期时间）                                         | 删除                           |
| ---------------------------------- | ----------------------------------------------------------- | ----------------------- | ------------------------------------- | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ | ------------------------------ |
| user                               | count <br />较频繁，可以不设置过期时间，或加锁              | hash无对应mysql表       | count::user_id                        | count 计数信息                                               | 查询为空 | 其他服务更新<br />1.视频发布2.点赞<br />3.关注               | 1.过期时间                     |
|                                    | user                                                        | hash                    | user::user_id                         | user信息                                                     | 查询为空 |                                                              | 1.过期时间2.mysql表更新/删除   |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
|                                    | video_info<br />视频获赞数和跟随数是rpc调用的               | hash                    | videoInfo::video_id                   | video_info 静态信息type Video struct {    Id       int64     AuthorId int64     Title    string     PlayUrl  string     CoverUrl string } | 查询为空 |                                                              | 1.过期时间2.video表更新/删除   |
| video                              | 系统发布的所有视频 id 用于视频流                            | zset<br />无对应mysql表 | videoAll                              | score: video发布时间戳  <br /> float64 <br />member: video_id |          | 不过期，发布视频时插入                                       | 项目不涉及删除视频             |
|                                    | 用户发布视频的 id <br />用于发布列表                        | set<br />无对应mysql表  | publishVids::user_id                  | video_ids                                                    | 查询为空 | video表创建一条记录：<br />添加对应key-member  video表不会更新<br /> video表删除一条记录：<br />移除对应key-member | 1.过期时间                     |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
|                                    | 1.一条点赞信息                                              | string无对应mysql表     | `fav::<videoId>::<userId>`            | true/false                                                   | 查询为空 | favorite表创建/更新记录，操作为：<br />点赞：变为true取消点赞：变为false | 1.过期时间2.favorite表删除记录 |
| **favor**                          | 2.用户点赞视频列表<br />size=用户的点赞数量                 | set<br />无对应mysql表  | `userFavList::<userId>`               | video_id                                                     | 查询为空 | favorite表创建/更新记录，操作为： <br />点赞操作 -->cnt+1<br />取消点赞-->cnt-1 <br />favorite表删除记录,点赞为true-->cnt-1 | 1.过期时间                     |
| 较频繁，可以不设置过期时间，或加锁 | 3.视频的获赞数                                              | string无对应mysql表     | `videoFavCnt::<videoId>`              | int64                                                        | 查询为空 | 点赞操作 -->cnt+1<br />取消点赞-->cnt-1 <br />favorite表删除记录,点赞为true-->cnt-1 | 1.过期时间                     |
|                                    | 4.视频作者的获赞数TotalFavorited                            | string无对应mysql表     | userTotalFavorited::authorId          | int64                                                        | 查询为空 | 点赞操作 -->cnt+1<br />取消点赞-->cnt-1 <br />favorite表删除记录,点赞为true-->cnt-1 | 1.过期时间                     |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
| **comment**                        | 评论用户                                                    | zset                    | comment::video_id                     | score: 评论发布时间戳 member: 序列化为json（字符串的话，分隔符会和content冲突）<br />Id        <br />UserId   <br />Content  <br />CreateDate | 查询为空 | comment表创建一条记录：添加对应comment--member  <br />comment表不会更新 <br />comment表删除一条记录：移除对应comment--member | 1.过期时间                     |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
|                                    | 关注用户的id                                                | set                     | follow::user_id                       | 关注用户的ids                                                | 查询为空 | relation表创建一条记录：添加对应key-member  relation表不会更新 relation表删除一条记录：移除对应key-member | 1.过期时间                     |
| relation                           | 粉丝的id                                                    | set                     | follower::user_id                     | 粉丝的ids                                                    | 查询为空 |                                                              | 1.过期时间                     |
|                                    | 好友的id <br />通过求关注和粉丝的交集可以得到，不用特地缓存 |                         |                                       |                                                              |          |                                                              |                                |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
| message                            | 历史消息                                                    | zset                    | message::history::小user_id+大user_id | score: 消息发布时间戳 member: 序列化为json：user_id<br />target_id<br />content | 查询为空 | message表创建一条记录：添加对应key-member  message表不会更新 messaget表删除一条记录：移除对应key-member | 1.过期时间                     |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |
|                                    |                                                             |                         |                                       |                                                              |          |                                                              |                                |



//Zset 只存储视频 ID 和时间戳，假如value过大怎么解决

将大 Zset 拆分为多个小 Zset，根据视频发布的时间进行分片存储。例如，可以按天、周、月或其他时间周期进行分片。



### 分布式锁

对favorite redis添加了etcd分布式锁，防止缓存击穿

在internal/pkg/favkafka/redis.go

------



## 消息队列



| 服务模块 | 用途                       |
| -------- | -------------------------- |
| video    | 异步上传视频，缩短响应时间 |



### topic

一共有3类topic

1.日志

2.redis-mysql同步

3.video服务的视频异步发布





------



## 中间件

### nacos

![image-20240911001341069](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409110013468.png)

### ELK

- 通过logstash收集和聚合微服务的日志数据传输给kafka

![image-20240906232118199](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409062321544.png)



### APISIX

前端app设计问题，post的请求参数都是放到url中，为了使grpc-transcode插件生效，apisix把post请求转为get请求

![image-20240909183210039](C:\Users\20588\AppData\Roaming\Typora\typora-user-images\image-20240909183210039.png)

![image-20240911101708631](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409111017965.png)

### jaeger

![image-20240911000922121](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409110009524.png)



### promethus

![image-20240911001136346](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409110011703.png)

### grafana

![image-20240911002233041](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409110022389.png)

### flinkcdc

单独部署，有6个服务对应的缓存同步任务

![image-20240911001317344](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409110013702.png)

### oss

![image-20240911101309101](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409111013499.png)

## 服务

基于Etcd作为服务的注册和发现中心，nacos作为配置中心，

rpc内部使用rpc调用获取相关信息



### User

1. 使用JWT验证身份、 Bcrypt加密密码、Validator验证数据合法性



- 因为创建和登录用户时，userId是没有的，所以都是用username查询  加索引

- is_follow  在video服务查找  user服务不提供

### video

#### 发布

1. 通过kafka异步发布视频，减少响应时间
2. filetype库校验文件类型，使用ffmpeg进行视频压缩和封面提取
3. 阿里云OSS存储视频和封面

#### 视频流

1. 使用zset存储视频id，方便根据时间获取视频信息
2. sync.Map+errgroup.WithContext(ctx) 利用协程并发组装视频流



### favorite

#### 点赞

1. 对缓存添加了etcd 分布式锁，防止缓存击穿

2. action_type

   1-点赞，2-取消点赞



### comment

1. action_type

   1-发布评论，2-删除评论



### relation

1. action_type

   1-关注，2-取消关注

2. 获取关注列表
   获取关注用户的ids 然后rpc获取用户信息
   再获取每个用户的is_follow字段 即登录用户是否关注了该用户

3. 获取好友列表
   好友列表，关注和粉丝的交集

   

### message

1. 前端是轮询获得消息
2. 时间顺序获取消息记录
3. 

------




## app

使用前端提供的app

app bug：

1. Avatar用户头像和BackgroundImage 用户个人页顶部大图默认
2. 视频流刷新不及时
3. 前端请求头 (Headers)没有   Authorization：Bearer eyJhbG.......
   token是直接放到url中的
   不安全且导致kratos的jwt中间件不能用

------



## 测试

### 单元测试

1.自动生成mock

```go
//go:generate mockgen -destination=../mocks/mrepo/video.go -package=mrepo . VideoRepo
```

### 性能测试

![image-20240911163639101](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409111636478.png)

------

## 项目启动

1. 配置nacos、APISIX、OSS秘钥、flinkcdc
2. docker-compose up -d

```bash
mysql开启binlog
--log-bin=mysql-bin
--binlog-format=ROW
--server-id=1


./bin/stop-cluster.sh
./bin/start-cluster.sh
export FLINK_HOME=/home/lanmengyou/code/go_code/TikTok/flink/flink-1.18.0


bin/flink-cdc.sh job/user-mysql-to-kafka.yaml
bin/flink-cdc.sh job/video-mysql-to-kafka.yaml
bin/flink-cdc.sh job/favorite-mysql-to-kafka.yaml
bin/flink-cdc.sh job/comment-mysql-to-kafka.yaml
bin/flink-cdc.sh job/relation-mysql-to-kafka.yaml
bin/flink-cdc.sh job/message-mysql-to-kafka.yaml

docker exec -it kafka  kafka-console-consumer.sh --topic flink-user2 --bootstrap-server localhost:9092 --from-beginning

docker-compose up -d --build --no-deps message user video favorite comment relation.


kubectl port-forward --address=0.0.0.0
#要访问在 WSL2 中运行的 Kubernetes 服务，您可以使用 kubectl port-forward 命令。 默认情况下，kubectl port-forward 仅监听 127.0.0.1（即本地主机）。 如果您希望从其他主机访问该服务，需要将监听地址设置为 0.0.0.0：
kubectl port-forward --address 0.0.0.0 <资源类型>/<资源名称> <本地端口>:<目标端口>

kubectl port-forward --address 0.0.0.0 pod/nginx 8080:80
kubectl port-forward --address 0.0.0.0 service/nacos 8848:8848 
kubectl port-forward --address 0.0.0.0 service/user 30000:30000 
kubectl port-forward --address 0.0.0.0 pod/user-68bf584b67-rczbj 8001:8001 

# 如果无法访问 charts.kubesphere.io, 可将 charts.kubesphere.io 替换为 charts.kubesphere.com.cn
helm upgrade --install -n kubesphere-system --create-namespace ks-core ./ks-core-1.1.3.tgz --debug --wait
 kubectl get pods -n kubesphere-system
#转发集群pod内部端口
kubectl port-forward -n kubesphere-system ks-console-f8b5c9f97-l9n7j 8099:8000

#查看日志
kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l 'app in (ks-install, ks-installer)' -o jsonpath='{.items[0].metadata.name}') -f

docker build -t lanmengyou/tiktok-user:v1.0.0 .
docker build -t lanmengyou/tiktok-video:v1.0.0 .
docker build -t lanmengyou/tiktok-favorite:v1.0.0 .
docker build -t lanmengyou/tiktok-comment:v1.0.0 .
docker build -t lanmengyou/tiktok-relation:v1.0.0 .
docker build -t lanmengyou/tiktok-message:v1.0.0 .

docker push lanmengyou/tiktok-user:v1.0.0
docker push lanmengyou/tiktok-video:v1.0.0
docker push lanmengyou/tiktok-favorite:v1.0.0
docker push lanmengyou/tiktok-comment:v1.0.0
docker push lanmengyou/tiktok-relation:v1.0.0
docker push lanmengyou/tiktok-message:v1.0.0


helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update
helm install kafka bitnami/kafka \
  --set replicaCount=3 \
  --set persistence.enabled=true \
  --set persistence.size=8Gi \
  --set externalAccess.enabled=true \
  --set externalAccess.service.type=NodePort



```





## 遇到问题

1. nacos会在本地生成缓存，没有读取到时从本地读取

2. 前端app访问需要关闭防火墙

3. 异步写入kafka时，ctx不要用上层传入的，  因为上层直接结束了，ctx相当于到期了

   重新context.Background()

   

4. 视频投稿接口的post的body是multipart/form-data类型，  而 gRPC 的 `protobuf` 不支持直接处理这种格式。生成的video_http.pb.go文件中的对应函数是不能用的，要进行修改

5. 

6. UserInfo (UserId,Token)

    //这里app前端返回的req.UserId 是0，需要使用用token解析出来的userId
   //但是微服务通信时使用 userId

7. 

   ```
   func _VideoService_Publish0_HTTP_Handler(srv VideoServiceHTTPServer) func(ctx http.Context) error {
   	return func(ctx http.Context) error {
   		// 解析 multipart/form-data 请求
   		if err := ctx.Request().ParseMultipartForm(32 << 20); err != nil {
   			return err
   		}
   
   		// 处理文件字段
   		file, _, err := ctx.Request().FormFile("data")
   		if err != nil {
   			return err
   		}
   		defer file.Close()
   
   		fileBytes, err := ioutil.ReadAll(file)
   		if err != nil {
   			return err
   		}
   
   		// 获取其他字段
   		token := ctx.Request().FormValue("token")
   		title := ctx.Request().FormValue("title")
   
   		// 创建 gRPC 请求对象
   		in := &DouyinPublishActionRequest{
   			Data: fileBytes,
   			Token:    token,
   			Title:    title,
   		}
   
   		http.SetOperation(ctx, OperationVideoServicePublish)
   		h := ctx.Middleware(func(ctx context.Context, req interface{}) (interface{}, error) {
   			return srv.Publish(ctx, req.(*DouyinPublishActionRequest))
   		})
   		out, err := h(ctx, in)
   		if err != nil {
   			return err
   		}
   		reply := out.(*DouyinPublishActionResponse)
   		return ctx.Result(200, reply)
   	}
   }
   ```

   

8. rdb和rpc调用时，若用上层的ctx会超时，用context.Background()

   comment（data/comment.go:102）调用relationrpc调用很慢，20s

9. ```
   //FollowCount  FollowerCnt
   go func() {
       defer wg.Done()
       followCntRes, err := r.data.relationc.FollowCnt(context.Background(), &relationV1.FollowCntRequest{UserId: id})
       if err != nil {
          r.log.Errorf("data.GetCountById/FollowCnt-err:%v\n", err)
          return
       }
       count.FollowCount = followCntRes.FollowCnt
       count.FollowerCount = followCntRes.FollowerCnt
   }()
   ```

## 待做

1. 限流，apisix+kratos

2. CI/CD

3. 分布式事务

4. 读写分离

5. message的缓存还没加上

6. nacos     

   ```
    NamespaceId:         "", ////当namespace是public时，此处填空字符串。
   ```

7. 

| 服务模块  | 用途                           |      |
| :-------- | :----------------------------- | ---- |
| video     | 异步上传视频，缩短响应时间     | ✓    |
| sociality | 异步执行社交操作，缩短响应时间 |      |
| chat      | 异步发送聊天消息，缩短响应时间 |      |





------



# 实习项目

课题任务一:Envoy + Wasm 使用Go为Envoy开发wasm插件 插件一：json-valitor插件 插件二：coraza-waf防火墙插件

需要具备Envoy、WebAssembly、Go等技术

课题任务二:Kubernetes + Wasm 在Kubernetes 平台上使用KWasm Operator构建Wasm运行时，运行一个rust写的的LLM推理Wasm应用 需要具备Kubernetes、WebAsseembly、wasm运行时、Containered等技术

wasm 对应是linux或windows wasm不支持gc，go支持不好 WASI NN 规范定义了 Wasm 运行时应如何与本机 AI/ML 库（例如 PyTorch 和 TensorFlow）交互，以使用 Rust 等高性能语言进行 AI 推理

## 课题一 k8s+wasm

### 项目1.1 LLM推理应用

1个nginx容器 提供前端页面

一个wasm容器，两种 ---编译的llama-go 或者 调用chatgpt-api（或者没有前端页面，而是通过cli命令行，使用**-it** 打开一个交互命令行）

LLM模型部署在docker中

写一个AI对话助手，可以在浏览器中访问。

前端页面使用nginx部署，后端编译为wasm



参考项目：

1. [ChatGPTNextWeb](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/tree/main)
2. [langchain ai 构建上下文感知推理应用程序](https://github.com/langchain-ai/langchain) [Ollama ](https://ollama.com/)[用 Ollama 轻松玩转本地大模型 - 少数派 (sspai.com)](https://sspai.com/post/85193)

[LinGoose----Go框架](https://github.com/henomis/lingoose)

1. llama2-go 调用本地llama2模型
2. 将llama2.go编译为wasm，在 WasmEdge 里运行llama 2 LLM
3. [llama2.go](https://github.com/nikolaydubina/llama2.go) 。只用纯go语言就能推理 llama 2 模型的框架，没有任何繁杂的 python 依赖。
4. [go-openai](https://github.com/sashabaranov/go-openai) ------调用的openai 代码已有 需要有代理服务器
5. 调用文心一言的接口 代码已有



**如何使k8s支持wasm** 底层是[runwasi ](https://github.com/containerd/runwasi)注意docker-desktop使用的是

[WebAssembly 在云原生中的实践指南](https://xie.infoq.cn/article/fb0e0ad0d75dd573aef3eb545?utm_source=related_read&utm_medium=article)

1. Kubernetes + Containerd + Crun linux启动sudo containerd
2. KWasm Operator 是一种用于自动化应用程序的运维任务的自定义控制器，将人类操作员的知识和经验转化为自动化的代码。

```Bash
 GOOS=wasip1 GOARCH=wasm go build -o main.wasm main.go
#tinygo build -o main.wasm -target wasm ./main.go  注意是wasi不是wasm
 tinygo build -o main.wasm -target=wasi main.go
wasmedge --dir .:. --nn-preload default:GGML:AUTO:stories110M.bin  main.wasm --prompt-template llama-2-chat
wasmedge --dir .:. --nn-preload default:GGML:AUTO:stories110M.bin
#构建wasm镜像
docker buildx build --platform wasi/wasm -t llama2-go:v1 .  

#上传
 #首先，确保你已经登录到 Docker Hub 或者其他镜像仓库。你可以使用以下命令登录：
    docker login registry-1-stage.docker.io
#然后，使用 `docker tag` 命令给你本地构建好的镜像打上正确的标签，以便上传到目标仓库：
   docker tag wasm-edge-hello:v1  registry-1-stage.docker.io/lanmengyou/wasm_edge-hello:latest

   docker push registry-1-stage.docker.io/lanmengyou/wasm_edge-hello:latest


#创建集群
kind create cluster --config kind/cluster.yaml
#下载helm
scoop install helm   （windows）

wget https://get.helm.sh/helm-v3.14.1-linux-amd64.tar.gz
tar -xvzf   helm-v3.14.1-linux-amd64.tar.gz
mv linux-amd64/helm /usr/local/bin/helm
# Add helm repo
helm repo add kwasm http://kwasm.sh/kwasm-operator/
# Install operator
helm install -n kwasm --create-namespace kwasm-operator kwasm/kwasm-operator
# Annotate single node  添加注释
kubectl annotate node docker-desktop kwasm.sh/kwasm-node=true
# Run example
kubectl apply -f  kind/runtimeclass.yaml
kubectl apply -f  kind/pod.yaml  #运行时需要指定RuntimeClass

kubectl apply -f  pod.yaml  kubectl port-forward pod/wasm-edge-hello-pod 8080:8080 输出hello world

kubectl logs wasi-demo
kubectl describe pod wasm-edge-hello-pod 
```

1. Krustlet
2. [deisplates/containerd-wasm垫片：用于在Kubernetes中运行WebAssembly工作负载的containerd垫片](https://github.com/deislabs/containerd-wasm-shims/tree/main) 使用这个支持wasmedge
3. [wasmedge-containers-examples](https://github.com/second-state/wasmedge-containers-examples/)

![img](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/typora/202407090024056.png?token=AWX6LWTXLOCDKVC3YP5B24DGRQJRM)

- **模型是如何打包的**。一个典型的模型由原始模型资产和一堆代码依赖组成。比如：通过将模型 + 依赖项打包到 Docker 容器中来进行工作。 Docker 是将软件打包、分发和部署到现代基础设施的行业标准方式。
- **模型运行的地方**。一些服务框架只是为您提供了一个 Docker 容器，您可以在任何支持 Docker 的地方运行该容器。而一些服务框架则建立在 Kubernetes 之上，通过 Kubernetes 进行自动化部署、扩展和管理容器。

## **课题二** Envoy+wasm

### 项目2.1 验证插件

```Bash
tinygo build -o main.wasm -scheduler=none -target=wasi main.go

#启动命令
docker run --rm -p 8089:8089 -p 8099:8099 -p 8001:8001  -v $PWD/envoy.yaml:/envoy.yaml  -v $PWD/main.wasm:/main.wasm  --entrypoint envoy containers.istio.tetratelabs.com/proxyv2:1.9.7-tetrate-v0      -c /envoy.yaml  

Invoke-WebRequest -Uri http://localhost:18000 -Method POST -Headers @{ "content-type" = "application/json" }

Invoke-WebRequest -Uri http://localhost:18000 -Method POST -Headers @{ "Content-Type" = "application/json" } -Body '{"id": "xxx", "token": "xxx", "anotherField": "yyy"}'
```

定期调度 HTTP 调用 定期调用名为“compress”的外部函数 定期记录当前时间（以纳秒为单位） helloworld 来自 http://httpbin.org/uuid 的响应的哈希值对请求进行授权。 对请求或响应正文（如 append/prepend/replace）执行操作

使用 Go 和 `proxy-wasm-go-sdk` 编写一个 WebAssembly（Wasm）插件，以及如何将其集成到 Envoy 中。这个插件的功能是验证传入请求的 JSON 负载，并确保其中包含必要的键。

构建和运行一个 Wasm 插件，验证请求 body 是 JSON，并包含两个必要的键 ——`id` 和 `token`。

```Go
        // 验证请求体
        if !gjson.ValidBytes(body) {
                proxywasm.LogErrorf("body is not a valid json %v", string(body))
                return types.ActionPause
        }
        //解析json
        jsonData := gjson.ParseBytes(body)

        for _, requiredKey := range this.requiredKeys {
                if !jsonData.Get(requiredKey).Exists() {
                        proxywasm.LogErrorf("required key (%v) is missing: %v", requiredKey, jsonData)
                        return types.ActionPause
                }
        }

        // 通过 header 获取request path
const (
        // 注意 proxywasm 获取 请求路径的方式
        HttpPath = ":path"
)

        hp, err := proxywasm.GetHttpRequestHeader(HttpPath)
        if err != nil {
                proxywasm.LogErrorf("get http path error: %s", err.Error())
        }
        urlParser, err := url.Parse(hp)
        if err != nil {
                proxywasm.LogError(err.Error())

        }
        // 打印请求路径 以及参数
        proxywasm.LogInfof("uri = %s", urlParser.Path)
        proxywasm.LogInfof("host = %s", urlParser.Host)
        proxywasm.LogInfof("params = %s", urlParser.RawQuery)

        //通过参数获取用户 以及判断用户是否为admin
        if user := urlParser.Query().Get("user"); user != "admin" {
                _ = proxywasm.SendHttpResponse(401,
                        [][2]string{
                                {"content-type", "application/json; charset=utf-8"},
                        },
                        []byte("用户没有权限或缺少参数"),
                        -1)
                // 表示不可继续
                return types.ActionPause
        }
```

### 项目2.2防火墙插件

//waf 外部防火墙插件 对请求进行设置，符合规则才进行 比如ip

jwps 从本地或远程获取秘钥配置

使用wasm应用调用外部服务，校验token jwt

#### 构建

```Bash
source ~/.bashrc

#  go run mage.go build
tinygo build -gc=custom -opt=2 -o build/mainraw.wasm -scheduler=none -target=wasi -tags='custommalloc nottinygc_envoy no_fs_access memoize_builders coraza.rule.multiphase_evaluation'

SecDefaultAction: 设置默认的 ModSecurity 行为，包括阶段（phase）和日志记录。
SecDebugLogLevel 3: 设置调试日志级别为 3。
Include @owasp_crs/*.conf: 引入了一组由 OWASP 提供的规则，这些规则通常涵盖了常见的 Web 应用程序安全问题。
SecRule REQUEST_URI "@streq /admin" ...: 针对请求 URI 的规则，如果请求 URI 与 "/admin" 相等，则执行阻止操作。
SecRule REQUEST_BODY "@rx maliciouspayload" ...: 针对请求体的规则，如果请求体匹配正则表达式 "maliciouspayload"，则执行阻止操作。
SecRule RESPONSE_HEADERS::status "@rx 406" ...: 针对响应状态码的规则，如果响应状态码匹配正则表达式 "406"，则执行阻止操作。
SecRule RESPONSE_BODY "@contains responsebodycode" ...: 针对响应体的规则，如果响应体包含字符串 "responsebodycode"，则执行阻止操作。
```

#### 问题

```Plaintext
为什么通过authority 获取waf
```

#### 目标

```Plaintext
负载均衡 - 令牌桶:

负载均衡： 分配传入的网络或应用程序请求到多个后端服务器，以确保更好的性能、可用性和可伸缩性。
令牌桶算法： 一种用于限制访问速率的算法，通过在令牌桶中放入令牌，请求只有在获取令牌的情况下才能被处理，有助于防止过载。
安全性检查 - WAF（Web Application Firewall）:

安全性检查： 通过检查和验证系统、网络或应用程序中的数据、交互或配置，以确保其满足安全标准。
WAF： 一种安全工具，位于网络和应用程序之间，用于检测和阻止针对 Web 应用程序的攻击，如SQL注入、跨站脚本攻击等。
超时控制:

超时控制： 设置在系统中操作或事件完成之前的最大等待时间，以防止无限期地等待某些事件的完成。
认证:

认证： 确认用户、系统或实体的身份，以确保访问权限和数据的安全性。
常见的认证方法包括用户名密码认证、令牌认证、OAuth认证等。
日志插件:

日志插件： 用于捕获和记录系统、应用程序或服务的事件、错误、警告等信息的插件。
可用于故障排除、监控、审计等目的。
统计和监控插件:

统计和监控： 收集和分析系统的性能数据、资源利用率等信息，以便了解系统的运行状况。
插件： 可以是用于扩展和定制监控系统的模块，以满足特定需求。
```

#### Transaction

coraza.types.Transaction

这段代码是Go语言的源代码，定义了一个名为Transaction的接口。该接口包含了处理Web请求和响应的方法，以及与WAF（Web Application Firewall）相关的配置信息。以下是对该接口的主要方法的简要描述：

1. **ProcessConnection**: 在请求处理的开始阶段调用，用于处理连接信息。
2. **ProcessURI**: 对URI和查询字符串进行分析的方法，应在请求处理的开始阶段调用。
3. **SetServerName**: 设置服务器名称的方法，用于在执行ProcessRequestHeaders之前检查SERVER_NAME变量。
4. **AddRequestHeader**: 添加请求头的方法。
5. **ProcessRequestHeaders**: 对请求头进行分析的方法，需要在执行前添加请求头。
6. **RequestBodyReader**: 返回一个用于读取已由请求体缓冲区写入的内容的io.Reader。
7. **AddGetRequestArgument**: 添加GET请求参数的方法。
8. **AddPostRequestArgument**: 添加POST请求参数的方法。
9. **AddPathRequestArgument**: 添加PATH请求参数的方法。
10. **AddResponseArgument**: 添加响应参数的方法。
11. **ProcessRequestBody**: 对请求体进行分析的方法，是可选的。
12. **WriteRequestBody**: 尝试将数据写入请求体，如果请求体超过限制并且动作是拒绝，则返回中断。
13. **ReadRequestBodyFrom**: 尝试从io.Reader中写入数据到请求体，如果请求体超过限制并且动作是拒绝，则返回中断。
14. **AddResponseHeader**: 添加响应头的方法。
15. **ProcessResponseHeaders**: 对响应头进行分析的方法，需要在执行前添加响应头。
16. **ResponseBodyReader**: 返回一个用于读取已由响应体缓冲区写入的内容的io.Reader。
17. **ProcessResponseBody**: 对响应体进行分析的方法，是可选的。
18. **WriteResponseBody**: 尝试将数据写入响应体，如果响应体超过限制并且动作是拒绝，则返回中断。
19. **ReadResponseBodyFrom**: 尝试从io.Reader中写入数据到响应体，如果响应体超过限制并且动作是拒绝，则返回中断。
20. **ProcessLogging**: 记录与该事务相关的所有信息。
21. **IsRuleEngineOff**: 如果RuleEngine设置为Off，则返回true。
22. **IsRequestBodyAccessible**: 如果已通过RequestBodyAccess启用了RequestBody访问，则返回true。
23. **IsResponseBodyAccessible**: 如果已通过ResponseBodyAccess启用了ResponseBody访问，则返回true。
24. **IsResponseBodyProcessable**: 如果响应体满足处理的条件，则返回true。
25. **IsInterrupted**: 如果事务被中断，则返回true。
26. **Interruption**: 返回Interruption类型，如果请求被中断，则返回nil。
27. **MatchedRules**: 返回匹配请求的规则及相关信息的列表。
28. **DebugLogger**: 返回用于此事务的调试记录器。
29. **ID**: 返回事务的ID。
30. **Closer**: 关闭事务并释放与之关联的任何资源，如请求/响应体。

这个接口主要用于WAF实例处理Web请求和响应，以及执行规则引擎来检查和干预请求和响应的过程。

#### proxywasm.hostcall

这个Go语言编写的Proxy-Wasm SDK提供了一套函数和接口，使得在WASM环境中构建代理程序变得更容易。以下是对SDK中主要功能和接口的详细分析：

1. **配置信息获取：**
2. `GetVMConfiguration`和`GetPluginConfiguration`用于获取代理的配置信息。`GetVMConfiguration`在VM启动时调用，而`GetPluginConfiguration`在插件启动时调用。这使得在代理启动时能够获取必要的配置信息。
3. **定时调用周期设置：**
4. `SetTickPeriodMilliSeconds`用于设置定时调用的周期，这对于执行周期性任务非常有用。这个周期性任务是在`types.PluginContext.OnTick`中执行的。
5. **共享队列处理：**
6. `RegisterSharedQueue`用于注册共享队列，这样当队列中有新项时，将调用`types.PluginContext.OnQueueReady`。这提供了一种跨多个WASM VM实例共享数据的方式。
7. **HTTP调用处理：**
8. `DispatchHttpCall`允许代理将HTTP调用分派到远程集群，并在调用完成时调用回调函数处理响应。这对于执行异步HTTP调用非常有用，例如在处理请求时调用外部服务。
9. **HTTP请求和响应处理：**
10. 一系列函数用于在HTTP请求和响应的各个阶段操作头部、主体和尾部。这些函数提供了在HTTP处理期间修改请求和响应的能力，以及访问它们的信息。
11. **TCP流处理：**
12. 提供了一组函数用于处理TCP流的下游数据、上游数据，以及控制TCP流的继续或关闭。这对于以流的形式处理TCP连接非常有用，例如在代理中实现自定义TCP层逻辑。
13. **共享数据存储：**
14. `GetSharedData`和`SetSharedData`允许代理获取和设置共享数据。共享数据可以在不同的WASM VM实例之间进行共享，这为跨多个实例之间共享状态提供了一种机制。
15. **HTTP响应发送：**
16. `SendHttpResponse`允许代理发送HTTP响应到下游。这在代理需要直接构造和发送响应时非常有用，例如在处理某些特殊情况时。
17. **GetProperty 和 GetPropertyMap:**
18. `GetProperty` 用于从主机获取给定路径下的属性或元数据的原始字节。
19. `GetPropertyMap` 与 `GetProperty` 类似，但用于解码映射类型的属性。这个函数期望路径指向一个映射类型的属性，并返回解码后的键值对数组。
20. **SetProperty:**
21. `SetProperty` 用于设置给定路径下的属性或元数据。它允许在WASM插件中修改主机的属性，例如在Envoy中更改特定的元数据。
22. **CallForeignFunction:**
23. `CallForeignFunction` 用于调用主机实现的外部函数。这允许WASM插件与主机进行更底层的交互。函数接受一个函数名和参数，返回调用结果。
24. **日志记录函数:**
25. 提供了一系列不同日志级别的函数，例如 `LogTrace`, `LogDebug`, `LogInfo`, `LogWarn`, `LogError`, `LogCritical`，以及对应的格式化版本。这些函数用于在WASM插件中生成日志，帮助调试和记录信息。
26. **Metric 相关函数:**
27. 提供了定义和操作计数器、计量器和直方图类型的度量指标的函数。这些函数用于在WASM插件中收集和报告性能度量信息。
28. **Map 操作函数:**
29. 提供了一组用于操作Header Map的函数，包括设置、获取、删除和替换键值对。Header Map用于在HTTP请求和响应之间传递元数据。
30. **Buffer 操作函数:**
31. 提供了一组用于处理缓冲区的函数，包括获取、追加、替换和预置缓冲区数据。这对于处理HTTP请求和响应的数据流非常有用。
32. 

#### coraza-wasilibs

在Go应用程序的源代码中注册插件，然后在适当的地方调用插件提供的功能。下面是使用的一般步骤：

1. **导入插件包：** 在Go应用程序的源代码中，首先导入Coraza WASI插件包。根据你的代码，导入的路径可能类似于：

```Go
import "github.com/corazawaf/coraza-wasilibs"
```

1. **注册插件：** 在程序的初始化过程中，通常在 `init` 函数中，调用插件包提供的 `Register` 函数或其他 `RegisterX` 函数来注册插件。这是为了确保在应用程序的生命周期内插件被正确初始化和准备就绪。

```Go
func init() {
    wasilibs.Register()
}
```

1. 或者，如果你想单独注册特定的插件，可以使用类似下面的方式：

```Go
func init() {
    wasilibs.RegisterPM()
    wasilibs.RegisterRX()
    wasilibs.RegisterSQLi()
    wasilibs.RegisterXSS()
}
```

1. **使用插件：** 一旦插件被注册，你可以在你的应用程序的其他地方调用插件提供的功能。这可能包括检测请求中的安全威胁、记录日志、拦截恶意行为等。具体的使用方式取决于插件的功能和你的应用程序需求。

```Go
// 例如，在请求处理的地方调用插件来检测 SQL 注入
func handleRequest(query string) {
    isSQLiDetected := wasilibs.SQLiOperator.Check(query)
    if isSQLiDetected {
        // 处理 SQL 注入
        // ...
    } else {
        // 处理正常请求
        // ...
    }
}
```

总体而言，使用Coraza WASI插件主要涉及在Go应用程序中导入、注册并调用插件的功能。这与命令行的使用方式不同，因为它是在应用程序代码中嵌入并以程序化的方式使用插件。

#### 规则

ModSecurity SecLang 规则集

**可以根据你的具体需求和应用程序的特性来自定义规则，也可以使用 OWASP CRS 的规则，或者两者结合使用**

在 ModSecurity 中，常见的字符串比较运算符用于规则中的条件匹配。以下是一些常见的字符串比较运算符：

1. `@streq`：精确字符串匹配，判断两个字符串是否完全相等。
2. 示例：`SecRule REQUEST_URI "@streq /admin" "deny"`
3. `@contains`：检查字符串是否包含指定的子字符串。
4. 示例：`SecRule ARGS "@contains login" "deny"`
5. `@beginsWith`：检查字符串是否以指定的前缀开始。
6. 示例：`SecRule REQUEST_URI "@beginsWith /public" "allow"`
7. `@endsWith`：检查字符串是否以指定的后缀结束。
8. 示例：`SecRule ARGS "@endsWith .pdf" "deny"`
9. `@rx`：使用正则表达式进行匹配。
10. 示例：`SecRule ARGS "@rx ^[0-9]{5}$" "allow"`

这些运算符使得规则可以根据请求中的内容、参数、URI 等进行灵活的字符串匹配，从而执行相应的安全策略。在 ModSecurity 的规则中，这些字符串比较运算符可以结合各种条件和操作执行阻止、允许、日志记录等操作。

#### 作用

Web应用程序防火墙（WAF）引擎通常设计用于以下目的：

1. **攻击检测：** WAF 引擎可以检测和识别各种Web攻击，如SQL注入、跨站脚本（XSS）、跨站请求伪造（CSRF）等。
2. **规则引擎：** 提供一个规则引擎，允许管理员定义和配置规则，以根据特定的攻击模式或行为来检测和阻止流量。
3. **实时日志记录：** 记录攻击尝试和其他安全事件，使管理员能够分析和响应这些事件。
4. **黑白名单支持：** 允许管理员配置黑名单规则（拒绝规则）和白名单规则（允许规则），以更灵活地控制 WAF 的行为。
5. **HTTP解码和编码：** 支持对HTTP请求和响应进行解码和编码，以防范基于编码的攻击。
6. **SSL支持：** 支持通过SSL/TLS加密的HTTPS连接，以保护传输中的数据。
7. **自定义脚本支持：** 提供扩展性，允许管理员使用自定义脚本扩展和定制 WAF 的功能，以适应特定环境的需求。

## WasmEdge-go库

WasmEdge-go 是一个用于在 Go 语言中与 WasmEdge 交互的库。WasmEdge 是一个 WebAssembly (Wasm) 执行引擎，它专注于高性能和低资源占用。WasmEdge-go 为 Go 语言提供了与 WasmEdge 引擎交互的接口，

**可以用于加载、验证、实例化和执行 WebAssembly 模块。**

以下是 WasmEdge-go 库的一些关键特性和用法：

1. **加载 Wasm 文件：**

```Go
vm := wasmedge.NewVM()
vm.LoadWasmFile("example.wasm")
```

1. **配置和实例化：**

```Go
conf := wasmedge.NewConfigure(wasmedge.WASI)
vm := wasmedge.NewVMWithConfig(conf)
```

1. **执行 Wasm 模块：**

```Go
result, err := vm.Execute("function_name", args...)
if err != nil {
    // 处理错误
}
```

1. **注册主机函数：**

```Go
hostFunction := wasmedge.NewFunctionType(/* input types */, /* output types */)
vm.RegisterFunction("host_function_name", hostFunction, hostFunc, nil, 0)
```

1. **内存操作：**

```Go
mem := vm.GetMemoryByIndex(0)
data, _ := mem.GetData(offset, size)
```

1. **释放资源：**

```Go
vm.Release()
conf.Release()
```

上述代码片段是 WasmEdge-go 库的一些基本用法，实际使用时可能需要根据具体的需求进行更多的配置和操作。确保你的环境中安装了 WasmEdge 引擎和 WasmEdge-go 库，可以参考官方文档和示例代码来了解更多用法和细节：

- WasmEdge 官方网站: https://wasmedge.org/
- WasmEdge-go GitHub 仓库: https://github.com/second-state/WasmEdge-go

请注意，代码片段中的函数和参数可能与实际库版本略有不同，具体取决于库的版本。建议查阅相关文档和代码示例以获取最新的信息。

## 使用go写一个wasm应用，结合大语言模型LLM应用

创建一个使用Go编写的WebAssembly（Wasm）应用，结合大语言模型（LLM）可能涉及几个步骤。在这个例子中，我将使用Go语言编写一个简单的Wasm应用，并使用JavaScript与GPT-3.5大语言模型进行通信。请注意，由于GPT-3.5的模型是在Python环境下进行训练的，因此我们将使用一个中间层，通过HTTP请求与GPT-3.5通信。

1. **创建Go的Wasm应用：**
2. 创建一个Go文件，比如 `main.go`，并写入以下代码：

```Plaintext
goCopy codepackage main

import (
        "syscall/js"
        "net/http"
        "bytes"
        "io/ioutil"
)

func main() {
        js.Global().Set("generateText", js.FuncOf(generateText))
        select {}
}

func generateText(this js.Value, p []js.Value) interface{} {
        inputText := p[0].String()

        // 发送HTTP请求到GPT-3.5
        gptResponse, err := sendRequestToGPT(inputText)
        if err != nil {
                return err.Error()
        }

        // 处理GPT-3.5的响应
        // 在实际应用中，可能需要解析JSON等格式的响应
        return gptResponse
}

func sendRequestToGPT(inputText string) (string, error) {
        url := "http://your-gpt-api-endpoint"  // 替换为实际的GPT-3.5 API端点

        // 构建HTTP请求
        req, err := http.NewRequest("POST", url, bytes.NewBuffer([]byte(inputText)))
        if err != nil {
                return "", err
        }

        // 设置请求头等

        // 发送HTTP请求
        client := &http.Client{}
        resp, err := client.Do(req)
        if err != nil {
                return "", err
        }
        defer resp.Body.Close()

        // 读取响应内容
        body, err := ioutil.ReadAll(resp.Body)
        if err != nil {
                return "", err
        }

        return string(body), nil
}
```

1. 请注意，上述代码中的 `your-gpt-api-endpoint` 需要替换为实际的GPT-3.5 API端点。
2. **将Go代码编译为Wasm：**
3. 在终端中执行以下命令，将Go代码编译为Wasm文件：

```Plaintext
bashCopy code
GOARCH=wasm GOOS=js go build -o main.wasm
```

1. **创建HTML文件：**
2. 创建一个HTML文件，比如 `index.html`，并引入Wasm文件以及JavaScript代码：

```Plaintext
htmlCopy code<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wasm with GPT-3.5</title>
</head>
<body>
    <script src="main.wasm"></script>
    <script>
        const go = new Go();
        WebAssembly.instantiateStreaming(fetch("main.wasm"), go.importObject).then((result) => {
            go.run(result.instance);
        });

        // 调用Go函数，并处理GPT-3.5的响应
        function generateText(inputText) {
            const gptResponse = generateText(inputText);
            console.log("GPT-3.5 Response:", gptResponse);
            // 在实际应用中，可以将响应显示在页面上或进行其他处理
        }
    </script>
</body>
</html>
```

1. 在这个例子中，我们调用了Go中的 `generateText` 函数，并在JavaScript中处理了GPT-3.5的响应。
2. **启动一个HTTP服务器：**
3. 在终端中执行以下命令，启动一个简单的HTTP服务器：

```Plaintext
bashCopy code
python3 -m http.server
```

1. 访问 `http://localhost:8000` 即可查看你的Wasm应用。

请注意，实际应用中，你需要替换GPT-3.5的API端点，并根据GPT-3.5 API的文档设置适当的请求头、参数等。此外，这只是一个简单的示例，实际应用中可能需要更复杂的逻辑和错误处理。

## 部署一个大型语言模型（LLM）应用到 Kubernetes（k8s）

可以分为几个步骤。以下是一个简单的指南，假设你已经有一个训练好的LLM模型，并希望将其部署在Kubernetes集群上。

步骤：

1. **Docker化LLM应用：**
2. 将LLM应用封装到一个Docker镜像中。创建一个 `Dockerfile` 并在其中定义LLM应用的依赖、环境和启动命令。确保Docker镜像中包含了LLM模型文件、应用代码以及任何必要的依赖。

```Dockerfile
FROM python:3.8

WORKDIR /app

# 将LLM应用的代码和模型文件复制到容器中
COPY . .

# 安装依赖
RUN pip install -r requirements.txt

CMD ["python", "llm_app.py"]
```

1. **推送Docker镜像到容器注册表（Container Registry）：**
2. 将Docker镜像推送到一个容器注册表，如Docker Hub、Google Container Registry等。确保你已经在容器注册表上创建了相应的仓库。

```Bash
docker build -t your-registry/llm-app:latest .
docker push your-registry/llm-app:latest
```

1. **创建Kubernetes部署文件：**
2. 创建一个Kubernetes的Deployment文件，描述LLM应用的部署配置。这个文件应该指定容器的镜像、端口映射、环境变量等。

```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-app-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: llm-app
  template:
    metadata:
      labels:
        app: llm-app
    spec:
      containers:
      - name: llm-app-container
        image: your-registry/llm-app:latest
        ports:
        - containerPort: 5000
```

1. **创建Kubernetes服务：**
2. 创建一个Kubernetes服务，允许其他Pod通过服务名访问LLM应用。

```YAML
apiVersion: v1
kind: Service
metadata:
  name: llm-app-service
spec:
  selector:
    app: llm-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: LoadBalancer
```

1. **部署到Kubernetes集群：**
2. 使用kubectl命令将Deployment和Service部署到Kubernetes集群。

```Bash
kubectl apply -f llm-app-deployment.yaml
kubectl apply -f llm-app-service.yaml
```

1. **访问LLM应用：**
2. 等待Pod和Service启动后，通过Service的External IP或者集群内部IP访问LLM应用。

```Bash
kubectl get services
```

1. 找到 `llm-app-service` 的 EXTERNAL-IP，并使用浏览器或HTTP工具进行访问。

以上步骤是一个简单的示例，实际上，你可能需要考虑数据持久化、自动伸缩、安全性等方面的更多细节。确保你的LLM应用与Kubernetes集群的最佳实践和安全准则一致。

## 插件

构建和运行一个 Wasm 插件，验证请求 body 是 JSON，并包含两个必要的键 ——`id` 和 `token`。

## 编写 Wasm 插件

这个示例使用 [tinygo](https://tinygo.org/) 来编译成 Wasm。确保你已经安装了 [tinygo 编译器](https://tinygo.org/getting-started/install/)。

### 配置 Wasm 上下文

首先配置 Wasm 上下文，这样 tinygo 文件才能操作 HTTP 请求：

```Go
package main

import (
        "github.com/tetratelabs/proxy-wasm-go-sdk/proxywasm"
        "github.com/tetratelabs/proxy-wasm-go-sdk/proxywasm/types"
        "github.com/tidwall/gjson"
)

func main() {
        // SetVMContext 是配置整个 Wasm VM 的入口。请确保该入口在 main 函数中调用，否则 VM 将启动失败。
        proxywasm.SetVMContext(&vmContext{})
}

// vmContext 实现 proxy-wasm-go SDK 的 types.VMContext 接口。
type vmContext struct {
        // 在这里嵌入默认的虚拟机环境，我们不需要实现所有方法。
        types.DefaultVMContext
}

// 复写 types.DefaultVMContext
func (*vmContext) NewPluginContext(contextID uint32) types.PluginContext {
        return &pluginContext{}
}

// pluginContext 实现 proxy-wasm-go SDK 的 types.PluginContext 接口
type pluginContext struct {
        // 在这里侵入默认的插件上下文，我们不需要实现所有方法。
        types.DefaultPluginContext
}

// 复写 types.DefaultPluginContext
func (ctx *pluginContext) NewHttpContext(contextID uint32) types.HttpContext {
        return &payloadValidationContext{}
}

// payloadValidationContext 实现 proxy-wasm-go SDK 的 types.HttpContext 接口
type payloadValidationContext struct {
        // 在这里嵌入默认的根 http 上下文，我们不需要实现所有方法。
        types.DefaultHttpContext
        totalRequestBodySize int
}
```

### 验证负载

内容类型头是通过实现 `OnHttpRequestHeaders` 来验证的，一旦从客户端收到请求头，就会调用该头。

`proxywasm.SendHttpResponse` 用于响应 403 forbidden 的错误代码和信息，如果内容类型丢失的话。

```Go
func (ctx *payloadValidationContext) OnHttpRequestHeaders(numHeaders int, endOfStream bool) types.Action {
        contentType, err := proxywasm.GetHttpRequestHeader("content-type")
        if err != nil || contentType != "application/json" {
                // 如果 header 没有期望的 content type，返回 403 响应
                if err := proxywasm.SendHttpResponse(403, nil, []byte("content-type must be provided"), -1); err != nil {
                        proxywasm.LogErrorf("failed to send the 403 response: %v", err)
                }
                // 终止 ActionPause 对流量的进一步处理
                return types.ActionPause
        }

        // ActionContinue 让主机继续处理 body
        return types.ActionContinue
}
```

请求主体是通过实现 `OnHttpRequestBody` 来验证的，每次从客户端接收到请求的一个块时，都会调用该请求。这是通过等待直到 `endOfStream` 为真并记录所有收到的块的总大小来完成的。一旦收到整个主体，就会使用 `proxywasm.GetHttpRequestBody` 读取，然后可以使用 golang 进行验证。

这个例子使用 `gjson`，因为 tinygo 不支持 golang 的默认 JSON 库。它检查有效载荷是否是有效的 JSON，以及键 `id` 和 `token` 是否存在。

```Go
func (ctx *payloadValidationContext) OnHttpRequestBody(bodySize int, endOfStream bool) types.Action {
        ctx.totalRequestBodySize += bodySize
        if !endOfStream {
                // OnHttpRequestBody 等待收到到 body 的全部才开始处理。
                return types.ActionPause
        }

        body, err := proxywasm.GetHttpRequestBody(0, ctx.totalRequestBodySize)
        if err != nil {
                proxywasm.LogErrorf("failed to get request body: %v", err)
                return types.ActionContinue
        }

        if !validatePayload(body) {
                // 如果验证失败，发送 403 响应。
                if err := proxywasm.SendHttpResponse(403, nil, []byte("invalid payload"), -1); err != nil {
                        proxywasm.LogErrorf("failed to send the 403 response: %v", err)
                }
                // 终止流量
                return types.ActionPause
        }

        return types.ActionContinue
}

// validatePayload 验证给定的 json 负载
// 注意该函数使用 gjson 解析 json，因为 TinyGo 不支持 encoding/json
func validatePayload(body []byte) bool {
        if !gjson.ValidBytes(body) {
                proxywasm.LogErrorf("body is not a valid json: %v", body)
                return false
        }
        jsonData := gjson.ParseBytes(body)

        // 验证 json。检查示例中是否存在必须的键
        for _, requiredKey := range []string{"id", "token"} {
                if !jsonData.Get(requiredKey).Exists() {
                        proxywasm.LogErrorf("required key (%v) is missing: %v", requiredKey, jsonData)
                        return false
                }
        }

        return true
}
```

### 编译成 Wasm

使用 tinygo 编译器编译成 Wasm：

```Bash
tinygo build -o main.wasm -scheduler=none -target=wasi main.go
```

### 部署 Wasm 插件

### 打包到 Docker 中部署到 Envoy

对于开发，这个插件可以在 Docker 中部署到 Envoy。下面的 Envoy 配置文件将设置 Envoy 监听 `localhost:18000`，运行所提供的 Wasm 插件，并在成功后响应 HTTP 200 和文本 `hello from server`。突出显示的部分是配置 Wasm 插件。

```YAML
static_resources:
  listeners:
    - name: main
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 18000
      filter_chains:
        - filters:
            - name: envoy.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: ingress_http
                codec_type: auto
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: local_service
                      domains:
                        - "*"
                      routes:
                        - match:
                            prefix: "/"
                          route:
                            cluster: web_service
 
                http_filters:
                 - name: envoy.filters.http.wasm
                    typed_config:
                      "@type": type.googleapis.com/udpa.type.v1.TypedStruct
                      type_url: type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm
                      value:
                        config:
                          vm_config:
                            runtime: "envoy.wasm.runtime.v8"
                            code:
                              local:
                                filename: "./main.wasm"
                  - name: envoy.filters.http.router

    - name: staticreply
      address:
        socket_address:
          address: 127.0.0.1
          port_value: 8099
      filter_chains:
        - filters:
            - name: envoy.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: ingress_http
                codec_type: auto
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: local_service
                      domains:
                        - "*"
                      routes:
                        - match:
                            prefix: "/"
                          direct_response:
                            status: 200
                            body:
                              inline_string: "hello from the server\n"
                http_filters:
                  - name: envoy.filters.http.router
                    typed_config: {}

  clusters:
    - name: web_service
      connect_timeout: 0.25s
      type: STATIC
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: mock_service
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: 127.0.0.1
                      port_value: 8099

admin:
  access_log_path: "/dev/null"
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 8001
```

运行 Docker 容器：

```Bash
docker run --rm -p 18000:18000 \
  -v $PWD/envoy.yaml:/envoy.yaml \
  -v $PWD/main.wasm:/main.wasm \
  --entrypoint envoy containers.istio.tetratelabs.com/proxyv2:1.9.7-tetrate-v0 \
  -l debug \
  -c /envoy.yaml
```

通过 curl 测试。首先，没有设置内容类型，将返回 403：

```Bash
% curl -i -X POST localhost:18000
HTTP/1.1 403 Forbidden
content-length: 29
content-type: text/plain
date: Sun, 13 Mar 2022 22:13:37 GMT
server: envoy

content-type must be provided
```

然后，请求 body 不是 JSON，同样返回 403。

```Bash
% curl -i -X POST localhost:18000 -H 'Content-Type: application/json' --data 'not JSON'
HTTP/1.1 403 Forbidden
content-length: 15
content-type: text/plain
date: Sun, 13 Mar 2022 22:15:53 GMT
server: envoy

invalid payload
```

JSON 负载中没有 `token` 字段，还是返回 403。

```Bash
% curl -i -X POST localhost:18000 -H 'Content-Type: application/json' --data '{"id": "xxx"}'
HTTP/1.1 403 Forbidden
content-length: 15
content-type: text/plain
date: Sun, 13 Mar 2022 22:17:18 GMT
server: envoy

invalid payload
```

当 id 和 token 字段都被提供时，将返回一个成功的响应。

```Bash
% curl -i -X POST localhost:18000 -H 'Content-Type: application/json' --data '{"id": "xxx", "token": "xxx", "anotherField": "yyy"}'
HTTP/1.1 200 OK
content-length: 22
content-type: text/plain
date: Sun, 13 Mar 2022 22:18:37 GMT
server: envoy
x-envoy-upstream-service-time: 1

hello from the server
```



------



# 6.824

## lab1

这是 MIT 6.824 课程中的第一个实验任务，要求你实现一个分布式的 MapReduce 系统。这个实验的目标是让你理解分布式系统中的一些关键概念，如任务分配、容错处理以及进程间通信。

### 实验概述
你将要实现一个由协调器（Coordinator）和工作者（Worker）组成的 MapReduce 系统：
- **协调器**负责向工作者分配任务，并处理因工作者失败而引起的任务重试。
- **工作者**将从协调器获取任务，执行 Map 或 Reduce 操作，并生成输出文件。

### 实验步骤

1. **设置实验环境**
   
   - 克隆实验代码库：
     ```bash
     git clone git://g.csail.mit.edu/6.824-golabs-2021 6.824
     cd 6.824
     ```
   - 进入 `src/main` 目录，编译并运行给定的 `mrsequential.go` 文件，这是一个单进程的 MapReduce 实现：
     ```bash
     cd src/main
     go build -race -buildmode=plugin ../mrapps/wc.go
     rm mr-out*
     go run -race mrsequential.go wc.so pg*.txt
     ```
   
2. **实现分布式 MapReduce 系统**
   - 你需要在 `mr/coordinator.go`、`mr/worker.go` 和 `mr/rpc.go` 中实现分布式 MapReduce 系统的核心逻辑。
   - 工作者应该从协调器获取任务，执行任务，并将结果存储在合适的输出文件中。协调器需要监控工作者的状态，并在工作者失败时重新分配任务。

3. **测试你的实现**
   - 编译 `mrapps/wc.go`：
     ```bash
     go build -race -buildmode=plugin ../mrapps/wc.go
     ```
   - 启动协调器：
     ```bash
     go run -race mrcoordinator.go pg-*.txt
     ```
   - 在另一个终端中启动一个或多个工作者：
     ```bash
     go run -race mrworker.go wc.so
     ```
   - 运行测试脚本 `test-mr.sh`，以验证你的实现是否正确：
     ```bash
     bash test-mr.sh
     ```

### 关键实现细节

- **协调器**：
  - 协调器负责追踪 Map 和 Reduce 任务的状态。
  - 当一个工作者请求任务时，协调器需要分配一个尚未开始或已超时的任务。
  - 协调器还需要检测工作者是否在合理的时间内完成任务，若没有完成，则将任务分配给其他工作者。

- **工作者**：
  - 工作者通过 RPC 请求任务。
  - 执行任务后，将结果写入中间文件（Map 任务）或输出文件（Reduce 任务）。
  - 通过 RPC 向协调器报告任务完成情况。

- **中间文件和输出文件**：
  - 中间文件命名格式为 `mr-X-Y`，其中 X 表示 Map 任务编号，Y 表示 Reduce 任务编号。
  - 最终的 Reduce 任务输出文件格式为 `mr-out-X`，其中 X 表示 Reduce 任务编号。

- **并发与容错**：
  - Go 的 `sync` 包可以帮助你处理并发问题，特别是在协调器中。
  - 你需要实现一种机制，确保当工作者失败时，协调器能够重新分配任务。

### 提示与建议

- 从简单的任务分配开始，逐步添加错误处理和并发控制。
- 使用 Go 的 `race detector` (`-race` 选项) 来检测并发问题。
- 使用 `json` 包来序列化和反序列化中间数据。

### 提交与检查

在完成实验后，确保所有测试都通过，然后你可以将实验提交给课程系统。

这个实验不仅要求你理解并实现一个分布式系统，还会帮助你掌握如何在分布式环境中处理容错、并发等挑战性问题。祝你实验顺利！如果有任何问题，随时向我提问。



## lab2

**命令是上层服务lab3/lab4 使用raft时传递的，会在日志中存储**

### 目标

这个实验非常详细，涉及到在多个阶段实现 Raft 共识算法。以下是你可以处理每个部分的简要概述：

#### 第2A部分：领导选举
- **目标：** 实现 Raft 的领导选举和心跳机制。
- **步骤：**
  1. 修改 `Raft` 结构体，添加与选举相关的状态（例如，任期、投票计数）。
  2. 实现 `RequestVote` RPC 处理程序，使候选人可以请求其他节点的投票。
  3. 设置定期触发选举的机制，例如在没有接收到领导者心跳信号时触发。
  4. 实现 `AppendEntries` RPC，领导者可以周期性地发送心跳信号，以防止其他节点发起选举。

#### 第2B部分：日志复制
- **目标：** 实现领导者和跟随者之间的日志追加机制，以通过测试。
- **步骤：**
  1. 实现 `Start` 函数，使得新的日志条目可以通过领导者追加到日志中。
  2. 编写代码通过 `AppendEntries` RPC 发送和接收新的日志条目。
  3. 确保当某些跟随者的日志与领导者不一致时，领导者能够正确地回滚并同步日志。

#### 第2C部分：持久化
- **目标：** 确保 Raft 在服务器重启后能够恢复之前的状态。
- 保存的分为raft元数据和快照
- **步骤：**
  1. 完成 `persist` 和 `readPersist` 函数，实现将 Raft 的状态保存到 `Persister` 对象中，并在重启时恢复状态。
  2. 在每次状态更改时调用 `persist` 保存持久化状态。
  3. readPersist，是在raft启动时读取，
  4. 在 `AppendEntries` 中实现快速回滚以提高同步效率。

#### 第2D部分：日志压缩
- **目标：** 实现**日志压缩**机制，以便长时间运行的服务可以定期丢弃旧的日志条目。
- 压缩可以理解为主节点将已提交的旧日志转换为快照，从节点则根据主节点提供的快照来同步数据。
  - 主节点会主动进行日志压缩。
  - 从节点不会主动进行压缩，但会通过接收主节点的快照来实现类似压缩的效果。主节点执行日志压缩后，如果从节点需要通过快照才能追上主节点的状态，那么主节点会发送当前的快照到从节点，否则会继续通过日志复制的方式保持同步。

- **步骤：**
  1. 实现 `Snapshot` 接口，服务端可以通过它通知 Raft 当前的状态快照。
  2. 实现 `CondInstallSnapshot`，当接收到新的快照时判断是否需要更新。
  3. 实现 `InstallSnapshot` RPC，用于在从节点落后较多时，领导者发送快照以帮助其快速同步状态。
  4. 修改 Raft 的日志管理，使得在存储状态快照后，能够丢弃不需要的日志条目。
  5. 在实验2D中，测试人员定期调用 `Snapshot()` ,**服务层在每个对等体上调用** `Snapshot()` （而不仅仅是在领导者上）。
  6. 但是，现在可能会有一个follower远远落在后面，以至于leader已经丢弃了它需要赶上的日志条目; leader必须发送一个快照以及从快照开始的日志
  7. 

快照----主节点日志压缩/从节点落后追赶/崩溃后恢复  ，持久化----节点56重启时恢复状态

从节点落后追赶：

1. 网络问题
2. 崩溃  可能先持久化恢复，又被主节点快照覆盖追赶

------



### 实例代码建议

这段“Raft Structure Advice” 提供了关于如何组织 Raft 实例代码的建议，特别是如何处理外部事件和定期任务。以下是主要要点的中文解释：

1. **共享数据与锁**：每个 Raft 实例都有一堆状态（如日志、当前索引等），这些状态必须在并发 goroutine 中更新。虽然可以使用消息通道来管理状态更新，但经验表明，使用共享数据和锁更为直接和简单。

2. **时间驱动的活动**：Raft 实例有两个基于时间的活动：
   - **Leader 发送心跳信号**。
   - **其他节点在超过选举超时时间未收到心跳时发起选举**。

   建议为每个活动单独创建一个长时间运行的 goroutine，而不是将多个活动合并到一个 goroutine 中。

3. **选举超时管理**：选举超时的管理是一个常见的难题。最简单的方案是维护一个变量，记录上次从 Leader 接收到信息的时间。选举超时的 goroutine 定期检查当前时间是否超过了超时时间。最好使用 `time.Sleep()` 来驱动定期检查，而不是使用 `time.Ticker` 和 `time.Timer`，后者使用起来较为复杂。

4. **处理已提交日志条目**：应创建一个单独的长时间运行的 goroutine，将已提交的日志条目按顺序发送到 `applyCh`。这个 goroutine 应该是单独的，因为发送到 `applyCh` 可能会阻塞；此外，这应该是一个单独的 goroutine，以确保日志条目按顺序发送。更新 `commitIndex` 的代码需要触发 `apply` goroutine，最简单的方法是使用条件变量（Go 的 `sync.Cond`）来处理。

5. **RPC 的处理**：每个 RPC 应该在其自己的 goroutine 中发送及处理回复，有两个原因：
   - 这样无法访问的节点不会延迟收集多数回复。
   - 这样心跳和选举计时器可以始终正常工作。

   最好在同一个 goroutine 中处理 RPC 回复，而不是通过通道传递回复信息。

6. **网络延迟与 RPC 乱序**：需要注意网络可能会延迟 RPC 和 RPC 回复，并且在发送并发 RPC 时，网络可能会重新排序请求和回复。Leader 在处理 RPC 回复时要格外小心，必须检查在发送 RPC 之后任期是否发生变化，并考虑到来自同一 Follower 的并发 RPC 回复可能会改变 Leader 的状态（例如 `nextIndex`）。

这些建议有助于在设计和实现 Raft 协议时更好地管理并发和异步操作。



### 日志压缩
日志压缩对于防止 Raft 日志无限增长至关重要，否则这可能最终会耗尽存储资源并减慢系统的运行速度。日志压缩的核心思想是定期创建应用程序状态的快照，从而允许丢弃已经包含在快照中的旧日志条目。

1. **快照与日志索引的对应关系**：在创建快照时，需要确保应用程序的状态与 Raft 日志中的某个已知索引相对应。这意味着应用程序需要向 Raft 通知快照对应的日志索引，或者 Raft 需要延迟应用新的日志条目，直到快照完成。
   
2. **恢复协议**：当服务器崩溃并重新启动时，如果使用了快照，就需要特别注意恢复过程。如果 Raft 状态和快照是分别持久化的，服务器可能会在持久化快照和更新 Raft 状态之间崩溃。这会导致问题，因为根据图 13 的第 7 步，快照所覆盖的日志必须被丢弃。

   例如，如果服务器重启时读取了更新后的快照，但日志仍然是旧的，它可能会重新应用一些已经包含在快照中的日志条目。
   
   解决方案是引入一个持久化的状态记录，标记 Raft 持久化日志中第一个条目对应的“真实”索引。这样可以将其与加载的快照的 lastIncludedIndex 进行比较，以确定应丢弃日志开头的哪些元素。
   
   

快照会整个替换应用的状态， 应用快照需要截取日志到快照包含的最新日志
注意：快照是上层应用发给raft的

------



### 加速日志回溯优化

加速日志回溯是一种优化，虽然在大多数部署中可能不是必需的，但在某些情况下非常有用。这一优化在原文中描述得较为简略，可能是因为作者认为它对于大多数部署来说并不必要。具体来说，在文本中没有明确说明从客户端发送回来的冲突索引和任期应该如何被领导者用于确定下一个 nextIndex。

我们认为，作者可能希望你遵循的协议是：

1. **prevLogIndex 不存在**：如果跟随者的日志中没有 prevLogIndex，那么它应该返回 conflictIndex = len(log)，并且 conflictTerm = None。

   即 领导者发送到该对等体的上一条日志不存在 或者说日志较少 ，领导者重发该对等体的最新日志的下一条

2. **prevLogIndex 存在但任期不匹配**：如果跟随者的日志中存在 prevLogIndex，但任期不匹配，那么它应该返回 conflictTerm = log[prevLogIndex].Term，然后在其日志中搜索第一个任期等于 conflictTerm 的条目的索引。

   例如任期大，

3. **领导者处理冲突响应**：领导者收到冲突响应后，应该首先在其日志中搜索 conflictTerm。

   如果找到具有该任期的条目，它应该将 nextIndex 设置为日志中最后一个该任期条目之后的索引。

   如果没有找到具有该任期的条目，则应将 nextIndex 设置为 conflictIndex。

一种简化的解决方案是只使用 conflictIndex（忽略 conflictTerm），这简化了实现，但有时会导致领导者向跟随者发送比严格必要的更多的日志条目，以使它们同步。

------



### 锁建议

这段“Raft Locking Advice” 是关于如何在 6.824 课程的 Raft 实验中使用锁的建议，帮助开发者正确处理并发问题，防止数据竞争和死锁。以下是主要规则的中文解释：

#### 规则 1：多线程访问共享数据时使用锁
当多个 goroutine 访问同一个数据时，如果至少有一个 goroutine 会修改该数据，必须使用锁来防止同时访问导致的数据竞争。Go 的竞态检测工具非常适合检测违反此规则的情况。

#### 规则 2：在执行一系列共享数据的修改时使用锁
如果代码执行了一系列对共享数据的修改，而其他 goroutine 如果在修改过程中访问这些数据可能会产生错误，应该在整个修改序列上使用锁。例如：
```go
rf.mu.Lock()
rf.currentTerm += 1
rf.state = Candidate
rf.mu.Unlock()
```
在这个例子中，必须在整个修改过程中持有锁，以防止其他 goroutine 看到不一致的数据。

#### 规则 3：在一系列读取操作中使用锁
如果代码执行了一系列对共享数据的读取操作（或读写混合），而如果在中途另一个 goroutine 修改了数据会导致错误，应该在整个操作序列上使用锁。例如：
```go
rf.mu.Lock()
if args.Term > rf.currentTerm {
   rf.currentTerm = args.Term
}
rf.mu.Unlock()
```
需要在整个操作序列上持有锁，防止出现竞态条件。

#### 规则 4：避免在持有锁的情况下等待
在持有锁的情况下，不要进行可能会等待的操作，如读取 Go channel、发送 channel、等待计时器、调用 `time.Sleep()` 或发送 RPC 并等待回复。这样做可能会阻止其他 goroutine 的进展，还可能导致死锁。应在等待之前释放锁。

#### 规则 5：重新获取锁后重新检查假设条件
在释放锁并重新获取锁之后，必须小心之前的假设条件可能已经发生变化。一个典型的错误是，启动 goroutine 后，继续在未加锁的情况下访问共享数据。例如：
```go
rf.mu.Lock()
rf.currentTerm += 1
rf.state = Candidate
for <each peer> {
    go func() {
        rf.mu.Lock()
        args.Term = rf.currentTerm
        rf.mu.Unlock()
        Call("Raft.RequestVote", &args, ...)
    } ()
}
rf.mu.Unlock()
```
这个代码可能是错误的，因为在创建 goroutine 和读取 `rf.currentTerm` 之间，时间可能已经过去很长，可能多个任期已经变化。因此，在外部代码持有锁时，需要使用 `rf.currentTerm` 的副本。

#### 总结
这段建议还包括了一些编写和分析并发代码的方法，尤其是如何识别需要加锁的代码片段。

建议一种较为实用的策略是，从没有锁的代码开始，逐步识别和添加必要的锁，同时在可能的等待操作之前释放锁。



### 奇数节点

在 Raft 中，所有重要操作（选举、日志提交）都依赖“多数派”（quorum）达成一致。使用奇数节点，主要有两个好处：

1. **避免选举平局**
   - 在选举新 Leader 时，每个节点投一票，得到超过半数票数才能当选。
   - 如果节点数是偶数，比如 4 个，出现 2:2 的平局就会频繁重试选举；而奇数节点（3、5、7……）则不可能出现完全平票，选举更果断。
2. **最大化容错能力，最小化“浪费”节点**
   - 为了容忍 f 个节点故障，Raft 要求集群规模至少是 2f+1。
   - 当你固定想容忍同样数量的故障时，选用奇数节点能让每个节点都“有用”：
     - 例如，要容忍 1 个故障，用 3 个节点（2×1+1）最合适；用 4 个节点多出的那一个在多数票计算上并不会提高容错数（仍只能容忍 1 个故障），反而增加了资源开销。
     - 同理，容忍 2 个故障要 5 个节点；容忍 3 个故障要 7 个节点，……

总结来说，奇数节点配置既能保证选举和提交过程无平局，又能在给定资源下实现最大的故障容忍度和最少的资源浪费。



------



## 集群成员变化

1. **配置变更的必要性**：集群的配置在实际应用中并非固定不变，节点可能需要替换或调整，以适应不同的需求。

2. **安全性考虑**：直接从旧配置切换到新配置可能导致安全性问题，如在同一任期内出现多个领导者。因此，需要一种安全的方式进行配置更改。

3. **共同一致（Joint Consensus）**： （也可以只用老配置决定）
   - 在配置变更过程中，引入“共同一致”阶段。这个阶段包含旧配置和新配置的所有节点。
   - 领导者能够同时从旧配置和新配置的节点中获取支持，确保选举和日志提交的安全性。

4. **日志条目处理**：
   - 当领导者接收到配置变更请求时，会创建一个新的日志条目（包含旧新配置），并在整个集群中进行复制。
   - 只有在这个条目被提交后，新的配置才会生效。

5. **新节点的加入**：
   - 新加入的节点可以在没有投票权的情况下加入集群，以避免对配置变更的影响。
   - 在追赶至当前集群状态后，这些节点才能参与到后续的投票和决策中。

6. **领导者状态转移**：
   - 如果当前领导者不在新配置中，领导者会在提交新配置后退位，确保集群可以正常运作。

7. **移除旧节点的处理**：
   - 当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。



## 问题

未解决

1. 锁粒度太大，容易造成死锁 ，，

2. 7.6 是否一项提议只需要被多数派通过就可以提交？

3. 代码 readPersist的log类型

4. advanceCommitL()：Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；

5. ```
   reply.ConflictIndex = rf.log.lastindex() 
   reply.ConflictIndex = rf.log.lastindex() + 1
   
   AppendEntries
   ```

   

   

已解决

1. 增加了判断还是不是领导者的条件 ，因为旧领导者可能在重新加入集群后要处理rpc请求

   ![image-20240802212846537](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408022128030.png)

2. 

   ```go
   增加rf.beginSnapshot字段,下面两个都不行
   
   raft发送快照到应用   的判断条件进行更改，
   if rf.waitingSnapshot != nil {
   
   if len(rf.waitingSnapshot) > 0 {
   因为make时如果是全新，那么waitingSnapshot会是nil
   
   ```

   

3. ```
   // 领导者才能发送
   //因为是异步发送，所以需要再次判断（比如上层for循环，节点已经不是领导者）
   // 上层判断不精确
   if rf.state != Leader {
       Debug(dTimer, "S%d 不是领导者，发送追加日志失败 to %d,currentTerm:%v ,state:%v", rf.me, peer, rf.currentTerm, rf.state)
       return
   }
   ```

4. 

5. 

   ```go
   //peer第一条日志是快照的最后一条日志
   if args.LastIncludedIndex > rf.log.lastindex() {
       // 情况1: LastIncludedIndex 大于当前日志的最大索引，创建一个新的日志，只有快照的最后一条日志
       rf.log = mkLog([]Entry{{Term: args.LastIncludedTerm}}, args.LastIncludedIndex)
   } else if args.LastIncludedIndex >= rf.log.start() {
       // 情况2: LastIncludedIndex 在当前日志范围内，截取该索引之后的日志
       rf.log = mkLog(rf.log.slice(args.LastIncludedIndex), args.LastIncludedIndex)
   } else {
       // 情况3: LastIncludedIndex 小于当前日志的起始索引，创建一个新的日志，只有快照的最后一条日志
       rf.log = mkLog([]Entry{{Term: args.LastIncludedTerm}}, args.LastIncludedIndex)
   }
   
   //注意截取后要进行覆盖  不然原来args.LastIncludedIndex处的日志还在 1111111111111111111111
   rf.log.Log[0].Command = nil
   rf.log.Log[0].Term = args.LastIncludedTerm
   ```

   

```
type ApplyMsg struct {
type Raft struct {

func (rf *Raft) GetState() (int, bool) {
func (rf *Raft) persist() {
func (rf *Raft) readPersist(data []byte) {
func (rf *Raft) Snapshot(index int, snapshot []byte) {

type RequestVoteArgs struct {
type RequestVoteReply struct {

func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) {
func (rf *Raft) sendRequestVote(server int, args *RequestVoteArgs, reply *RequestVoteReply) bool {

func (rf *Raft) Start(command interface{}) (int, int, bool) {
func (rf *Raft) Kill() {
func (rf *Raft) killed() bool {
func (rf *Raft) ticker() {
func Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft {

842
```





## 日志工具

```bash
go test -race
go test --race -run TestSnapshotInstallCrash2D


#dtest
./dtest -p 10 -n 10 --output ./logs --verbose  --race
./dtest -p 1 -n 100 --output ./logs --verbose  --race TestSnapshotInstallCrash2D

tests: 要运行的测试列表。
--sequential/-s: 顺序运行每组测试。
--workers/-p: 并行任务的数量。
--iter/-n: 运行的迭代次数。
--output/-o: 输出路径。
--verbose/-v: 详细级别。
--archive/-a: 保存所有日志，而不仅仅是失败的日志。
--race/-r/-R: 是否使用竞争条件检查器。
--loop/-l: 是否持续运行。
--growth/-g: 使用 --loop 时，迭代次数的增长比例。
--timing/-t: 是否报告时间（仅在 macOS 上有效）。

#dslog  
#1.文件
python3  ./dslog -c 5  logs/1

#2.
VERBOSE=1 go test -run TestSnapshotInstallCrash2D | ./dslog -c 5 >logs/debug.log -i LEAD,CLNT,TIMR

file: 指定要读取的文件，如果没有提供则从标准输入读取。
colorize: 是否启用彩色输出，默认启用。
n_columns/c: 设置输出的列数，如果未指定则默认单列输出。
ignore/i: 指定要忽略的日志主题。
just: 指定只显示的日志主题。

```



## lab3



每个键/值服务器（kvserver）都与一个Raft节点关联，一个Join等操作 是由client客户端发起，在**主节点对应的k-v server服务端**开始，经过**所有节点组成的的raft层**达成一致和持久化，最后回到**所有k-v  server服务端**执行

使用请求序列号seqNo 来保证没有重复请求或者超过最新的请求

两类通道

- 一个是raft的applyMsg通道，由上层创建传给raft

- 一个是通知Join等操作完成通道，



该实验要求实现一个容错的键/值存储服务，利用之前在Lab 2中实现的Raft库来进行数据复制。具体来说，服务由多个键/值服务器（kvservers）组成，使用Raft协议确保数据的一致性。即使部分服务器出现故障或网络分区，只要大多数服务器仍然可以通信，服务就可以继续处理客户端请求。

主要目标是实现线性化的键/值存储操作。线性化意味着如果客户端按顺序调用`Put(key, value)`、`Append(key, arg)`、`Get(key)`等操作，系统表现得就像只有一个服务器依次处理请求，并且并发操作的结果与某个顺序执行的结果一致。



#### **Part A：不带快照的键/值服务**

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409151549593.png" alt="raft_diagram" style="zoom: 33%;" />

在这一部分，你需要实现一个基础的键/值存储服务，**每个服务器都有一个Raft节点**。核心的任务是确保键/值操作通过Raft协议进行复制，所有服务器保持相同的键/值状态。

##### 主要步骤：

1. **客户端与Raft领导者交互**：

   - 客户端通过**Clerk与Raft集群的领导者**通信，发送`Put`、`Append`、`Get`等操作。

   - 当Clerk无法确定Raft的领导者时，它应自动重试并找到新的领导者。

   - `Put(key, value)`：将某个键的值替换为指定值。

     `Append(key, arg)`：向键的现有值追加一个字符串参数。

     `Get(key)`：获取键对应的值。

2. **操作的Raft日志复制**：

   - **每个键/值服务器（kvserver）都与一个Raft节点关联**。服务器接收来自客户端的请求后，会通过Raft日志复制该操作。
   - Raft日志确保所有服务器保持相同的顺序执行客户端操作，最终一致。

3. **线性化执行**：

   - **线性化**是指所有客户端操作的执行结果与这些操作依次在单一副本上执行的结果相同。即使客户端之间的操作是并发的，系统也必须表现得像是按某种顺序执行这些操作。
   - 例如，如果客户端A执行了`Put("x", "1")`，并且完成操作后客户端B执行`Get("x")`，那么客户端B必须能看到值`"1"`。

4. **处理失败和重试**：

   - Clerk在发送RPC请求时，可能会遇到某个Raft领导者失效的情况。在这种情况下，Clerk应重试该操作并发送请求给其他kvservers，直到找到新的领导者。
   - 你需要确保每个客户端请求只被执行一次，即使由于重试而多次发送了相同的请求。

5. **防止重复执行**：

   - 系统需要处理并发请求，确保操作不会被多次执行或乱序执行。
   - 你需要设计数据结构来防止同一请求被多次执行，并且每个客户端的操作必须有**唯一标识**，方便服务器检测重复请求。

##### 实现提示：

1. **Clerk和Server的RPC处理**：

   - Clerk通过RPC与服务器通信，你需要在`kvraft/client.go`中为Clerk实现RPC调用逻辑（Put、Append、Get）。
   - 服务器端需要在`kvraft/server.go`中实现RPC处理逻辑，将请求提交给Raft并等待结果返回。

2. **Raft日志与操作提交**：

   - 服务器会将客户端的操作（Put、Append、Get）封装成一个`Op`对象，并通过Raft的`Start()`方法提交到日志中。
   - 当Raft成功达成一致时，服务器会通过`applyCh`通道接收到提交的日志条目，并应用到本地的键/值数据库中。

3. **测试**：

   - 你需要通过一系列的测试，确保你的系统能正确地处理一个或多个客户端的请求。
   - 测试会检查在不同情况下（如网络不可靠、服务器崩溃等），系统是否仍能正确地保持一致性并执行操作。

   

#### **Part B：带快照的键/值服务**

- 通过快照机制减少Raft日志的存储空间和重启时的恢复时间。Raft日志不再存储所有历史操作，服务器可以在日志达到一定大小后，通过快照保存当前状态，并丢弃旧的日志。
- 要确保即使快照存储时系统状态恢复，操作仍然不会重复执行。
- Raft 快照机制的核心是将状态机（如 Key-Value 服务器）的最新状态打包成一个快照文件，并丢弃快照之前的所有日志条目，只保留最新的快照和快照之后的增量日志。从上层key-Value 服务器传递下来，**存储的是 kv.data（Key-Value）和 kv.seqNo（client id -> sequence number）**
- **raft的持久化 崩溃恢复的的是快照、Key-Value 服务器的持久化 崩溃恢复的的是快照的内部数据-解码**

在完成Part A后，系统的Raft日志会不断增长，重启时需要重新回放完整的日志来恢复状态，这会变得非常低效。Part B的任务是通过**快照（snapshot）机制**减少Raft日志的大小，加快系统恢复速度。

##### 主要步骤：

1. **Raft状态的快照**：
   - 当Raft的日志大小超过指定阈值时，服务器需要生成快照并将其持久化到磁盘。
   
   - 快照可以保存当前的键/值数据库状态，并清除旧的Raft日志条目，减小持久化存储的大小。
   
     
   
   - ```
     快照数据是：
     e.Encode(kv.data)
     e.Encode(kv.seqNo)
     ```
   
   - 你需要修改`kvserver`代码，使其在检测到Raft日志超过阈值时生成快照，并通过Raft的`Snapshot()`方法将快照保存到持久化存储中。
   
   - 同时，服务器在启动时应从快照中读取已保存的状态。
   
2. **服务器恢复时读取快照**：
   - 当服务器重启时，它应首先从快照中恢复键/值数据库的状态，而不是从Raft日志开始重放。
   - **跨快照的重复操作检测**：
     - 因为在生成快照时可能还有未完成的日志条目，服务器需要确保对这些未完成操作的处理是线性化的，避免重复执行。
   
3. **Raft日志的截断**：
   - 当生成快照后，Raft可以安全地丢弃日志中已包含在快照中的条目，从而减少存储开销。
   - 你需要修改服务器的逻辑，使其能够在日志大小超过阈值时自动生成快照。



#### 线性化保证如何实现

线性化（Linearizability）是一种强一致性的保证，它要求系统中的所有操作看起来像是按某个全序顺序一次性执行的，并且该顺序符合现实中的时间顺序（即，操作在某个时间点执行后，任何在这之后的操作应该可以观察到该操作的结果）。

**要求数据的线性化一致性或强一致性，通常是通过领导者来完成的。**

在分布式键/值存储系统中，线性化保证意味着每个客户端的读写操作看起来是按照某个线性顺序执行的，并且这个顺序符合操作实际的发生顺序。换句话说，尽管系统中有多个副本和并发请求，客户端会感受到系统是按某个线性顺序执行的。

##### 实现线性化的关键点

为了实现线性化，Raft协议作为分布式一致性协议在多个副本间达成一致，通过以下几种方式确保线性化：

1. **通过Raft日志复制实现一致性**

   - **日志复制**：Raft协议的核心是通过日志复制来保持多个节点的一致性。Raft中的每个客户端操作（如`Put`、`Append`、`Get`）都被作为日志条目复制到所有节点中，只有在多数节点都同意该日志条目后，操作才被认为是“提交”的。
   - **领导者（Leader）选举**：在Raft中，只有领导者节点可以处理客户端的写请求。领导者将每个客户端的操作写入自己的日志并尝试将其复制给其他副本节点。线性化得以实现的原因在于，每次只能有一个领导者，并且领导者确保操作在日志中的顺序保持一致。

2. **将操作封装为状态机命令**

   - 在分布式系统中，每个客户端的操作都会被封装成一个状态机命令，这些命令通过Raft日志复制机制传递给各个服务器的状态机。因为这些命令被按相同顺序复制和执行，所有服务器的状态机都保持一致。
   - **线性化执行**：当某个操作成功提交到Raft日志后，系统确保所有服务器都会按相同的顺序执行该操作，并且客户端在读取时能够看到所有已提交的操作结果。

3. **处理并发客户端请求**

   - 多个客户端可能会并发地向集群发送写入和读取请求。在这种情况下，Raft通过以下机制来确保线性化：
     1. **顺序一致性**：领导者会按照收到客户端请求的顺序将这些请求作为日志条目加入Raft日志。因为领导者是唯一能够处理写操作的节点，所以它能够决定操作的全局顺序。
     2. **提交机制**：只有当日志条目被多数节点（即集群中的大多数副本）确认时，该条目才被认为是“已提交”。客户端只有在操作被提交后，才能收到操作成功的响应。这个提交机制确保所有的客户端看到的都是已提交的操作，未提交的操作对客户端不可见。

4. **处理读取请求**

   - **线性化的读取**：在实现中，读取操作（如`Get`）通常是从领导者节点获取最新的状态。但为了确保读取操作是线性化的，必须确保领导者在响应读取请求时，已经应用了所有的写入操作。因此，领导者需要等待所有先前的写操作都被提交后，才能返回读取结果。
     - 例如，当领导者接收到`Get`请求时，它需要检查是否有尚未提交的日志条目。如果有，领导者需要等待这些日志条目提交后，再返回结果，从而保证读取请求的结果反映的是最新的状态。

5. **防止重复操作**

   - 在分布式系统中，由于网络超时或其他原因，客户端可能会重试同一个操作，导致同一个操作被多次提交。为了确保每个操作只执行一次，系统需要为每个客户端的每个请求分配一个唯一的标识符（如`Clerk`的`ClientId`和`RequestId`）。
   - 每个服务器会跟踪它处理过的每个客户端的最新请求，如果它检测到某个请求是重复的，它会直接返回之前的结果，而不会重新执行该操作。

6. **处理领导者失效**

   - 在Raft中，领导者失效后，其他节点会进行新一轮的领导者选举，选出新的领导者。新的领导者从之前的领导者那里继承日志条目，并继续处理客户端请求。
   - 为了确保线性化，在新的领导者选举出来之前，系统会暂停处理客户端请求。因为客户端只能与领导者进行通信，这意味着在领导者失效期间，客户端的写入请求会被阻塞，直到选出新的领导者并确保日志条目的一致性后再处理。

---

##### 示例

假设有一个分布式键/值存储系统，存在三个节点`A`、`B`、`C`，其中节点`A`是Raft的领导者。

1. **客户端1请求Put操作：**
   - 客户端1向节点`A`发送一个`Put("key1", "value1")`操作。
   - 节点`A`将该操作记录到它的日志中，并开始将日志条目复制到节点`B`和`C`。
   - 一旦该日志条目被大多数节点（`A`和`B`）确认，节点`A`会将该操作标记为已提交，并将结果返回给客户端1。

2. **客户端2请求Get操作：**
   - 在客户端1的`Put`操作提交后，客户端2发送`Get("key1")`操作。
   - 节点`A`会检查它的日志，确保所有写入操作都已提交，然后读取键`key1`的最新值并返回给客户端2。此时，客户端2将会获得`"value1"`作为返回值。
   

即使客户端1和客户端2的操作是并发的，系统依然能保证客户端2在看到客户端1的`Put`操作的结果后才执行它的`Get`操作，这就是线性化的体现。

---

##### 总结

线性化通过以下方式实现：
- Raft日志复制确保所有操作按照全局顺序执行。
- 领导者选举和提交机制确保操作被提交后才对外可见。
- 并发处理通过Clerk的重试机制和请求唯一标识符确保每个操作只执行一次。
- 防止未提交操作影响读取请求，领导者需要等待所有日志条目提交后再执行读取。

通过这些机制，系统能在面对网络分区、服务器故障等问题时，依然保证操作是线性化的。





#### 读操作一定是在领导者上完成的吗

- **读取操作不一定必须由领导者处理**，但如果要求数据的线**性化一致性**或**强一致性**，通常是通过领导者来完成的。
- 在某些优化场景下，可以通过跟随者处理读取操作，但需要通过特殊机制（如 Raft 的 ReadIndex 或租约机制）来确保一致性。
- 如果系统对一致性要求较低（如最终一致性），则读取操作可以通过跟随者来完成，减少领导者的负担并提高系统性能。



##### 1. **Raft **

在 Raft 一致性算法中，客户端的读取操作**不一定**需要由领导者执行，但如果希望确保读取到最新、最一致的数据，则通常需要通过领导者来完成。

读取操作的两种方式：

   - **通过领导者处理读取（Leader-based Read）**：
     - 在 Raft 中，领导者负责处理所有写操作（例如日志复制、状态更新等）。为了确保读取的结果是最新的、符合线性化一致性，最简单的方式是让客户端的读取请求通过领导者。
     - 领导者可以保证读取到的状态是最新的，因为它是唯一能够接收并提交新的写操作的节点。
     - 这样可以避免读取到未提交的或过时的数据。
   
   - **通过跟随者处理读取（Follower-based Read）**：
     - 在某些优化场景下，客户端的读取操作可以直接由跟随者（Follower）节点来处理，以减少领导者的负载并提高系统的读取吞吐量。
     - 但这种读取操作可能存在不一致性问题，因为跟随者的数据状态可能落后于领导者的最新状态。
     - 为了确保从跟随者读取的数据也是线性化一致的，Raft 引入了所谓的 "lease read" 或 "read index" 机制。具体来说，领导者可以向跟随者提供一个读租约（lease），在租约有效期内，跟随者可以安全地响应客户端的读取请求，因为在此期间内不会有新的领导者被选举，跟随者的数据不会落后于领导者。
     - 此外，Raft 还支持使用 **ReadIndex** 机制来确保从跟随者读取时依然满足线性化一致性。ReadIndex 机制通过领导者告知跟随者当前日志的提交索引，跟随者在处理读取请求时会等待日志到达这个提交索引，以确保读取到的是最新的已提交状态。

领导者读取 vs 跟随者读取的权衡：

   - **领导者读取**：更简单，保证强一致性，但领导者负载较大，影响吞吐量。

   - **跟随者读取**：可以提升读取性能，减轻领导者压力，但需要复杂的机制来确保读取的一致性。

     

##### 2. **Paxos 和 Multi-Paxos **

类似于 Raft，Paxos 和 Multi-Paxos 也采用领导者来处理写操作。

   - **领导者读取**：Paxos 协议中，写操作由领导者发起，所有变更需要经过多数派节点（quorum）同意。因此，读取操作如果由领导者处理，通常可以直接返回最新的状态，并保持一致性。
   
   - **跟随者读取**：由于 Paxos 允许节点之间存在滞后，读取操作在跟随者上可能无法保证一致性。为此，Multi-Paxos 可以允许类似 Raft 的 "lease read" 机制，让跟随者也能够处理读取请求，前提是保证其数据不落后于领导者。



##### 3. **在读写分离场景下**

某些分布式数据库或系统采用**读写分离**架构，即写操作通过领导者处理，而读取操作通过跟随者节点处理。为了平衡性能和一致性，系统可能会采用以下几种一致性模型：

- **最终一致性（Eventual Consistency）**：允许从跟随者读取操作，不需要立即得到最新的数据，但系统最终会达到一致性状态。比如在很多分布式存储系统中，为了提高读取的吞吐量，客户端读取操作可以直接从副本节点（Follower）上读取，但不保证读取到的是最新状态。

- **强一致性（Strong Consistency）**：在这种模型下，客户端必须从领导者读取数据，或至少从保证最新状态的节点读取数据。

- **线性化一致性（Linearizability）**：要求读取操作在读取最新的写操作之后执行，通常需要通过领导者来完成。如果允许从跟随者读取，则需要保证跟随者的状态与领导者一致。



##### 4. **领导者读取的必要性**

在一些严格的强一致性模型中（如线性化一致性），如果不采用额外的机制（如 read index），从跟随者读取可能会导致读取到过时的数据。因此，很多系统为了保证读取到最新的写入，倾向于让读取请求通过领导者处理。

但这并不意味着读取操作一定必须由领导者完成。通过一些优化手段，可以让跟随者处理部分读取请求，并仍然保持数据一致性。这样可以实现更高的读性能，同时不损害系统的线性化一致性。





#### 跨快照的重复操作检测

在分布式系统中，为了保证线性化一致性和正确性，服务器需要能够处理跨快照的重复操作检测。即使部分操作已经被快照保存，而另一部分操作还存在于日志中，系统仍然需要正确处理这些重复的客户端请求。

背景

在分布式系统中，为了优化存储和提升性能，日志条目会周期性地被快照（snapshot）化，即将当前系统状态保存为一个快照，并删除已经应用到快照的日志条目。这种机制能够减少存储和日志回放的开销。然而，这带来了一个新的挑战：如何确保跨快照的重复请求能够被正确检测和处理。

例如，假设某个客户端发送了一系列请求，其中一些请求已经被应用到系统状态并被保存为快照，另一些请求仍然存在于日志中。如果客户端重新发送了之前的请求，系统需要检测到这些请求已经被处理，而不能重新执行它们。

跨快照的重复操作检测

为了解决跨快照的重复操作检测问题，可以采取以下机制：

1. **保存客户端请求的元数据**

   - **请求唯一标识符（ClientId + RequestId）**：每个客户端请求应带有唯一的标识符，通常由客户端ID (`ClientId`) 和请求ID (`RequestId`) 组成。系统通过检查这些标识符来判断请求是否已经处理过。
   - **请求状态的持久化**：服务器需要为每个客户端保存其最近的请求ID以及该请求的处理结果。这可以存储在内存中，但为了处理跨快照的情况，这些信息还需要持久化在快照中，以确保快照后仍能检测到已处理过的请求。
     - 当服务器创建快照时，系统不仅要保存当前的应用状态（如键值对），还需要将每个客户端的最新请求状态一起保存到快照中。
     - 在恢复快照时，系统会重新加载这些客户端的请求状态，确保可以继续检测已处理的请求。

2. **日志与快照结合处理**

   - **日志与快照的协同**：在创建快照时，快照保存了系统的状态，但仍然需要处理日志中尚未快照化的请求。具体来说，服务器在接收请求时首先检查日志中的条目，再检查快照中的状态。
     - 例如，如果某个请求的请求ID在快照之后但在当前日志中不存在，系统应该确保从快照中检查该请求是否已经被处理。

3. **请求处理流程**

   在处理客户端请求时，系统需要按照以下流程来检测并处理重复操作：

   - **步骤1：检查日志**：首先检查日志，看看该请求是否已经被记录。如果日志中存在该请求的条目，并且它还没有被提交，那么等待其提交。如果请求已提交，则直接返回之前的结果。
   
   - **步骤2：检查快照**：如果在日志中未找到请求，那么检查快照中的客户端请求状态。系统可以通过`ClientId` 和 `RequestId` 来确认请求是否已被处理。如果快照中已经保存了该请求的处理结果，则直接返回该结果。
   
   - **步骤3：处理新请求**：如果在日志和快照中都未找到该请求，则将该请求作为新的操作进行处理，并将其添加到日志中。之后，在日志提交时更新该请求的处理结果，并在下次创建快照时将其包含在快照中。

4. **快照恢复时的请求处理**

   - 当服务器从快照恢复时，它不仅需要恢复系统状态，还需要恢复客户端的最新请求状态。这样，当客户端重试之前的请求时，服务器仍能检测到这些请求是否已经被处理。
   - 例如，假设系统已经从快照恢复，当某个客户端重新发送已处理的请求时，服务器可以通过恢复的客户端请求状态直接返回之前的结果，而不需要重新执行该操作。

##### 示例

假设有一个分布式键/值存储系统，并且系统已经创建了一个快照。这个快照包括了客户端1的`Put("key1", "value1")`请求，并删除了该请求的日志条目。

1. **客户端1发送相同的`Put`请求（重复请求）：**
   - 当服务器收到客户端1的`Put("key1", "value1")`请求时，它首先检查当前的日志条目，发现该请求不在日志中。
   - 然后，服务器检查从快照恢复的客户端请求状态，发现该请求的`RequestId`已经被处理过。
   - 系统直接返回之前的成功结果给客户端1，而不会重新执行该`Put`操作。

2. **客户端2发送新请求：**
   - 客户端2发送了一个新的请求`Put("key2", "value2")`。服务器首先检查日志，发现该请求不在日志中。
   - 服务器随后检查快照中是否存在该请求的状态，发现客户端2的该请求还未处理过。
   - 系统将该请求添加到日志中，并在多数节点确认后提交该请求，并返回处理结果给客户端2。

##### 关键要点

1. **请求ID跟踪和持久化**：通过唯一的请求ID和客户端ID组合，系统能够准确检测每个请求的执行状态，并避免重复执行。为了处理跨快照的场景，服务器需要在快照中持久化这些请求ID信息。

2. **快照和日志的整合**：系统需要结合快照和日志来确保请求的完整处理流程。已经被快照化的请求状态应与日志中的未快照化操作一起被考虑。

3. **恢复机制**：在从快照恢复时，除了恢复系统的核心状态外，系统还需要恢复已处理的请求信息，这样在快照恢复后，仍然可以进行重复操作的检测。

通过这种机制，服务器可以在快照优化和日志操作之间平衡，确保跨快照的请求能够得到有效处理并防止重复执行。



## lab4

这个实验的目的是构建一个分片的键值存储系统，主要由两个组件组成：**副本组**和**分片控制器**。总体目标是管理数据在分片中的分布，确保系统吞吐量随副本组数量增加而扩展，并能够无缝处理重新配置。

### 第一部分：实现分片控制器 

1. **概述**：分片控制器负责管理分片到副本组的分配。你需要实现几个RPC处理程序，包括添加副本组（`Join`）、移除副本组（`Leave`）、转移分片（`Move`）以及查询当前配置（`Query`）。

2. **具体任务**：
   - 在 `shardctrler` 目录下的 `server.go` 和 `client.go` 中实现分片控制器。
   - 分片控制器管理一系列编号的配置，每个配置描述了一组副本组以及分片到副本组的分配。
   - **Join RPC**：将新的副本组加入系统，并重新分配分片，尽可能地均匀分布，并最少移动分片。
   - **Leave RPC**：移除指定的副本组，将这些组的分片重新分配给剩余的组。
   - **Move RPC**：手动指定某个分片应属于哪个副本组，主要用于测试。
   - **Query RPC**：查询指定编号的配置，如果编号是-1或大于现有最大编号，则返回最新配置。

3. **实现细节**：
   - 初始配置编号为0，应该不包含任何组，所有分片都指向无效的GID（编号为0）。
   - 实现时需要注意避免重复的RPC请求，尽量减少分片移动，并且分片的重新分配要保持确定性（即在Go语言中的map遍历顺序不确定，因此要小心处理）。
   - 提供一个容错的分片控制器，使用Raft协议保证系统在故障情况下仍能正常工作。

完成这些任务后，确保代码通过 `shardctrler` 目录下的所有测试。

### 第二部分：实现分片键值服务器

1. **概述**：分片键值服务器负责处理 `Get`、`Put` 和 `Append` 操作，同时支持在多个副本组之间重新配置分片。服务器需要与分片控制器交互，了解分片到副本组的最新分配，并在分片迁移时进行数据传输。

   - 实验中的 Raft 副本组不会动态演化成员集。
   - 数据和查询模型非常简单。
   - 分片的移交过程较慢，并且在移交期间不允许并发的客户端访问。

   相比之下，真正的生产级系统通常会处理更复杂的场景，包括更高效的分片管理、动态成员更新、并发处理等功能。

2. **任务**：

   - 修改 `shardkv` 目录下的 `client.go`、`common.go` 和 `server.go`，使服务器能够处理配置变化并进行分片迁移。
   - 实现分片迁移时，确保并发的客户端请求不会导致不一致的结果。服务器必须在分片所有权变化时立即停止为该分片提供服务，并将数据迁移给新的副本组。
   - 实现RPC机制，服务器之间通过RPC传输分片数据。
   - 服务器需要周期性地查询分片控制器，获取最新配置。对于不负责的分片，服务器应该返回 `ErrWrongGroup` 错误。

3. **配置变更处理**：
   - 服务器在检测到配置变化时，应该立即开始迁移分片。在迁移完成之前，不能为这些分片提供服务。
   - 如果一个副本组失去了某个分片，它必须停止为该分片提供服务，并开始将数据迁移到新负责的副本组。
   - 使用Raft日志确保所有副本组成员在相同的操作序列中处理重新配置和客户端请求。

4. **测试**：
   - 完成上述任务后，确保代码通过 `shardkv` 目录下的所有测试，尤其是并发配置变化、可靠性、分片迁移等方面的测试。

### 实验提交

在提交之前，请确保所有测试都通过，包括 Raft 实现的测试 (`raft` 目录)、键值存储系统的测试 (`kvraft` 目录)、分片控制器的测试 (`shardctrler` 目录) 以及分片键值服务器的测试 (`shardkv` 目录)。

这个实验的核心挑战在于如何处理多个副本组之间的分片迁移和重新配置，同时保证系统的一致性和容错性。



### 分片控制器

在分片控制器 (`Shard Controller`) 的设计中，`Config` 用于定义分片和副本组之间的映射关系。每个配置 (`Config`) 包含了配置编号、分片到副本组的映射、以及每个副本组和它们的服务器列表。

这里的目标是实现一个分片控制器，支持添加、移除副本组，以及在副本组之间移动分片。以下是实现思路的主要步骤：

#### 主要组件

1. **`Config` 结构体**：
   - `Num`: 配置编号，用来唯一标识每个配置。
   - `Shards`: 表示每个分片对应的副本组ID (`gid`)。
   - `Groups`: 一个映射，记录副本组ID (`gid`) 和服务器列表之间的映射。

2. **RPC 接口**：
   - `Join`: 添加一组新的副本组，并重新分配分片。
   - `Leave`: 删除一组副本组，并将它们持有的分片重新分配给其他副本组。
   - `Move`: 手动将一个分片分配给指定的副本组，用于测试。
   - `Query`: 获取指定配置编号的配置，如果 `num == -1`，返回最新的配置。

#### 设计思路

##### 1. Join RPC

- 传入一个映射：`gid -> servers[]`，其中 `gid` 是副本组ID，`servers[]` 是该组的服务器列表。
- 新的副本组加入后，分片控制器需要重新平衡分片的分配，确保尽可能均匀地将分片分配到所有副本组。

```go
func (sc *ShardCtrler) Join(args *JoinArgs, reply *JoinReply) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    // 创建一个新配置
    newConfig := sc.latestConfig()
    newConfig.Num += 1

    // 将新的副本组添加到配置中
    for gid, servers := range args.Servers {
        newConfig.Groups[gid] = servers
    }

    // 重新分配分片
    sc.rebalanceShards(&newConfig)

    // 保存配置
    sc.configs = append(sc.configs, newConfig)
}
```

##### 2. Leave RPC

- 接受一个 `gids[]` 列表，删除这些副本组，并将它们的分片重新分配给其他副本组。

```go
func (sc *ShardCtrler) Leave(args *LeaveArgs, reply *LeaveReply) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    newConfig := sc.latestConfig()
    newConfig.Num += 1

    // 删除指定的副本组
    for _, gid := range args.GIDs {
        delete(newConfig.Groups, gid)
    }

    // 重新分配它们持有的分片
    sc.rebalanceShards(&newConfig)

    sc.configs = append(sc.configs, newConfig)
}
```

##### 3. Move RPC

- 将某个分片手动分配给指定的副本组。

```go
func (sc *ShardCtrler) Move(args *MoveArgs, reply *MoveReply) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    newConfig := sc.latestConfig()
    newConfig.Num += 1

    // 手动移动分片
    newConfig.Shards[args.Shard] = args.GID

    sc.configs = append(sc.configs, newConfig)
}
```

##### 4. Query RPC

- 返回指定编号的配置。如果 `num == -1`，返回最新配置。

```go
func (sc *ShardCtrler) Query(args *QueryArgs, reply *QueryReply) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    if args.Num == -1 || args.Num >= len(sc.configs) {
        reply.Config = sc.configs[len(sc.configs)-1]
    } else {
        reply.Config = sc.configs[args.Num]
    }
}
```

##### 5. 重新分配分片 (`rebalanceShards`)

- 当副本组发生变化时，需要重新平衡分片。目标是尽量均匀分配分片。

```go
func (sc *ShardCtrler) rebalanceShards(config *Config) {
    // 获取所有现有的 gid
    gids := make([]int, 0)
    for gid := range config.Groups {
        gids = append(gids, gid)
    }

    // 重新均匀分配分片
    for i := 0; i < NShards; i++ {
        config.Shards[i] = gids[i % len(gids)]
    }
}
```

#### 锁机制与Raft的一致性

由于这是一个分布式系统，多个分片控制器实例之间通过 Raft 保证一致性。因此，所有对配置的修改（如 `Join`、`Leave`、`Move`）都需要通过 Raft 的日志同步机制。确保每个实例处理相同的请求顺序，从而保持一致性。

#### 测试与验证

确保每个 RPC 函数的实现能够处理以下情况：
- 正常的副本组加入和移除。
- 手动移动分片的场景。
- 在多副本组、多个客户端并发操作的情况下，确保分片分配的一致性。

你可以通过实现这些方法，并运行测试集来验证分片控制器的功能是否符合预期。









### 分片键值服务器

实现一个分片键值服务器（Shard Key-Value Store）的核心任务是通过分片机制将键值对存储在多个副本组上，以支持分布式环境下的高可用性和负载均衡。主要思路是将键映射到不同的分片，并将每个分片分配给不同的副本组来管理存储和操作请求。

#### 实现思路

##### 1. 系统结构

- **客户端（Clients）**：发送 `Get`、`Put`、`Append` 等请求，系统会根据键决定分片，并将请求发送到管理该分片的副本组。
- **分片控制器（Shard Controller）**：负责管理副本组和分片之间的映射。控制器接收 `Join`、`Leave`、`Move`、`Query` 等指令，动态调整分片与副本组的关系。
- **副本组（Replica Groups）**：副本组是实际存储和管理键值对的服务器集群。每个副本组负责管理若干分片，并通过一致性协议（如 Raft）保证副本组内数据一致性。
- **Raft 协议**：副本组内部的多个节点通过 Raft 协议进行选主并保持一致性，以确保高可用性和容错能力。

##### 2. 数据分片机制

- **分片数目**：通常，系统会有一个固定的分片数，比如 `NShards = 10`。每个分片存储一部分键值数据。
- **哈希映射**：为了确定某个键属于哪个分片，通常使用哈希函数（如 `hash(key) % NShards`）将键映射到分片。
- **分片分配**：分片控制器负责将分片分配给副本组。副本组负责处理所有属于该分片的键值对请求。

##### 3. 请求处理流程

1. **客户端请求**：客户端发起 `Get`、`Put` 或 `Append` 请求。
2. **确定分片**：根据请求中的键，使用哈希函数确定该键属于哪个分片。
3. **查找副本组**：通过分片控制器查询当前配置，找到负责该分片的副本组。
4. **发送请求**：将请求发送到负责该分片的副本组，主节点处理请求并通过 Raft 保证一致性。

##### 4. 分片控制器

分片控制器与之前讨论的一样，主要负责处理分片与副本组之间的映射。它维护一个配置列表，每个配置都记录当前分片和副本组的关系。

分片控制器的核心功能包括：
- **`Join`**：新副本组加入系统，分片控制器会重新分配分片。
- **`Leave`**：副本组离开系统，分片控制器将其管理的分片重新分配给其他副本组。
- **`Move`**：将某个分片从一个副本组移动到另一个副本组。
- **`Query`**：返回指定版本的配置，或返回最新配置。

##### 5. 副本组

每个副本组内部使用 Raft 协议来保证副本之间的数据一致性。副本组需要处理以下操作：

- **`Get(key)`**：根据键找到对应的分片，然后在该分片内查找值。
- **`Put(key, value)`**：根据键找到对应的分片，将键值对存入分片，并在副本组内复制数据。
- **`Append(key, value)`**：在原有值的基础上附加新值。

副本组的核心逻辑是通过 Raft 保证每个写请求在所有副本上都执行相同的操作。

##### 6. 重新分片（Shard Rebalancing）

当副本组的加入或离开导致分片重新分配时，数据需要在副本组之间迁移。步骤如下：

1. **分片控制器更新配置**：当 `Join` 或 `Leave` 操作发生时，分片控制器会生成新的配置，调整分片与副本组的映射。
2. **数据迁移**：副本组需要将旧的分片数据迁移到新的副本组。通常是将分片的数据从旧的副本组复制到新的副本组，保证在迁移过程中不丢失数据。
3. **切换配置**：迁移完成后，所有副本组切换到新的配置，继续处理新的请求。

##### 7. 容错与高可用性

为了保证系统在某些副本组宕机时依然可用，系统会将每个分片的数据复制到多个副本（如 3 个副本）。通过 Raft 协议，可以在副本组内的节点之间选出一个主节点处理请求。当主节点宕机时，剩下的副本可以通过选举产生新的主节点，继续处理请求。

#### 具体实现结构

##### 1. 分片控制器（Shard Controller）

```go
type ShardCtrler struct {
    mu      sync.Mutex
    configs []Config
}

func (sc *ShardCtrler) Join(args *JoinArgs, reply *JoinReply) {
    // 处理副本组的加入逻辑
}

func (sc *ShardCtrler) Leave(args *LeaveArgs, reply *LeaveReply) {
    // 处理副本组的离开逻辑
}

func (sc *ShardCtrler) Move(args *MoveArgs, reply *MoveReply) {
    // 处理分片移动逻辑
}

func (sc *ShardCtrler) Query(args *QueryArgs, reply *QueryReply) {
    // 返回指定编号的配置
}
```

##### 2. 副本组（Replica Group）

每个副本组内部实现键值对存储逻辑，并通过 Raft 协议保证一致性。

```go
type KVServer struct {
    mu       sync.Mutex
    me       int
    rf       *raft.Raft
    applyCh  chan raft.ApplyMsg
    kvStore  map[string]string
}

func (kv *KVServer) Get(args *GetArgs, reply *GetReply) {
    // 处理 Get 请求
}

func (kv *KVServer) PutAppend(args *PutAppendArgs, reply *PutAppendReply) {
    // 处理 Put 和 Append 请求
}
```

##### 3. Raft 协议

Raft 协议用于保证每个副本组内的节点之间的数据一致性。每个写操作都会在 Raft 中作为日志进行复制，确保所有副本都执行相同的操作。

##### 总结

分片键值服务器的关键在于如何将键值数据合理分片，并通过分片控制器动态管理分片与副本组之间的映射。通过分片和副本机制，可以实现系统的高可用性和负载均衡。而 Raft 协议在副本组内部确保数据一致性，保证在分布式环境中的可靠性。





## 运行

lab1:

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408080647435.png" alt="lab1" style="zoom:50%;" />

lab2:

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408080647878.png" alt="1" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408080647679.png" alt="2" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408080647911.png" alt="3" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202408080647248.png" alt="4" style="zoom:50%;" />

lab3:

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409211753142.png" alt="image-20240921175329888" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409211753054.png" alt="image-20240921175352762" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202409211754093.png" alt="image-20240921175405779" style="zoom:50%;" />

------



# 项目工具

- 一个 Go 应用一般由以下 3 部分组成：
  - 应用配置；
  - 应用业务逻辑；
  - 应用启动框架。

## 工厂模式

```Go
type XXXOptions struct {
    // Fields
}

type xxx struct {
    // Fields
}

func NewXXX(opts *XXXOptions) (*xxx, error) {
    // Create logic that is not perceived by the outside world
    return &xxx{}, nil
}

func (x *xxx) FuncA() string {
    return ""
} 
```

## 目录

```Go
//跟 project-layout 目录规范唯一不一样的地方是，miniblog 将具体的实现目录 miniblog 放在 internal/ 目录下，而非 internal/app/ 目录下，

├── api # Swagger / OpenAPI 文档存放目录
│   └── openapi
│       └── openapi.yaml # OpenAPI 3.0 API 接口文档
├── cmd # main 文件存放目录
│   └── miniblog
│       └── miniblog.go
├── configs # 配置文件存放目录
│   ├── miniblog.sql # 数据库初始化 SQL
│   ├── miniblog.yaml # miniblog 配置文件
│   └── nginx.conf # Nginx 配置
├── docs # 项目文档
│   ├── devel # 开发文档
│   │   ├── en-US # 英文文档
│   │   └── zh-CN # 中文文档
│   │       ├── architecture.md # miniblog 架构介绍
│   │       ├── conversions # 规范文档存放目录
│   │       │   ├── api.md # 接口规范
│   │       │   ├── commit.md # Commit 规范
│   │       │   ├── directory.md # 目录结构规范
│   │       │   ├── error_code.md # 错误码规范
│   │       │   ├── go_code.md # 代码规范
│   │       │   ├── log.md # 日志规范
│   │       │   └── version.md # 版本规范
│   │       └── README.md
│   ├── guide # 用户文档
│   │   ├── en-US # 英文文档
│   │   └── zh-CN # 中文文档
│   │       ├── announcements.md # 动态与公告
│   │       ├── best-practice # 最佳实践
│   │       ├── faq # 常见问题
│   │       ├── installation # 安装指南
│   │       ├── introduction # 产品介绍
│   │       ├── operation-guide # 操作指南
│   │       ├── quickstart # 快速入门
│   │       └── README.md
│   └── images # 项目图片存放目录
├── examples # 示例源码
├── go.mod
├── go.sum
├── init # Systemd Unit 文件保存目录
│   ├── miniblog.service # miniblog systemd unit
├── internal # 内部代码保存目录，这里面的代码不能被外部程序引用
│   ├── miniblog # miniblog 代码实现目录
│   │   ├── biz # biz 层代码
│   │   ├── controller # controller 层代码
│   │   │   └── v1 # API 接口版本
│   │   │       ├── post # 博客相关代码实现
│   │   │       │   ├── create.go # 创建博客
│   │   │       │   ├── delete_collection.go #批量删除博客
│   │   │       │   ├── delete.go # 删除博客
│   │   │       │   ├── get.go # 获取博客详情
│   │   │       │   ├── list.go # 获取博客列表
│   │   │       │   ├── post.go # 博客 Controller 结构定义、创建
│   │   │       │   └── update.go # 更新博客
│   │   │       └── user
│   │   │           ├── change_password.go # 修改用户密码
│   │   │           ├── create.go #创建用户
│   │   │           ├── delete.go # 删除用户
│   │   │           ├── get.go # 获取用户详情
│   │   │           ├── list.go # 获取用户列表
│   │   │           ├── login.go # 用户登录
│   │   │           ├── update.go  # 更新用户
│   │   │           └── user.go # 用户 Controller 结构定义、创建
│   │   ├── helper.go # 工具类代码存放文件
│   │   ├── miniblog.go # miniblog 主业务逻辑实现代码
│   │   ├── router.go # Gin 路由加载代码
│   │   └── store # store 层代码
│   └── pkg # 内部包保存目录
│       ├── core # core 包，用来保存一些核心的函数
│       ├── errno # errno 包，实现了 miniblog 的错误码功能
│       │   ├── code.go # 错误码定义文件
│       │   └── errno.go # errno 包功能函数文件
│       ├── known # 存放项目级的常量定义
│       ├── log # miniblog 自定义 log 包
│       ├── middleware # Gin 中间件包
│       │   ├── authn.go # 认证中间件
│       │   ├── authz.go # 授权中间件
│       │   ├── header.go # 指定 HTTP Response Header
│       │   └── requestid.go # 请求 / 返回头中添加 X-Request-ID
│       └── model # GORM Model
├── LICENSE # 声明代码所遵循的开源协议
├── Makefile # Makefile 文件，一般大型软件系统都是采用 make 来作为编译工具
├── _output # 临时文件存放目录
├── pkg # 可供外部程序直接使用的 Go 包存放目录
│   ├── api # REST API 接口定义存放目录
│   ├── proto # Protobuf 接口定义存放目录
│   ├── auth # auth 包，用来完成认证、授权功能
│   │   ├── authn.go # 认证功能
│   │   └── authz.go # 授权功能
│   ├── db # db 包，用来完成 MySQL 数据库连接
│   ├── token # JWT Token 的签发和解析
│   ├── util # 工具类包存放目录
│   │   └── id # id 包，用来生成唯一短 ID
│   └── version # version 包，用来保存 / 输出版本信息
├── README-en.md # 英文 README
├── README.md # 中文 README
├── scripts # 脚本文件
│   ├── boilerplate.txt # 指定版权头信息
│   ├── coverage.awk # awk 脚本，用来计算覆盖率
│   ├── make-rules # 子 Makefile 保存目录
│   │   ├── common.mk # 存放通用的 Makefile 变量
│   │   ├── golang.mk # 用来编译源码
│   │   └── tools.mk # 用来完成工具的安装
│   └── wrktest.sh # wrk 性能测试脚本
└── third_party # 第三方 Go 包存放目录
```

### `/cmd`

本项目的主干。

每个应用程序的目录名应该与你想要的可执行文件的名称相匹配(例如，`/cmd/myapp`)。

不要在这个目录中放置太多代码。如果你认为代码可以导入并在其他项目中使用，那么它应该位于 `/pkg` 目录中。如果代码不是可重用的，或者你不希望其他人重用它，请将该代码放到 `/internal` 目录中。你会惊讶于别人会怎么做，所以要明确你的意图!

通常有一个小的 `main` 函数，从 `/internal` 和 `/pkg` 目录导入和调用代码，除此之外没有别的东西。

有关示例，请参阅 `/cmd` 目录。

### `/internal`

私有应用程序和库代码。这是你不希望其他人在其应用程序或库中导入代码。请注意，这个布局模式是由 Go 编译器本身执行的。有关更多细节，请参阅Go 1.4 `release notes` 。注意，你并不局限于顶级 `internal` 目录。在项目树的任何级别上都可以有多个内部目录。

你可以选择向 internal 包中添加一些额外的结构，以分隔共享和非共享的内部代码。这不是必需的(特别是对于较小的项目)，但是最好有可视化的线索来显示预期的包的用途。你的实际应用程序代码可以放在 `/internal/app` 目录下(例如 `/internal/app/myapp`)，这些应用程序共享的代码可以放在 `/internal/pkg` 目录下(例如 `/internal/pkg/myprivlib`)。

### `/pkg`

外部应用程序可以使用的库代码(例如 `/pkg/mypubliclib`)。其他项目会导入这些库，希望它们能正常工作，所以在这里放东西之前要三思:-)注意，`internal` 目录是确保私有包不可导入的更好方法，因为它是由 Go 强制执行的。`/pkg` 目录仍然是一种很好的方式，可以显式地表示该目录中的代码对于其他人来说是安全使用的好方法。由 Travis Jeffery 撰写的 `I'll take pkg over internal` 博客文章提供了 `pkg` 和 `internal` 目录的一个很好的概述，以及什么时候使用它们是有意义的。

当根目录包含大量非 Go 组件和目录时，这也是一种将 Go 代码分组到一个位置的方法，这使得运行各种 Go 工具变得更加容易（正如在这些演讲中提到的那样: 来自 GopherCon EU 2018 的 `Best Practices for Industrial Programming` , [GopherCon 2018: Kat Zien - How Do You Structure Your Go Apps](https://www.youtube.com/watch?v=oL6JBUk6tj0) 和 [GoLab 2018 - Massimiliano Pippi - Project layout patterns in Go](https://www.youtube.com/watch?v=3gQa1LWwuzk) ）。

如果你想查看哪个流行的 Go 存储库使用此项目布局模式，请查看 `/pkg` 目录。这是一种常见的布局模式，但并不是所有人都接受它，一些 Go 社区的人也不推荐它。

如果你的应用程序项目真的很小，并且额外的嵌套并不能增加多少价值(除非你真的想要:-)，那就不要使用它。当它变得足够大时，你的根目录会变得非常繁琐时(尤其是当你有很多非 Go 应用组件时)，请考虑一下。

### `/vendor`

应用程序依赖项(手动管理或使用你喜欢的依赖项管理工具，如新的内置 `Go Modules` 功能)。`go mod vendor` 命令将为你创建 `/vendor` 目录。请注意，如果未使用默认情况下处于启用状态的 Go 1.14，则可能需要在 `go build` 命令中添加 `-mod=vendor` 标志。

如果你正在构建一个库，那么不要提交你的应用程序依赖项。

注意，自从 `1.13` 以后，Go 还启用了模块代理功能(默认使用 `https://proxy.golang.org` 作为他们的模块代理服务器)。在`here` 阅读更多关于它的信息，看看它是否符合你的所有需求和约束。如果需要，那么你根本不需要 `vendor` 目录。

国内模块代理功能默认是被墙的，七牛云有维护专门的的`模块代理` 。

### 服务应用程序目录

#### `/api`

OpenAPI/Swagger 规范，JSON 模式文件，协议定义文件。

有关示例，请参见 `/api` 目录。

### Web 应用程序目录

#### `/web`

特定于 Web 应用程序的组件:静态 Web 资产、服务器端模板和 SPAs。

### 通用应用目录

#### `/configs`

配置文件模板或默认配置。

将你的 `confd` 或 `consul-template` 模板文件放在这里。

#### `/init`

System init（systemd，upstart，sysv）和 process manager/supervisor（runit，supervisor）配置。

#### `/scripts`

执行各种构建、安装、分析等操作的脚本。

这些脚本保持了根级别的 Makefile 变得小而简单(例如， `https://github.com/hashicorp/terraform/blob/main/Makefile` )。

有关示例，请参见 `/scripts` 目录。

#### `/build`

打包和持续集成。

将你的云( AMI )、容器( Docker )、操作系统( deb、rpm、pkg )包配置和脚本放在 `/build/package` 目录下。

将你的 CI (travis、circle、drone)配置和脚本放在 `/build/ci` 目录中。请注意，有些 CI 工具(例如 Travis CI)对配置文件的位置非常挑剔。尝试将配置文件放在 `/build/ci` 目录中，将它们链接到 CI 工具期望它们的位置(如果可能的话)。

#### `/deployments`

IaaS、PaaS、系统和容器编排部署配置和模板(docker-compose、kubernetes/helm、mesos、terraform、bosh)。注意，在一些存储库中(特别是使用 kubernetes 部署的应用程序)，这个目录被称为 `/deploy`。

#### `/test`

额外的外部测试应用程序和测试数据。你可以随时根据需求构造 `/test` 目录。对于较大的项目，有一个数据子目录是有意义的。例如，你可以使用 `/test/data` 或 `/test/testdata` (如果你需要忽略目录中的内容)。请注意，Go 还会忽略以“.”或“_”开头的目录或文件，因此在如何命名测试数据目录方面有更大的灵活性。

有关示例，请参见 `/test` 目录。

### 其他目录

#### `/docs`

设计和用户文档(除了 godoc 生成的文档之外)。

有关示例，请参阅 `/docs` 目录。

#### `/tools`

这个项目的支持工具。注意，这些工具可以从 `/pkg` 和 `/internal` 目录导入代码。

有关示例，请参见 `/tools` 目录。

#### `/examples`

你的应用程序和/或公共库的示例。

有关示例，请参见 `/examples` 目录。

#### `/third_party`

外部辅助工具，分叉代码和其他第三方工具(例如 Swagger UI)。

#### `/githooks`

Git hooks。

#### `/assets`

与存储库一起使用的其他资产(图像、徽标等)。

#### `/website`

如果你不使用 Github 页面，则在这里放置项目的网站数据。

有关示例，请参见 `/website` 目录。



### tree工具



## 设置容器的 CPU 配额

_ "go.uber.org/automaxprocs"

来使程序自动设置 `GOMAXPROCS` 以匹配 Linux 容器 CPU 配额。通过正确设置容器的 CPU 配额，可以解决 `GOMAXPROCS` 可能设置过大，导致生成线程过多，从而导致严重的上下文切换，浪费 CPU，降低程序性能的潜在问题。

## 应用程序组成部分及构建方法

### 应用配置

#### **命令行选项/参数：Pflag**

##### 介绍

给开发的组件加上各种启动参数来配置服务进程，影响服务的行为。 pflag 是标准库 flag 包的一个替代品，其设计的目的就是取代标准库 flag 包，pflag 实现了 POSIX/GNU 风格的命令行参数，同时 pflag 完全兼容 flag，并且提供了更为强大的特性。

pflag 具有如下特性：

- 支持丰富的参数类型，例如除了支持基本类型、切片类型外，还支持高级类型：`count`、`duration`、`ip`、`ipmask`、`map` 等；
- 兼容标准 flag 包的 `Flag` 和 `FlagSet`；
- 支持更高级的功能，比如：`shorthand`、`deprecated`、`hidden` 等。

pflag 非常适合用来构建大型项目，一些耳熟能详的开源项目都是用 pflag 来进行命令行参数解析，例如：kubernetes、istio、helm、docker、etcd 等。

**pflag 主要是通过创建** **`Flag`** **和** **`FlagSet`** **来使用的。**

##### pflag 包 Flag 定义

pflag 可以对命令行参数进行处理，一个命令行参数在 pflag 包中会解析为一个 `Flag` 类型的变量，`Flag` 是一个结构体，定义如下：

```Go
type Flag struct {
    Name                string // flag 长选项的名称
    Shorthand           string // flag 短选项的名称，一个缩写的字符
    Usage               string // flag 的使用文本
    Value               Value  // flag 的值
    DefValue            string // flag 的默认值
    Changed             bool // 记录 flag 的值是否有被设置过
    NoOptDefVal         string // 当 flag 出现在命令行，但是没有指定选项值时的默认值
    Deprecated          string // 记录该 flag 是否被放弃
    Hidden              bool // 如果值为 true，则从 help / usage 输出信息中隐藏该 flag
    ShorthandDeprecated string // 如果 flag 的短选项被废弃，当使用 flag 的短选项时打印该信息
    Annotations         map[string][]string // 给 flag 设置注解
}
```

`Flag` 的值是一个 `Value` 类型的接口，`Value` 定义如下：

```Go
type Value interface {
    String() string // 将 flag 类型的值转换为 string 类型的值，并返回 string 的内容
    Set(string) error // 将 string 类型的值转换为 flag 类型的值，转换失败报错
    Type() string // 返回 flag 的类型，例如：string、int、ip等
}
```

通过将 flag 的值抽象成一个 interface 接口，可以使我们自定义 flag 类型。

##### pflag 包 FlagSet 定义

pflag 除了支持单个的 `Flag` 之外，还支持 `FlagSet`。

`FlagSet` 是一些预先定义好的 `Flag` 的集和，几乎所有的 pflag 操作，都需要借助 `FlagSet` 提供的方法来完成。在实际开发中，我们可以使用 2 种方法来获取并使用 `FlagSet`：

- (1)调用 `NewFlagSet` 创建一个 `FlagSet`。
- (2)使用 pflag 包定义的全局 `FlagSet`: `CommandLine`。实际上 `CommandLine` 也是由 `NewFlagSet` 函数创建的。

(1)自定义 `FlagSet`。

```Go
var version bool

flagSet := pflag.NewFlagSet("test", pflag.ContinueOnError)
flagSet.BoolVar(&version, "version", true, "Print version information and quit.")
```

我们可以通过定义一个新的 `FlagSet` 来定义命令及其子命令的 `Flag`。

(2)使用全局 `FlagSet`。如下是一个使用全局 `FlagSet` 的示例：

```Go
import (
    "github.com/spf13/pflag"
)

pflag.BoolVarP(&version, "version", "v", true, "Print version information and quit.")
```

`pflag.BoolVarP` 函数定义如下：

```Go
func BoolVarP(p *bool, name, shorthand string, value bool, usage string) {
    flag := CommandLine.VarPF(newBoolValue(value, p), name, shorthand, usage)
    flag.NoOptDefVal = "true"
}
```

可以看到 `pflag.BoolVarP` 最终调用了 `CommandLine`，`CommandLine` 是一个包级别的变量，定义为：

```Go
// CommandLine is the default set of command-line flags, parsed from os.Args.
var CommandLine = NewFlagSet(os.Args[0], ExitOnError)
```

在一些不需要定义子命令的命令行工具中，可以直接使用全局的 `FlagSet`，更加简单方便。

##### 使用方法

上面，我们介绍了使用 pflag 包的 2 个核心结构体。接下来，我来详细介绍下 pflag 的常见使用方法。pflag 有很多强大的功能，一些常见的使用方法如下。大概有以下 11 种常见的使用方法。

1. 兼容标准库的 flag 包

如果以前用的是标准库中的 flag 包，在替换为 pflag 时，大部分情况下只需要将导入的 pflag 包重命名为 flag 即可：

```Go
import flag "github.com/spf13/pflag"
```

1. 支持多种命令行参数定义方式

pflag 支持以下 4 种命令行参数定义方式：

- 支持长选项、默认值和使用文本，并将标志的值**存储在指针**中

```Go
var name = pflag.String("name", "colin", "Input Your Name")
```

- 支持长选项、短选项、默认值和使用文本，并将标志的值存储在指针中

```Go
var name = pflag.StringP("name", "n", "colin", "Input Your Name")
```

- 支持长选项、默认值和使用文本，并将标志的值**绑定到变量**

```Go
var name string
pflag.StringVar(&name, "name", "colin", "Input Your Name")
```

- 支持长选项、短选项、默认值和使用文本，并将标志的值绑定到变量

```Go
var name string
pflag.StringVarP(&name, "name", "n","colin", "Input Your Name")
```

上面的函数命名是有规则的：

- **函数名带** **`Var`** **说明是将标志的值绑定到变量，否则是将标志的值存储在指针中**。（绑定==复制，存储==指针指向一样）
- **函数名带** **`P`** **说明支持短选项，否则不支持短选项。**

**定义完标志之后，调用** **`pflag.Parse()`** **来解析定义的标志。**

为什么声明后还要解析，举个例子 在 Go 中，需要声明和解析命令行参数的原因是分离参数声明和实际参数值的初始化。声明参数允许你定义应用程序接受的命令行选项，包括选项的名称、默认值和帮助文本。解析参数则是在程序运行时，将命令行提供的值与这些声明进行关联。 下面是一个例子，以说明为什么声明和解析是有用的。假设你正在构建一个命令行工具，可以接受输入文件和输出文件的文件名。在程序开始运行之前，你可能会声明这些参数如下：

```Go
var (
    inputFileName  string
    outputFileName string
)
```

这些变量用于存储命令行参数的值。然后，你可以解析命令行参数，以将命令行提供的值与这些变量进行关联：

```Go
func main() {
    flag.StringVar(&inputFileName, "input", "input.txt", "Input file name")
    flag.StringVar(&outputFileName, "output", "output.txt", "Output file name")
    flag.Parse()
    
    // 现在 inputFileName 和 outputFileName 包含了命令行提供的值
}
```

解析参数后，`inputFileName` 和 `outputFileName` 包含了命令行提供的值（如果有）。这允许你在程序中轻松地访问这些值，以便根据用户的选择执行不同的操作。如果用户未提供参数，那么这些变量将包含你在声明中设置的默认值。

总结一下，声明和解析参数的分离允许你在程序中定义参数的结构和默认值，然后根据用户的输入动态地将值与这些参数进行关联。这种分离提供了灵活性，使你能够轻松地更改和扩展命令行选项，而不必改变整个程序的逻辑。

pflag.CommandLine.PrintDefaults() ———函数用于将当前已定义的命令行标志的默认值和使用说明打印到标准输出（通常是终端）。

pflag.Lookup("name")——用于查找指定名称的命令行标志，并返回一个 `*flag.Flag` 对象，该对象包含有关该标志的信息。如果指定名称的标志不存在，`Lookup()` 将返回 `nil`。

```Go
var (
        flagvar = pflag.Int("flagname", 1234, "help message for flagname")//返回的是一个指针
)

func main() {
        var name string
        pflag.StringVar(&name, "name", "colin", "Input Your Name")

        pflag.Parse()

        println("flagname:", *flagvar)
        println("name:", pflag.Lookup("name").Value.String())

        pflag.CommandLine.PrintDefaults()
}
```

1. 使用 `Get<Type>` 获取参数的值

可以使用 `Get<Type>` 来获取标志的值，`<Type>` 代表 pflag 所支持的类型。例如：有一个 `pflag.FlagSet`，带有一个名为 `flagname` 的 `int` 类型的标志，可以使用 `GetInt()` 来获取 `int` 值。需要注意 `flagname` 必须存在且必须是 `int`，例如：

```Go
i, err := flagset.GetInt("flagname")
```

1. 获取非选项参数

代码示例如下：

```Go
var (
    flagvar = pflag.Int("flagname", 1234, "help message for flagname")
)

func main() {
    pflag.Parse()

    fmt.Printf("argument number is: %v\n", pflag.NArg())
    fmt.Printf("argument list is: %v\n", pflag.Args())
    fmt.Printf("the first argument is: %v\n", pflag.Arg(0))
}
```

执行上述代码，输出如下：

```Bash
$ go run example1.go arg1 arg2
argument number is: 2
argument list is: [arg1 arg2]
the first argument is: arg1
```

pflag.NArg() ————》返回非选项参数的个数 pflag.Args() ————》 返回所有的非选项参数 pflag.Arg(i) ————》 返回第 `i` 个非选项参数。参数下标 `0` 到 `pflag.NArg() - 1`。

1. 指定了选项但是没指定选项值时的默认值

创建一个 flag 后，可以为这个 flag 设置 `pflag.NoOptDefVal`。如果一个 flag 具有 `NoOptDefVal`，并且该 flag 在命令行上没有设置这个 flag 的值，则该标志将设置为 `NoOptDefVal` 指定的值。例如：

```Go
var ip = flag.IntP("flagname", "f", 1234, "help message")
flag.Lookup("flagname").NoOptDefVal = "4321"
```

上面的代码会产生结果如下表所示：

| **命令行参数**  | **解析结果** |
| --------------- | ------------ |
| --flagname=1357 | ip=1357      |
| --flagname      | ip=4321      |
| [nothing]       | ip=1234      |

1. 弃用标志或者标志的简写

可以弃用标志或者标志的简写。弃用的标志/简写在帮助文本中会被隐藏，并在使用不推荐的标志/简写时打印正确的用法提示，使用方法如下：

弃用名为 `logmode` 的标志，并告知用户应该使用哪个标志代替

```Go
// deprecate a flag by specifying its name and a usage message
pflag.CommandLine.MarkDeprecated("logmode", "please use --log-mode instead")
```

这样隐藏了帮助文本中的 `logmode`，并且当使用 `logmode` 时打印了 `Flag --logmode has been deprecated, please use --log-mode instead`。

1. 保留名为 `port` 的标志，但是弃用它的简写形式

```Go
pflag.IntVarP(&port, "port", "P", 3306, "MySQL service host port.")

// deprecate a flag shorthand by specifying its flag name and a usage message
pflag.CommandLine.MarkShorthandDeprecated("port", "please use --port only")
```

这样隐藏了帮助文本中的简写 `P`，并且当使用简写 `P` 时打印了 `Flag shorthand -P has been deprecated, please use --port only。usage message` 在此处必不可少，并且不应为空。

1. 隐藏标志

可以将 flag 标记为隐藏的，这意味着它仍将正常运行，但不会显示在 usage/help 文本中。例如：隐藏名为 `secretFlag` 的标志，只在内部使用，并且不希望它显示在帮助文本中或者使用文本中，代码如下：

```Go
// hide a flag by specifying its name
pflag.CommandLine.MarkHidden("secretFlag")
```

1. 禁用 flag 的 help 和 usage 的排序

pflag 允许你禁用 flag 的 help 和 usage 的排序，例如：

```Go
pflag.CommandLine.BoolP("verbose", "v", false, "verbose output")
pflag.CommandLine.String("coolflag", "yeaah", "it's really cool flag")
pflag.CommandLine.Int("usefulflag", 777, "sometimes it's very useful")
pflag.CommandLine.SortFlags = false
pflag.CommandLine.PrintDefaults()
```

上述代码输出如下：

```Bash
-v, --verbose           verbose output
     --coolflag string   it's really cool flag (default "yeaah")
     --usefulflag int    sometimes it's very useful (default 777)
```

1. 支持 Go 标准库 flag 包定义的 flag

为了支持使用 Go 的 flag 包定义的 flag，必须将它们添加到 pflag 标志集中。这通常是支持第三方依赖项定义的标志所必需的(例如 golang/glog)。例如：将 Go flags 添加到 `CommandLine` 标志集中：

```Go
package main
import (
        goflag "flag"
        flag "github.com/spf13/pflag"
)

var ip *int = flag.Int("flagname", 1234, "help message for flagname")

func main() {
        flag.CommandLine.AddGoFlagSet(goflag.CommandLine)
        flag.Parse()
}
```

1. 自定义标志名

可以设置一个自定义标志名的 normalization function。它允许标志在代码中创建时以及在命令行上使用某些需要 normalized 的形式时，标记名都会发生 normalized。normalized 形式一般用于比较。下面是使用自定义 normalized 函数的两个示例。

- 使 `-`，`_` 和 `.` 在标志中等效。比如 `--my-flag` 等于 `--my_flag` 等于 `--my.flag`

```Go
func wordSepNormalizeFunc(f *pflag.FlagSet, name string) pflag.NormalizedName {
        from := []string{"-", "_"}
        to := "."
        for _, sep := range from {
                name = strings.Replace(name, sep, to, -1)
        }
        return pflag.NormalizedName(name)
}

myFlagSet.SetNormalizeFunc(wordSepNormalizeFunc)
```

- 给两个标志设置别名。例如 `--old-flag-name` 等于 `--new-flag-name`

```Go
func aliasNormalizeFunc(f *pflag.FlagSet, name string) pflag.NormalizedName {
        switch name {
        case "old-flag-name":
                name = "new-flag-name"
                break
        }
        return pflag.NormalizedName(name)
}

myFlagSet.SetNormalizeFunc(aliasNormalizeFunc)
```

#### **配置文件：**viper

[Viper](https://github.com/spf13/viper) 是 Go 应用程序现代化、完整的解决方案，能够处理不同格式的配置文件，让我们在构建现代应用程序时，不必担心配置文件格式。Viper 也能够满足我们对应用配置的各种需求。Viper有 很多特性，其中一些比较重要的特性如下：

- 支持默认配置。
- 支持从 `json`、`toml`、`yaml`、`yml`、`properties`、`props`、`prop`、`hcl`、`dotenv`、`env` 格式的文件中读取数据。
- 实时监控和重新读取配置文件（可选）。
- 支持从环境变量中读取配置。
- 支持从远程配置系统（etcd 或 Consul）读取并监控配置变化。
- 从命令行参数读取配置。
- 支持从 buffer 中读取配置。
- 可以显式的给配置项设置值。

Viper 可以从不同的位置读取配置，不同位置的配置具有不同的优先级，高优先的配置会覆盖低优先级相同的配置，按优先级从高到低排列如下：

1. 通过 `viper.Set` 函数显试设置的配置
2. 命令行参数
3. 环境变量
4. 配置文件
5. key/value 存储
6. 默认值

##### Viper 使用方法

**Viper 配置键不区分大小写**

(1)读入配置，将配置读入到 viper 中，有如下读入方式：

- 可以设置默认的配置文件名。
- 读取配置文件。
- 监听和重新读取配置文件。
- 从 `io.Reader` 读取配置。
- 从环境变量读取。
- 从命令行标志读取。
- 从远程 Key/Value 存储读取。

(2)读取配置，从 viper 中读取配置到应用程序中，viper 提供如下函数，来读取配置：

- `Get(key string) interface{}`
- `Get<Type>(key string) <Type>`
- `AllSettings() map[string]interface{}`
- `IsSet(key string) bool`

##### 读入配置

1. 设置默认值

一个好的配置系统应该支持默认值。viper 支持对 key 设置默认值，当没有通过配置文件，环境变量，远程配置或命令行标志设置 key 时，设置默认值通常是很有用的，可以使程序即使在没有明确指定配置时，也能够正常运行。例如：

```Go
viper.SetDefault("ContentDir", "content")
viper.SetDefault("LayoutDir", "layouts")
viper.SetDefault("Taxonomies", map[string]string{"tag": "tags", "category": "categories"})
```

1. 读取配置文件

viper 可以读取配置文件来解析配置，支持 `json`、`toml`、`yaml`、`yml`、`properties`、`props`、`prop`、`hcl`、`dotenv`、`env` 格式的配置文件。Viper 可以搜索多个路径，但目前单个 Viper 实例仅支持单个配置文件。Viper 不默认任何配置搜索路径，将默认决策留给应用程序。

以下是如何使用 Viper 搜索和读取配置文件的示例：

```Go
var (
        cfg  = pflag.StringP("config", "c", "", "Configuration file.")
        help = pflag.BoolP("help", "h", false, "Show this help message.")
)

func main() {
        pflag.Parse()
        if *help {
                pflag.Usage()
                return
        }

        // 从配置文件中读取配置
        if *cfg != "" {
                viper.SetConfigFile(*cfg)   // 指定配置文件名
                viper.SetConfigType("yaml") // 如果配置文件名中没有文件扩展名，则需要指定配置文件的格式，告诉 viper 以何种格式解析文件
        } else {
                viper.AddConfigPath(".")          // 把当前目录加入到配置文件的搜索路径中
                viper.AddConfigPath("$HOME/.iam") // 配置文件搜索路径，可以设置多个配置文件搜索路径
                viper.SetConfigName("config")     // 配置文件名称（没有文件扩展名）
        }
        // if err := viper.ReadInConfig(); err != nil { // 读取配置文件。如果指定了配置文件名，则使用指定的配置文件，否则在注册的搜索路径中搜索
        //         panic(fmt.Errorf("Fatal error config file: %s \n", err))
        // }

        if err := viper.ReadInConfig(); err != nil {
                if _, ok := err.(viper.ConfigFileNotFoundError); ok {
                        // 配置文件未找到错误；如果需要可以忽略
                } else {
                        // 配置文件被找到，但产生了另外的错误
                }
        }

        fmt.Printf("Used configuration file is: %s\n", viper.ConfigFileUsed())

        viper.WatchConfig()
        viper.OnConfigChange(func(e fsnotify.Event) {
                // 配置文件发生变更之后会调用的回调函数
                fmt.Println("Config file changed:", e.Name)
        })

        viper.WriteConfigAs("config.running.yaml")

        // // 使用环境变量
        // os.Setenv("VIPER_USER_SECRET_ID", "QLdywI2MrmDVjSSv6e95weNRvmteRjfKAuNV")
        // os.Setenv("VIPER_USER_SECRET_KEY", "bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb")

        // viper.AutomaticEnv()                                             // 设置 viper 查找是否有跟配置文件中相匹配的环境变量，如果有，则将该环境变量的值设置为配置项的值；
        // viper.SetEnvPrefix("VIPER")                                      // 设置环境变量前缀：VIPER_，如果是 viper，将自动转变为大写。
        // viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_")) // 将 viper.Get(key) key 字符串中 '.' 和 '-' 替换为 '_'
        // viper.BindEnv("user.secret-key")
        // viper.BindEnv("user.secret-id", "USER_SECRET_ID") // 绑定环境变量名到 key
}
```

在加载配置文件出错时，你可以像下面这样处理找不到配置文件的特定情况：

```Go
if err := viper.ReadInConfig(); err != nil {
    if _, ok := err.(viper.ConfigFileNotFoundError); ok {
        // 配置文件未找到错误；如果需要可以忽略
    } else {
        // 配置文件被找到，但产生了另外的错误
    }
}

// 配置文件找到并成功解析
```

viper 支持设置多个配置文件搜索路径，需要注意添加搜索路径的顺序，**viper 会根据添加的路径顺序搜索配置文件**，如果找到则停止搜索。如果调用 `SetConfigFile` 直接指定了配置文件名，并且配置文件名没有文件扩展名时，需要显试指定配置文件的格式，以使 viper 能够正确解析配置文件。

如果通过搜索的方式查找配置文件，则需要注意 `SetConfigName` 设置的配置文件名是不带扩展名的，在搜索时 viper 会在文件名之后追加文件扩展名，并尝试搜索所有支持的扩展类型。比如，如果我们通过 `SetConfigName` 设置了配置文件名为 `config`，则 viper 会在注册的搜索路径中，依次搜索：`config.json`、`config.toml`、`config.yaml`、`config.yml`、`config.properties`、`config.props`、`config.prop`、`config.hcl`、`config.dotenv`、`config.env`。

1. 写入配置文件

读取配置文件很有用，但有时候我们可能需要将程序中当前的配置保存起来，方便后续使用或者 debug，viper 提供了一系列的函数，可以让我们把当前的配置保存到文件中，viper 提供了如下函数来保存配置：

- `WriteConfig`：保存当前的配置到 viper 当前使用的配置文件中，如果配置文件不存在会报错，如果配置文件存在则覆盖当前的配置文件。
- `SafeWriteConfig`：保存当前的配置到 viper 当前使用的配置文件中，如果配置文件不存在会报错，如果配置文件存在则返回 `file exists` 错误。
- `WriteConfigAs`：保存当前的配置到指定的文件中，如果文件不存在则新建，如果文件存在则会覆盖文件。
- `SafeWriteConfigAs`：保存当前的配置到指定的文件中，如果文件不存在则新建，如果文件存在则返回 `file exists` 错误。

根据经验，标记为 `Safe` 的所有方法都不会覆盖任何文件，而是直接创建（如果不存在），而默认行为是创建或截断。

一个小示例：

```Go
viper.WriteConfig()
viper.SafeWriteConfig()
viper.WriteConfigAs("config.running.yaml")
viper.SafeWriteConfigAs("config.running.yaml")
```

1. 监听和重新读取配置文件

Viper 支持在运行时让应用程序实时读取配置文件，也就是热加载配置。可以通过 `WatchConfig` 函数热加载配置。在调用 `WatchConfig` 函数之前，请确保已经添加了配置文件的搜索路径。可选地，可以为 Viper 提供一个回调函数，以便在每次发生更改时运行。

示例：

```Go
viper.WatchConfig()
viper.OnConfigChange(func(e fsnotify.Event) {
   // 配置文件发生变更之后会调用的回调函数
        fmt.Println("Config file changed:", e.Name)
})
```

1. 设置配置值

我们可以通过 `viper.Set()` 函数来显试设置配置：

```Go
viper.Set("user.username", "colin")
```

1. 注册和使用别名

别名允许多个键引用单个值。示例：

```Go
viper.RegisterAlias("loud", "Verbose")
viper.Set("verbose", true) // 效果等同于下面一行代码
viper.Set("loud", true)   // 效果等同于上面一行代码

viper.GetBool("loud") // true
viper.GetBool("verbose") // true
```

1. 使用环境变量

viper 还支持环境变量，通过如下 5 个函数来支持环境变量：

- `AutomaticEnv()`
- `BindEnv(input ...string) error`
- `SetEnvPrefix(in string)`
- `SetEnvKeyReplacer(r *strings.Replacer)`
- `AllowEmptyEnv(allowEmptyEnv bool)`

这里要注意：viper 读取环境变量是区分大小写的。

viper 提供了一种机制来确保 `ENV` 变量是唯一的。通过使用 `SetEnvPrefix`，可以告诉 Viper 在读取环境变量时使用前缀。`BindEnv` 和 `AutomaticEnv` 都将使用此前缀。比如，我们设置了 `viper.SetEnvPrefix("VIPER")`，当使用 `viper.Get("apiversion")` 时，实际读取的环境变量是 `VIPER_APIVERSION`。

`BindEnv` 需要一个或两个参数。第一个参数是键名，第二个是环境变量的名称，环境变量的名称区分大小写。如果未提供 `ENV` 变量名，则viper将假定ENV变量名为： `环境变量前缀_键名全大写` ，例如：前缀为VIPER，key为username，则ENV变量名为： `VIPER_USERNAME` 。当显式提供 `ENV` 变量名（第二个参数）时，它不会自动添加前缀。例如，如果第二个参数是 `id`，Viper 将查找环境变量 `ID`。

在使用 `ENV` 变量时，需要注意的一件重要事情是，每次访问该值时都将读取它。Viper在调用 `BindEnv` 时不固定该值。

还有一个魔法函数 `SetEnvKeyReplacer`，`SetEnvKeyReplacer` 允许你使用 `strings.Replacer` 对象来重写 `Env` 键。如果你想在 `Get()` 调用中使用 `-` 或者 `.` ，但希望你的环境变量使用 `_` 分隔符，可以通过 `SetEnvKeyReplacer` 来实现。比如，我们设置了环境变量 `USER_SECRET_KEY=bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb`，但我们想用 `viper.Get("user.secret-key")`，我们调用函数：

```Go
viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_"))
```

上面的代码，在调用 `viper.Get()` 函数时，会用 `_` 替换 `.` 和 `-` 。默认情况下，空环境变量被认为是未设置的，并将返回到下一个配置源。若要将空环境变量视为已设置，可以使用 `AllowEmptyEnv` 方法。使用环境变量示例如下：

```Go
// 使用环境变量
os.Setenv("VIPER_USER_SECRET_ID", "QLdywI2MrmDVjSSv6e95weNRvmteRjfKAuNV")
os.Setenv("VIPER_USER_SECRET_KEY", "bVix2WBv0VPfrDrvlLWrhEdzjLpPCNYb")

viper.AutomaticEnv() // 读取环境变量
viper.SetEnvPrefix("VIPER") // 设置环境变量前缀：VIPER_，如果是 viper，将自动转变为大写。
viper.SetEnvKeyReplacer(strings.NewReplacer(".", "_", "-", "_")) // 将 viper.Get(key) key 字符串中 '.' 和 '-' 替换为 '_'
viper.BindEnv("user.secret-key")
viper.BindEnv("user.secret-id", "USER_SECRET_ID") // 绑定环境变量名到 key
```

1. 使用标志

viper 支持 pflag 包，能够绑定 key 到 flag。与 `BindEnv` 类似，在调用绑定方法时，不会设置该值。但在访问它时会设置。对于单个标志，可以调用 `BindPFlag()` 进行绑定：

```Go
viper.BindPFlag("token", pflag.Lookup("token")) // 绑定单个标志
```

还可以绑定一组现有的pflags（`pflag.FlagSet`）：

```Go
viper.BindPFlags(pflag.CommandLine)             //绑定标志集
```

##### 读取配置

viper 提供了如下方法来读取配置：

- `Get(key string) interface{}`
- `Get<Type>(key string) <Type>`
- `AllSettings() map[string]interface{}`
- `IsSet(key string) bool`

每一个 `Get` 方法在找不到值的时候都会返回零值。为了检查给定的键是否存在，可以使用 `IsSet()` 方法。`<Type>` 可以是 viper 支持的类型首字母大写：`Bool`、`Float64`、`Int`、`IntSlice`、`String`、`StringMap`、`StringMapString`、`StringSlice`、`Time`、`Duration`。例如：`GetInt()`。

读取配置具体使用方法如下：

1. 访问嵌套的键

例如：加载下面的 JSON 文件：

```JSON
{
    "host": {
        "address": "localhost",
        "port": 5799
    },
    "datastore": {
        "metric": {
            "host": "127.0.0.1",
            "port": 3099
        },
        "warehouse": {
            "host": "198.0.0.1",
            "port": 2112
        }
    }
}
```

Viper可以通过传入 `.` 分隔的路径来访问嵌套字段：

```Go
viper.GetString("datastore.metric.host") // (返回 "127.0.0.1")
```

如果 `datastore.metric` 被直接赋值覆盖（被 flag，环境变量，`set()` 方法等等），那么 `datastore.metric` 的所有子键都将变为未定义状态，它们被高优先级配置级别覆盖了。

如果存在与分隔的键路径匹配的键，则直接返回其值。例如：

```Go
{
    "datastore.metric.host": "0.0.0.0",
    "host": {
        "address": "localhost",
        "port": 5799
    },
    "datastore": {
        "metric": {
            "host": "127.0.0.1",
            "port": 3099
        },
        "warehouse": {
            "host": "198.0.0.1",
            "port": 2112
        }
    }
}
```

通过 `viper.GetString` 获取值：

```Go
viper.GetString("datastore.metric.host") // 返回 "0.0.0.0"
```

1. 提取子树

例如：viper 加载了如下配置：

```YAML
app:
  cache1:
    max-items: 100
    item-size: 64
  cache2:
    max-items: 200
    item-size: 80
```

可以通过 `viper.Sub` 提取子树：

```Go
subv := viper.Sub("app.cache1")
```

`subv` 现在就代表：

```Bash
max-items: 100
item-size: 64
```

1. 反序列化

viper 可以支持将所有或特定的值解析到结构体、map 等。可以通过 2 个函数来实现：

- `Unmarshal(rawVal interface{}) error`
- `UnmarshalKey(key string, rawVal interface{}) error`

一个示例：

```Go
type config struct {
        Port int
        Name string
        PathMap string `mapstructure:"path_map"`
}

var C config

err := viper.Unmarshal(&C)
if err != nil {
        t.Fatalf("unable to decode into struct, %v", err)
}
```

如果想要解析那些键本身就包含 `.` (默认的键分隔符）的配置，则需要修改分隔符：

```Go
v := viper.NewWithOptions(viper.KeyDelimiter("::"))

v.SetDefault("chart::values", map[string]interface{}{
    "ingress": map[string]interface{}{
        "annotations": map[string]interface{}{
            "traefik.frontend.rule.type":                 "PathPrefix",
            "traefik.ingress.kubernetes.io/ssl-redirect": "true",
        },
    },
})

type config struct {
        Chart struct{
        Values map[string]interface{}
    }
}

var C config

v.Unmarshal(&C)
```

Viper 在后台使用 `github.com/mitchellh/mapstructure` 来解析值，其默认情况下使用 `mapstructure tags`。当我们需要将 viper 读取的配置反序列到我们定义的结构体变量中时，一定要使用 mapstructure tags。

1. 序列化成字符串

有时候我们需要将 viper 中保存的所有设置序列化到一个字符串中，而不是将它们写入到一个文件中，示例如下：

```Go
import (
    yaml "gopkg.in/yaml.v2"
    // ...
)

func yamlStringSettings() string {
    c := viper.AllSettings()
    bs, err := yaml.Marshal(c)
    if err != nil {
        log.Fatalf("unable to marshal config to YAML: %v", err)
    }
    return string(bs)
}
```

### 应用业务逻辑

应用的业务逻辑根据业务的不同差别很大。一般而言，一个 Go 应用中会执行以下类别的业务逻辑处理（可能会用到其中一个或多个）：

- 初始化缓存；
- 初始化并创建各类数据库客户端，例如：Redis、MySQL、Kafka、MongoDB、Etcd 等；
- 初始化并创建其他服务的客户端等；
- 初始化并启动Web服务，例如：HTTP、HTTPS、GRPC；
- 启动异步任务，这些异步任务可以执行任何业务需要的操作，例如：watch kube-apiserver、定期从第三方服务拉取数据，并缓存、注册 `/metrics` 并监听指定的端口、启动 kafka 消费队列等等；
- 执行特定的业务处理，并退出程序；
- 还有很多其他业务逻辑。

### 应用启动框架

**CLI** (Command Line Interface) 应用程序是一种在命令行环境下运行的应用程序，用户通过输入命令和参数来与应用程序交互。这种应用程序通常不具有图形界面，而是通过纯文本形式的命令来进行操作。

CLI 应用程序具有以下特点：

1. 输入输出：CLI 应用程序从命令行接受输入参数，并将结果输出到命令行。
2. 命令行参数解析：CLI 应用程序通过解析命令行参数来确定执行的操作和相应的参数。
3. 纯文本界面：CLI 应用程序通常以纯文本形式与用户进行交互，用户通过输入命令和参数来操作应用程序。
4. 脚本化和自动化：由于 CLI 应用程序可以通过脚本命令来操作，它们通常用于自动化任务和批处理作业。

在开发 CLI 应用程序时，需要考虑用户友好的命令行界面设计、命令行参数解析、错误处理以及与其他系统或服务的交互等问题。CLI 应用程序广泛应用于系统管理、工具开发、数据处理、版本控制系统（如Git）、容器管理等领域。

#### Cobra

[Cobra](https://github.com/spf13/cobra) 是一个可以创建强大的现代 CLI 应用程序的库，它还提供了一个可以生成应用和命令文件的程序的命令行工具：`cobra-cli`。有许多大型项目都是用 cobra 来构建他们的应用程序，例如：kubernetes、Docker、Etcd、Rkt、Hugo 等。Cobra 具有很多特性，一些核心特性如下：

- 可以构建基于子命令的 CLI，并支持支持嵌套子命令。例如：`app server`，`app fetch`。
- 可以通过 `cobra-cli init appname` & `cobra-cli add cmdname` 轻松生成应用和子命令。
- 智能化命令建议 (app srver... did you mean app server?)。
- 自动生成命令和标志的 help 文本，并能自动识别 `-h` ， `--help` 等标志。
- 自动为你的应用程序生成 bash、zsh、fish 和 powershell 自动补全脚本。
- 支持命令别名、自定义帮助、自定义用法等。
- 可以与 viper、pflag 紧密集成，用于构建 12-factor 应用程序。

Cobra 建立在 commands、arguments 和 flags 结构之上。commands 代表命令，arguments 代表非选项参数，flags 代表选项参数（也叫标志）。一个好的应用程序应该是易懂的，用户可以清晰的知道如何去使用这个应用程序。 应用程序通常遵循如下模式：`APPNAME VERB NOUN --ADJECTIVE` 或者 `APPNAME COMMAND ARG --FLAG`，例如：

```Go
git clone URL --bare # clone 是一个命令，URL 是一个非选项参数，bare 是一个选项参数
```

这里，`VERB` 代表动词，`NOUN` 代码名词，`ADJECTIVE` 代表形容词。

##### `cobra-cli` 命令安装

Cobra 提供了一个 `cobra-cli` 命令，用来初始化一个应用程序并为其添加命令，方便我们开发基于 Cobra 的应用。`cobra-cli` 命令安装方法如下：

```Go
$ go install github.com/spf13/cobra-cli@latest
```

`cobra-cli` 命令提供了 4 个子命令：

- `init`：初始化一个 cobra 应用程序； //自动执行
- `add`：给通过 cobra init 创建的应用程序添加子命令；
- `completion`：为指定的 shell 生成命令自动补全脚本；
- `help`：打印任意命令的帮助信息。

`cobra-cli` 命令还提供了一些全局的参数：

- `-a`, `--author`：指定 Copyright 版权声明中的作者；
- `--config`：指定 cobra 配置文件的路径；
- `-l`, `--license`：指定生成的应用程序所使用的开源协议，内置的有：GPLv2, GPLv3, LGPL, AGPL, MIT, 2-Clause BSD or 3-Clause BSD；
- `--viper`：使用 `viper` 作为命令行参数解析工具，默认为 `true`。

#### Cobra 使用方法

> 提示：请确保 Go 版本 >= `1.18`。

在构建 cobra 应用时，我们可以自行组织代码目录结构，但 cobra 建议如下目录结构：

```Go
▾ appName/
    ▾ cmd/
        add.go
        your.go
        commands.go
        here.go
      main.go
```

`main.go` 文件目的只有一个：初始化 cobra 应用：

```Go
package main

import (
  "{pathToYourApp}/cmd"
)

func main() {
  cmd.Execute() //用于执行根命令和处理用户输入的命令行参数
}
```

##### 使用 `cobra-cli` 命令生成应用程序并添加子命令

我们可以选择使用 `cobra-cli` 命令行工具，来快速生成一个应用程序，并为其添加子命令，然后基于生成的代码进行二次开发，提高开发效率，具体步骤如下：

1. 生成应用程序

可以使用 `cobra-cli init` 命令初始化一个应用程序，然后我们就可以基于这个 Demo 程序做二次开发，提高开发效率。如下命令可以初始化一个新的应用程序：

```Bash
$ mkdir -p cobrademo && cd cobrademo && go mod init
$ cobra-cli init --license=MIT --viper
$ ls
cmd  go.mod  go.sum  LICENSE  main.go
```

> 提示：如果遇到错误 `Error: invalid character '{' after top-level value)'}'`，可参考：https://github.com/spf13/cobra-cli/issues/26。

当一个应用程序被初始化之后，就可以给这个应用程序添加一些命令：

```Bash
$ cobra-cli add serve
$ cobra-cli add config
$ cobra-cli add create -p 'configCmd' # 此命令的父命令的变量名（默认为 'rootCmd'）
$ ls cmd/
config.go  create.go  root.go  serve.go
```

执行 `cobra-cli add` 之后，会在 `cmd` 目录下生成命令源码文件。`cobra-cli add` 不仅可以添加命令，也可以添加子命令，例如上面的例子，通过 `cobra-cli add create -p 'configCmd'` 给 `config` 命令添加了 `create` 子命令，`-p` 指定子命令的父命令：`<父命令>Cmd`。

1. 编译并执行

在生成完命令后，可以直接执行 `go build` 命令编译应用程序：

```Bash
$ go build -v .
$ go work use .
$ ./cobrademo -h
A longer description that spans multiple lines and likely contains
examples and usage of using your application. For example:

Cobra is a CLI library for Go that empowers applications.
This application is a tool to generate the needed files
to quickly create a Cobra application.

Usage:
  cobrademo [command]

Available Commands:
  completion  Generate the autocompletion script for the specified shell
  config      A brief description of your command
  help        Help about any command
  serve       A brief description of your command

Flags:
      --config string   config file (default is $HOME/.cobrademo.yaml)
  -h, --help            help for cobrademo
  -t, --toggle          Help message for toggle

Use "cobrademo [command] --help" for more information about a command.

$ ./cobrademo config -h
......
Usage:
  cobrademo config [flags]
  cobrademo config [command]

Available Commands:
  create      A brief description of your command

Flags:
  -h, --help   help for config

Global Flags:
      --config string   config file (default is $HOME/.cobrademo.yaml)

Use "cobrademo config [command] --help" for more information about a command.
```

这里需要注意：命令名称要是 `camelCase` 格式，而不是 `snake_case` / `snake-case` 格式，如果不是驼峰格式，cobra 会报错。

1. 配置 cobra

cobra 在生成应用程序时，也会在当前目录下生成 `LICENSE` 文件，并且会在生成的 Go 源码文件中，添加 LICENSE Header，LICENSE 和 LICENSE Header 的内容可以通过 cobra 配置文件进行配置，默认的配置文件为：`~/.cobra.yaml`，例如：

```YAML
author: Steve Francia <spf@spf13.com>
year: 2020
license:
  header: This file is part of CLI application foo.
  text: |
    {{ .copyright }}

    This is my license. There are many like it, but this one is mine.
    My license is my best friend. It is my life. I must master it as I must
    master my life.
```

在如上例子中，`{{ .copyright }}` 的具体内容会根据 `author` 和 `year` 生成，根据此配置生成的 LICENSE 文件内容为：

```Plaintext
Copyright © 2020 Steve Francia <spf@spf13.com>
 
This is my license. There are many like it, but this one is mine.
My license is my best friend. It is my life. I must master it as I must
master my life.
 
LICENSE Header为 ：
/*
Copyright © 2020 Steve Francia <spf@spf13.com>
This file is part of CLI application foo.
*/
```

我们也可以使用内建的 licenses，内建的 licenses 有：GPLv2, GPLv3, LGPL, AGPL, MIT, 2-Clause BSD or 3-Clause BSD。例如，我们使用 MIT license：

```Bash
$ cobra-cli init --license=MIT
```

##### 使用 cobra 库创建命令

如果要用 cobra 库编码实现一个应用程序，需要首选创建一个空的 `main.go` 文件和一个 rootCmd 文件，之后可以根据需要添加其它命令。具体步骤如下；

1. 创建 rootCmd ( internal/miniblog/miniblog.go)

```Go
var rootCmd = &cobra.Command{
        Use:   "hugo",
        Short: "Hugo is a very fast static site generator",
        Long: `A Fast and Flexible Static Site Generator built with
         love by spf13 and friends in Go.
                                 Complete documentation is available at http://hugo.spf13.com`,
        Run: func(cmd *cobra.Command, args []string) {
                // Do Stuff Here
        },
}

func Execute() {
        if err := rootCmd.Execute(); err != nil { //rootCmd.Execute() 是 Cobra 库中的一个方法，它用于执行根命令和处理用户输入的命令行参数。 执行这个应用程序时，Cobra 库会解析命令行参数，并执行根命令的 Run 方法
                fmt.Println(err)
                os.Exit(1)
        }
}
```

还可以在 `init()` 函数中定义标志和处理配置，例如：internal/miniblog/helper.go

```Go
var (
        cfgFile     string
        projectBase string
        userLicense string
)

func init() {  //init函数会自动执行
        cobra.OnInitialize(initConfig) //cobra.OnInitialize() 方法接受一个函数作为参数，并将该函数设置为初始化函数。该初始化函数将在根命令执行之前被调用，因此它是应用程序的入口点之一。
        rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $HOME/.cobra.yaml)")
        rootCmd.PersistentFlags().StringVarP(&projectBase, "projectbase", "b", "", "base project directory eg. github.com/spf13/")
        rootCmd.PersistentFlags().StringP("author", "a", "YOUR NAME", "Author name for copyright attribution")
        rootCmd.PersistentFlags().StringVarP(&userLicense, "license", "l", "", "Name of license for the project (can provide `licensetext` in config)")
        rootCmd.PersistentFlags().Bool("viper", true, "Use Viper for configuration")
        viper.BindPFlag("author", rootCmd.PersistentFlags().Lookup("author"))
        viper.BindPFlag("projectbase", rootCmd.PersistentFlags().Lookup("projectbase"))
        viper.BindPFlag("useViper", rootCmd.PersistentFlags().Lookup("viper"))
        viper.SetDefault("author", "NAME HERE <EMAIL ADDRESS>")
        viper.SetDefault("license", "apache")
}

func initConfig() {
        // Don't forget to read config either from cfgFile or from home directory!
        if cfgFile != "" {
                // Use config file from the flag.
                viper.SetConfigFile(cfgFile)
        } else {
                // Find home directory.
                home, err := homedir.Dir()
                if err != nil {
                        fmt.Println(err)
                        os.Exit(1)
                }

                // Search config in home directory with name ".cobra" (without extension).
                viper.AddConfigPath(home)
                viper.SetConfigName(".cobra")
        }

        if err := viper.ReadInConfig(); err != nil {
                fmt.Println("Can't read config:", err)
                os.Exit(1)
        }
}
```

1. 创建 `main.go` (cmd / myblog / main.go)

我们还需要一个 main 函数来 调用 rootCmd，通常我们会创建一个 `main.go` 文件，在 `main.go` 中调用 `rootCmd.Execute()` 来执行命令：

```Go
package main

import (
  "{pathToYourApp}/cmd"
)

func main() {
  cmd.Execute()
}
```

需要注意，`main.go` 中不建议放很多代码，通常只需要调用 `cmd.Execute()` 即可。

1. 添加命令

除了 `rootCmd`，我们还可以调用 `AddCommand` 添加其它命令，通常情况下，我们会把其它命令的源码文件放在 `cmd/` 目录下，例如，我们添加一个 `version` 命令，可以创建 `cmd/version.go` 文件，内容为：

```Go
func init() {
        rootCmd.AddCommand(versionCmd)
}

var versionCmd = &cobra.Command{
        Use:   "version",
        Short: "Print the version number of Hugo",
        Long:  `All software has versions. This is Hugo's`,
        Run: func(cmd *cobra.Command, args []string) {
                fmt.Println("Hugo Static Site Generator v0.9 -- HEAD")
        },
}
```

本示例中，我们通过调用 `rootCmd.AddCommand(versionCmd)` 给 `rootCmd` 命令添加了一个 `versionCmd` 命令。

1. 编译并运行

替换 `main.go` 中 `{pathToYourApp}` 为对应的路径，

```Plaintext
$ go build -v .
$ ./myblog -h
```

通过步骤 1、2、3 我们就成功创建 cobra 应用程序和添加了命令。

```Shell
//使用命令示例
var rootCmd = &cobra.Command{
        Use:   "myapp",
        Short: "A brief description of your application",
        Long:  "A longer description of your application",
        Run: func(cmd *cobra.Command, args []string) {
                fmt.Println("Hello, this is the root command!")
        },
}
var subCmd = &cobra.Command{
        Use:   "sub",
        Short: "A brief description of the sub command",
        Run: func(cmd *cobra.Command, args []string) {
                fmt.Println("Hello, this is the sub command!")
        },
}

func init() {
        rootCmd.AddCommand(subCmd)
}

func main() {
        if err := rootCmd.Execute(); err != nil {
                fmt.Println(err)
                os.Exit(1)
        }
}

$ go build -o myapp main.go
$ ./myapp
Hello, this is the root command!
$ ./myapp sub
Hello, this is the sub command!
```

#### 使用标志

cobra 可以跟 pflag 结合使用，实现强大的标志功能。使用步骤如下：

1. 使用持久化的标志

标志可以是“持久的”，这意味着该标志可用于它所分配的命令以及该命令下的每个子命令。可以在 `rootCmd` 上定义持久标志：

```Go
rootCmd.PersistentFlags().BoolVarP(&Verbose, "verbose", "v", false, "verbose output")
```

1. 使用本地标志

也可以分配一个本地标志，本地标志只能在其所绑定的命令上使用：

```Go
rootCmd.Flags().StringVarP(&Source, "source", "s", "", "Source directory to read from")
```

`--source` 标志只能在 `rootCmd` 上引用，而不能在 `rootCmd` 的子命令上引用。

1. 将标志绑定到 viper

我们可以将标志绑定到 viper，这样就可以使用 `viper.Get()` 获取标志的值。

```Go
var author string

func init() {
  rootCmd.PersistentFlags().StringVar(&author, "author", "YOUR NAME", "Author name for copyright attribution")
  viper.BindPFlag("author", rootCmd.PersistentFlags().Lookup("author"))
}
```

1. 设置标志为必选

默认情况下，标志是可选的，我们也可以设置标志位必选，当设置标志位必选，但是没有提供标志时，cobra 会报错。

```Go
rootCmd.Flags().StringVarP(&Region, "region", "r", "", "AWS region (required)")
rootCmd.MarkFlagRequired("region")
```

1. 非选项参数验证

在使用命令的过程中，经常会传入非选项参数，并且需要对这些非选项参数进行验证，cobra 提供了机制来对非选项参数进行验证。可以使用 `Command` 的 `Args` 字段来验证非选项参数。cobra 也内置了一些验证函数，具体见下表：

| 函数                | 描述                                                         |
| ------------------- | ------------------------------------------------------------ |
| NoArgs              | 如果存在任何非选项参数，该命令将报错                         |
| ArbitraryArgs       | 该命令将接受任何非选项参数                                   |
| OnlyValidArgs       | 如果有任何非选项参数不在 `Command` 的 `ValidArgs` 字段中，该命令将报错 |
| MinimumNArgs(int)   | 如果没有至少 N 个非选项参数，该命令将报错                    |
| MaximumNArgs(int)   | 如果有多于 N 个非选项参数，该命令将报错                      |
| ExactArgs(int)      | 如果非选项参数个数不为 N，该命令将报错                       |
| ExactValidArgs(int) | 如果非选项参数的个数不为 N，或者非选项参数不在 `Command` 的 `ValidArgs` 字段中，该命令将报错 |
| RangeArgs(min, max) | 如果非选项参数的个数不在 `min` 和 `max` 之间，该命令将报错   |

使用自定义验证函数，示例如下：

```Go
var cmd = &cobra.Command{
  Short: "hello",
  Args: cobra.MinimumNArgs(1), // 使用内置的验证函数
  Run: func(cmd *cobra.Command, args []string) {
    fmt.Println("Hello, World!")
  },
}
```

也可以自定义验证函数，示例如下：

```Go
var cmd = &cobra.Command{
  Short: "hello",
  // Args: cobra.MinimumNArgs(10), // 使用内置的验证函数
  Args: func(cmd *cobra.Command, args []string) error { // 自定义验证函数
    if len(args) < 1 {
      return errors.New("requires at least one arg")
    }
    if myapp.IsValidColor(args[0]) {
      return nil
    }
    return fmt.Errorf("invalid color specified: %s", args[0])
  },
  Run: func(cmd *cobra.Command, args []string) {
    fmt.Println("Hello, World!")
  },
}
```

#### Help命令

在使用应用程序时，我们需要知道该应用程序的调用方法，所以需要有一个 Help 命令或者选项参数，Cobra 的强大之处也在于所有我们需要的功能 cobra 都已经帮我们实现好了。

在用 cobra 构建应用程序时，cobra 会自动为应用程序添加一个帮助命令，当用户运行 `app help` 时会调用此方法。

此外，当 `help` 的输入为其它命令时，会打印该命令的用法，比如有一个叫做 `create` 的命令，当调用 `app help create` 时，会打印 `create` 的帮助信息。

cobra 也会给每个命令自动添加 `--help` 标志。例如：

```Bash
$ cobra-cli help
Cobra is a CLI library for Go that empowers applications.
This application is a tool to generate the needed files
to quickly create a Cobra application.

Usage:
  cobra-cli [command]

Available Commands:
  add         Add a command to a Cobra Application
  completion  Generate the autocompletion script for the specified shell
  help        Help about any command
  init        Initialize a Cobra Application

Flags:
  -a, --author string    author name for copyright attribution (default "YOUR NAME")
      --config string    config file (default is $HOME/.cobra.yaml)
  -h, --help             help for cobra-cli
  -l, --license string   name of license for the project
      --viper            use Viper for configuration

Use "cobra-cli [command] --help" for more information about a command.
```

我们也可以定义自己的 `help` 命令。使用如下函数，可以定义 `help` 命令：

```Go
cmd.SetHelpCommand(cmd *Command)
cmd.SetHelpFunc(f func(*Command, []string))
cmd.SetHelpTemplate(s string)
```

#### 使用信息

当用户提供无效标志或无效命令时，cobra 会打印出 usage 信息。例如：

```Bash
$ cobra-cli --invalid
Error: unknown flag: --invalid
Usage:
  cobra-cli [command]

Available Commands:
  add         Add a command to a Cobra Application
  completion  Generate the autocompletion script for the specified shell
  help        Help about any command
  init        Initialize a Cobra Application

Flags:
  -a, --author string    author name for copyright attribution (default "YOUR NAME")
      --config string    config file (default is $HOME/.cobra.yaml)
  -h, --help             help for cobra-cli
  -l, --license string   name of license for the project
      --viper            use Viper for configuration

Use "cobra-cli [command] --help" for more information about a command.
```

像 `help` 一样，我们也可以自定义 usage，通过如下看函数可以自定义 usage：

```Go
cmd.SetUsageFunc(f func(*Command) error)
cmd.SetUsageTemplate(s string)
```

#### version 标志

如果在 `rootCmd` 命令上设置了 `Version` 字段，Cobra 会添加持久的 `--version` 标志。 运行应用程序时，指定了 `--version` 标志，应用程序会使用 `Version` 模板将版本打印到 stdout。可以使用 `cmd.SetVersionTemplate(s string)` 函数自定义 `Version` 模板。

#### PreRun and PostRun Hooks

在运行 `Run` 函数时我们可以运行一些钩子函数，比如 `PersistentPreRun` 和 `PreRun` 函数在 `Run` 函数之前执行。`PersistentPostRun` 和 `PostRun` 在 `Run` 函数之后执行。如果子命令没有指定 `Persistent*Run` 函数，则子命令将会继承父命令的 `Persistent*Run` 函数。这些函数的运行顺序如下：

1. `PersistentPreRun`
2. `PreRun`
3. `Run`
4. `PostRun`
5. `PersistentPostRun`

注意父级的 `PreRun` 只会在父级命令运行时调用，子命令时不会调用的。

下面是使用所有这些函数的两个命令的示例。执行子命令时，它将运行 `rootCmd` 命令的 `PersistentPreRun`，但不运行 `rootCmd` 命令的 `PersistentPostRun`：

```Go
func main() {

  var rootCmd = &cobra.Command{
    Use:   "root [sub]",
    Short: "My root command",
    PersistentPreRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside rootCmd PersistentPreRun with args: %v\n", args)
    },
    PreRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside rootCmd PreRun with args: %v\n", args)
    },
    Run: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside rootCmd Run with args: %v\n", args)
    },
    PostRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside rootCmd PostRun with args: %v\n", args)
    },
    PersistentPostRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside rootCmd PersistentPostRun with args: %v\n", args)
    },
  }

  var subCmd = &cobra.Command{
    Use:   "sub [no options!]",
    Short: "My subcommand",
    PreRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside subCmd PreRun with args: %v\n", args)
    },
    Run: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside subCmd Run with args: %v\n", args)
    },
    PostRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside subCmd PostRun with args: %v\n", args)
    },
    PersistentPostRun: func(cmd *cobra.Command, args []string) {
      fmt.Printf("Inside subCmd PersistentPostRun with args: %v\n", args)
    },
  }

  rootCmd.AddCommand(subCmd)

  rootCmd.SetArgs([]string{""})
  rootCmd.Execute()
  fmt.Println()
  rootCmd.SetArgs([]string{"sub", "arg1", "arg2"})
  rootCmd.Execute()
}
```

执行后，输出如下：

```Bash
Inside rootCmd PersistentPreRun with args: []
Inside rootCmd PreRun with args: []
Inside rootCmd Run with args: []
Inside rootCmd PostRun with args: []
Inside rootCmd PersistentPostRun with args: []

Inside rootCmd PersistentPreRun with args: [arg1 arg2]
Inside subCmd PreRun with args: [arg1 arg2]
Inside subCmd Run with args: [arg1 arg2]
Inside subCmd PostRun with args: [arg1 arg2]
Inside subCmd PersistentPostRun with args: [arg1 arg2]
```

#### 命令建议

Cobra 还有很多其它有用的特性，比如当我们输入的命令有误时，cobra 会根据注册的命令，推算出可能的命令。例如，当 `unknown command` 错误发生时，Cobra 将自动打印建议的命令:

```Bash
$ hugo srever
Error: unknown command "srever" for "hugo"

Did you mean this?
        server

Run 'hugo --help' for usage.
```

根据注册的每个子命令自动建议并使用 Levenshtein distance 实现。每个匹配最小距离为 2（忽略大小写）的注册命令将显示为建议。如果需要在命令中禁用建议或调整字符串距离，可以使用：

```Go
command.DisableSuggestions = true
```

或者：

```Go
command.SuggestionsMinimumDistance = 1
```

需要注意，Levenshtein distance（编辑距离）是针对二个字符串（例如英文字）的差异程度的量化量测，量测方式是看至少需要多少次的处理才能将一个字符串变成另一个字符串。

还可以使用 `SuggestFor` 属性显式设置要为其指定命令的名称，例如：

```Go
// configCmd represents the config command
var configCmd = &cobra.Command{
    Use:   "config",
    Short: "A brief description of your command",
    Long: `A longer description that spans multiple lines and likely contains examples
and usage of using your command. For example:

Cobra is a CLI library for Go that empowers applications.
This application is a tool to generate the needed files
to quickly create a Cobra application.`,
    SuggestFor: []string{"cfg", "conf"},
    Run: func(cmd *cobra.Command, args []string) {
        fmt.Println("config called")
    },
}
```

执行 `newApp cfg`：

```Bash
$ ./newApp cfg
Error: unknown command "cfg" for "newApp"

Did you mean this?
        config

Run 'newApp --help' for usage.
unknown command "cfg" for "newApp"

Did you mean this?
        config
```

------

## Git

![Git-Cheet-Sheet-ByGeekHour](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152031881.png)

![GitCheatSheet_byGeekHour_v1.0.0](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152030724.png)

### 介绍

Git是一种分布式版本控制系统，用于跟踪文件的更改，特别是源代码的更改。它由Linus Torvalds于2005年开发，最初用于管理Linux内核的开发。下面是对Git的详细介绍：

Git的核心概念

1. **版本库 (Repository)**：存储项目文件及其历史版本的数据库。可以是本地版本库（在你自己的电脑上）或远程版本库（例如在GitHub、GitLab等平台上）。
2. **分支 (Branch)**：一个独立的开发线索。Git允许你在同一项目中创建多个分支，每个分支可以独立开发，不会影响其他分支。
3. **提交 (Commit)**：对文件的改动快照。每次提交都会记录文件的当前状态，并附加提交信息。
4. **工作区 (Working Directory)**：当前正在编辑的项目文件。
5. **暂存区 (Staging Area)**：保存即将提交到版本库的更改快照。

Git的高级操作

1. **解决冲突**：当多个分支修改了同一文件的同一部分时，会产生冲突。Git会标记冲突，用户需要手动解决并提交解决方案。
2. **Git 分支管理**：使用 `git branch` 查看所有分支，使用 `git branch -d <branch_name>` 删除分支。
3. **Git 标签 (Tag)**：用于标记特定的提交，例如发布版本。使用 `git tag <tag_name>` 创建标签。
4. **Git 重置 (Reset)**：用于撤销更改。`git reset` 可以将当前分支重置到指定的提交。
5. **Git 交互式重置 (Interactive Rebase)**：用于编辑提交历史，例如修改提交信息、合并提交等。

Git的协作工作流

1. **Fork and Pull Request**：在GitHub等平台上，用户可以fork一个仓库，在自己的仓库中做更改，然后通过pull request请求将更改合并到原始仓库。
2. **Feature Branch**：每个新功能都在一个独立的分支上开发，完成后合并到主分支。
3. **Git Flow**：一种常见的分支管理策略，包括长期存在的主分支和开发分支，以及短期存在的功能分支、发布分支和修补分支。
4. 

### Commit规范

`gitlint` 工具来保证 Commit 规范

`Conventional Commits`（约定俗成的提交）规范是一份针对代码提交信息的轻量级约定。这份规范提供了一组简单的规则用于创建一份明确的代码提交的历史记录，并且方便在此基础之上做一些自动化的工具。这份约定描述了代码提交中带来的功能特性、修复和不兼容性更改，与 [SemVer（语义化版本）](https://semver.org/)是相吻合的。

代码提交记录应该有如下结构：

```Plaintext
<type>[optional scope]: <description>

[optional body]

[optional footer(s)]
```

其中，`<type>` 表示代码提交的类型，可以是以下之一：

- `feat`: 新功能（feature）
- `fix`: 修复 Bug
- `docs`: 文档更新
- `style`: 代码格式（不影响功能）
- `refactor`: 重构代码
- `test`: 添加或修改测试代码
- `chore`: 构建过程或辅助工具的变动
- `perf`: 改进性能的代码更改

`<scope>` 表示本次提交影响的范围，可以是文件路径、模块名称等。`<subject>` 是本次提交的简短描述，通常不超过50个字符。

`<body>` 是对本次提交的详细描述，可以包含更多细节、原因和解决方案等信息。

`<footer>` 可以包含一些额外的信息，比如关联的问题或缺陷编号。

1. **Fixes**: 用于表示当前提交修复了某个问题或缺陷。例如：`Fixes #123`
2. **Closes**: 用于表示当前提交关闭了某个问题或缺陷。例如：`Closes #456`
3. **Resolves**: 用于表示当前提交解决了某个问题或缺陷。例如：`Resolves #789`

一个示例的 Commit 规范如下：

```Plaintext
feat(users): add password reset feature

Added a new password reset feature for users. Users can now reset their passwords via email links.

- Updated user service to handle password reset logic.
- Added password reset email template.

Closes #123
```

### Git配置

1.查看配置

 git config -l 查看不同级别的配置文件：

```PHP
#查看系统config
git config --system --list
#查看当前用户（global）配置
git config --global  --list
```

2.Git相关的配置文件

1）、Git\etc\gitconfig ：Git 安装目录下的 gitconfig --system 系统级 

2）、C:\Users\to'm.gitconfig 只适用于当前登录用户的配置 --global 全局

![202407091901786](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111556260.png)

可以直接编辑配置文件，通过命令设置后会响应到这里。



设置用户名与邮箱

当你安装Git后首先要做的事情是设置你的用户名称和e-mail地址。这是非常重要的，因为每次Git提交都会使用该信息。它被永远的嵌入到了你的提交中：

```C#
git config --global user.name "kuangshen"  #名称
git config --global user.email 24736743@qq.com   #邮箱
```

![QQ_1721046500313](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152028632.png)

### Git基本理论（重要）

#### 三个区域

Git本地有三个工作区域：工作目录（Working Directory）、暂存区(Stage/Index)、资源库(Repository或Git Directory)。如果在加上远程的git仓库(Remote Directory)就可以分为四个工作区域。文件在这四个区域之间的转换关系如下：

![202407092224328](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111557410.png)

- Workspace：工作区，就是你平时存放项目代码的地方
- Index / Stage：暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息
- Repository：仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本
- Remote：远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换

本地的三个区域确切的说应该是git仓库中HEAD指向的版本：

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111557726.png" alt="202407092224570" style="zoom:33%;" />

- Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。
- WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。
- .git：存放Git管理信息的目录，初始化仓库的时候自动创建。
- Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。
- Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。
- Stash：隐藏，是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。

#### 工作流程

git的工作流程一般是这样的：

１、在工作目录中添加、修改文件；

２、将需要进行版本管理的文件放入暂存区域；

３、将暂存区域的文件提交到git仓库。

因此，git管理的文件有三种状态：已修改（modified）,已暂存（staged）,已提交(committed)

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111557218.png" alt="202407092225665" style="zoom:50%;" />





### Git文件操作

#### 文件的四种状态

版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。

- Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add 状态变为Staged.
- Unmodify: 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为Modified. 如果使用git rm移出版本库, 则成为Untracked文件
- Modified: 文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过, 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 !
- Staged: 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态. 执行git reset HEAD filename取消暂存, 文件状态为Modified

#### 查看文件状态

上面说文件有4种状态，通过如下命令可以查看到文件的状态：

```Plaintext
#查看指定文件状态
git status [filename]
#查看所有文件状态
git status
# git add .                  添加所有文件到暂存区
# git commit -m "消息内容"    提交暂存区中的内容到本地仓库 -m 提交信息
```

#### 忽略文件

模版：[github/gitignore: A collection of useful .gitignore templates](https://github.com/github/gitignore)

有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等

在主目录下建立".gitignore"文件，此文件有如下规则：

1. 如果文件已经添加，那么.gitignore不会生效
2. 默认忽略空文件夹
3. 忽略文件中的空行或以井号（#）开始的行将会被忽略。
4. 可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,...}）代表可选的字符串等。
5. 如果名称的最前面有一个感叹号（!），表示例外规则，**将不被忽略。**
6. 如果名称的最前面是一个路径分隔符（/），表
7. 示要忽略的文件在此目录下，而子目录中的文件不忽略。
8. 如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。

```Bash
#为注释
*.txt        #忽略所有 .txt结尾的文件,这样的话上传就不会被选中！
!lib.txt     #但lib.txt除外
/temp        #仅忽略项目根目录下的TODO文件,不包括其它目录temp
build/       #忽略build/目录下的所有文件
doc/*.txt    #会忽略 doc/notes.txt 但不包括 doc/server/arch.txt
```

### 操作

![202407092225245](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111558206.png)

#### GIT分支





```Shell
#在当前目录新建一个Git代码库
git init
git clone url
#--mirror 可以克隆所有分支：

git remote add origin <remote_repository_url>


#显示本地仓库和远程仓库中所有的分支列表
git branch -a

# 列出所有本地分支
git branch
# 列出所有远程分支
git branch -r

git stash   # 暂存您的更改       切换分支之前有未提交的更改或者还未保存的文件更改。Git 不允许您在切换分支时保留未提交的更                                     改，以防止意外覆盖或冲突。
#切换分支
git checkout main
git switch main

# 新建一个分支，但依然停留在当前分支
git branch [branch-name]
# 新建一个分支，并切换到该分支
git checkout -b [branch]

#新建一个远程分支
git checkout -b new-feature #创建一个新的本地分支并切换到该分支：
git add .   
git commit -m "添加新功能"  
git push origin new-feature

# 合并指定分支到当前分支
$ git merge [branch]
#变基 rebase  改变当前分支到指定分支   从两分支的公共交点处更改
git rebase <branch>


# 删除分支
$ git branch -d [branch-name]
# 删除远程分支
$ git push origin --delete [branch-name] //远程仓库中永久删除一个分支
#只删除本地仓库中的远程跟踪分支（不影响远程仓库的实际分支）
$ git branch -dr [remote/branch] 
```

![202407092225857](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111900870.png)

![202407092226910](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111900415.png)

IDEA中操作

![202407092226407](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111900898.png)

如果同一个文件在合并分支时都被修改了则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！

master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。



#### 推送

git clone命令执行后，您就已经建立了与远程仓库的连接

```Shell
#`origin` 是远程仓库的别名，您可以根据需要自定义别名。
git remote add origin <remote_repository_url>

要查看Git远程仓库的信息
git remote -v
特定远程仓库的详细信息
git remote show <remote_name>
```

推送到远程仓库：使用以下命令将本地分支的更改推送到远程仓库：

```Plaintext
git push -u origin <branch_name>
```

1. 将 `<branch_name>` 替换为要推送的分支的名称，通常是主分支（如 `main` 或 `master`）。

2. `-u` 参数将本地分支与远程分支关联，这样以后的推送可以简化为 `git push`。



#### 拉取

git config --global http.proxy http://127.0.0.1:2313

git config --global https.proxy https://127.0.0.1:2314

##### git pull

1.在拉取更新时自动与当前本地分支进行合并，可以使用 `git pull` 命令：

```Bash
git pull origin <branch-name>
```

上述命令**等价于 `git fetch` 和 `git merge` 的组合**操作，会自动拉取更新并尝试进行合并。

##### git fetch

2.要从远程仓库拉取分支（包括新分支或更新的分支），可以使用以下命令：

```Bash
git fetch origin <branch-name>
```

执行上述命令后，Git 会将远程仓库中指定分支的最新状态拉取到本地仓库中，

请注意，使用 `git fetch` **不会影响当前工作目录中的文件，只会更新本地仓库中的远程跟踪分支**。如果需要将远程分支的更改应用到当前工作目录中，请执行合并或拉取操作。

##### git merge

3.如果您想将远程分支的更新合并到当前本地分支，可以使用以下命令：

```Bash
git merge origin/<branch-name>
```

假如要使用 `--force` 推送时，要小心，因为**这会覆盖远程仓库中的历史记录。**



##### 冲突

拉取遇到冲突

1. 手动合并
2. vscode好用一点，可以目录shift多选一次合并多个



| 特点     | `git merge`                          | `git rebase`                     |
| -------- | ------------------------------------ | -------------------------------- |
| 历史记录 | 保留所有分支的提交历史，带有合并节点 | 线性化历史，没有合并节点         |
| 合并提交 | 会创建一个合并提交                   | 没有合并提交                     |
| 使用场景 | 需要保留分支历史，显示分支合并点     | 希望线性化历史，避免合并节点     |
| 适用对象 | 任何分支                             | 私有分支（避免在公共分支上变基） |

建议

- 如果你希望保留清晰的分支合并过程，并且多个开发者都可能需要回溯历史，那么使用 `merge`。
- 如果你想要一个干净、线性的历史，并且你在处理的是一个特性分支或私有分支，使用 `rebase`。



#### 回退

#####  git reflog和git log --oneline

**查看 commit 历史**

**`git reflog`**：显示所有本地 Git 操作的记录（包括丢弃的、重置的、移动分支等操作），便于恢复误操作。

**`git log --oneline`**：显示当前分支的提交历史，以简洁的方式展示提交记录。



##### git reset

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152044648.png" alt="QQ_1721047469278" style="zoom: 33%;" />

如果本地工作区文件落后，直接 --hard删除本地文件，再拉取就不会冲突

**误使用hard命令， reflog找到版本号，再使用reset回退**

```bash
#回退到某个 commit，但保留当前代码不变
git reset --soft <commit_hash>  
git push --force

#重置到指定的 commit，并丢弃所有的更改。
git reset --hard <commit_hash>


#回退到上一个 commit
git reset --hard HEAD^
```

注意

- `git reset --soft` 只会回退提交记录，保留代码的当前状态。如果你想要回退提交并丢弃代码更改，应该使用 `--hard` 选项（谨慎使用）。
- 使用 `--force` 推送时，要小心，因为这会覆盖远程仓库中的历史记录。

##### head

HEAD表示最新的提交id  

HEAD~/HEAD^上一个提交id

HEAD~3 之前的3个版本





#### 删除

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152103051.png" alt="QQ_1721048572955" style="zoom:50%;" />



#### 暂存本地更改

如果你不想提交这些更改，可以先暂存本地的更改，然后拉取远程更新：

```Plaintext
git stash
```

#### git diff

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152052981.png" alt="QQ_1721047976230" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152059986.png" alt="QQ_1721048365894" style="zoom:50%;" />

### 同类产品比较

<img src="https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407152018459.png" alt="QQ_1721045902436" style="zoom:50%;" />

------

## Air

安装 air 工具。

```Ruby
go install github.com/cosmtrek/air@latest
```

配置 air 工具。

这里我们使用 air 官方仓库中给出的示例配置：[air_example.toml](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fcosmtrek%2Fair%2Fblob%2Fmaster%2Fair_example.toml)。`air_example.toml` 里面的示例配置基本能满足绝大部分的项目需求，一般只需要再配置 `cmd`、`bin`、`args_bin` 3 个参数即可。

在 miniblog 项目根目录下创建 `.air.toml` 文件，内容见 [.air.toml](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs01%2F.air.toml)。

`.air.toml` 基于 `air_example.toml` 文件修改了以下参数配置：

```Plaintext
# 只需要写你平常编译使用的 shell 命令。你也可以使用 `make`.
cmd = "make build"
#cmd = "go build -o _output/myblog -v cmd/myblog/main.go"
# 由 `cmd` 命令得到的二进制文件名.
bin = "_output/miniblog"
# Customize binary, can setup environment variables when run your app.
full_bin = "APP_ENV=dev APP_USER=air ./_output/myblog"
```

参数介绍：

- `cmd`：指定了监听文件有变化时，air 需要执行的命令，这里指定了 `make build` 重新构建 `miniblog` 二进制文件；
- `bin`：指定了执行完 `cmd` 命令后，执行的二进制文件，这里指定了编译构建后的二进制文件 `_output/miniblog`。

（可选）使用 `-c` 选项来指定其他配置文件，例如：`air -c .air.toml`。

运行 `air` 命令，配置应用程序的运行和监视设置

**支持使用参数来配置 air 字段:**

如果你只是想配置构建命令和运行命令，您可以直接使用以下命令，而无需配置文件:

```Plaintext
air --build.cmd "go build -o bin/api cmd/run.go" --build.bin "./bin/api"
```

对于以列表形式输入的参数，使用逗号来分隔项目:

```Plaintext
air --build.cmd "go build -o bin/api cmd/run.go" --build.bin "./bin/api" --build.exclude_dir "templates,build"
```

**运行时参数**

您可以通过把变量添加在 air 命令之后来传递参数。

```Shell
# 会执行 ./tmp/main bench
air bench

# 会执行 ./tmp/main server --port 8080
air server --port 8080
```

## [OpenAPI 3.0](https://link.juejin.cn/?target=https%3A%2F%2Fspec.openapis.org%2Foas%2Flatest.html)/Swagger 2.0

### 介绍

Swagger 是一组围绕 OpenAPI 规范构建的开源工具，可以帮助我们设计、构建、记录和使用 REST API。Swagger 不仅可以帮助我们设计和记录 REST API，还可以让我们构建（服务器存根）和使用（REST 客户端）REST API。主要的 Swagger 工具包括：

- [Swagger Editor](https://link.juejin.cn/?target=https%3A%2F%2Feditor-next.swagger.io%2F)：基于浏览器的编辑器，可以在其中编写 OpenAPI 规范；
- [Swagger UI](https://link.juejin.cn/?target=https%3A%2F%2Fswagger.io%2Ftools%2Fswagger-ui%2F)：将 OpenAPI 规范呈现为交互式 API 文档；
- [Swagger Codegen](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fswagger-api%2Fswagger-codegen)：根据 OpenAPI 规范生成服务器存根和客户端库。

Swagger 是一组围绕 OpenAPI 规范构建的开源工具，可以帮助我们设计、构建、记录和使用 REST API。Swagger 不仅可以帮助我们设计和记录 REST API，还可以让我们构建（服务器存根）和使用（REST 客户端）REST API。主要的 Swagger 工具包括：

- [Swagger Editor](https://link.juejin.cn/?target=https%3A%2F%2Feditor-next.swagger.io%2F)：基于浏览器的编辑器，可以在其中编写 OpenAPI 规范；
- [Swagger UI](https://link.juejin.cn/?target=https%3A%2F%2Fswagger.io%2Ftools%2Fswagger-ui%2F)：将 OpenAPI 规范呈现为交互式 API 文档；
- [Swagger Codegen](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fswagger-api%2Fswagger-codegen)：根据 OpenAPI 规范生成服务器存根和客户端库。

### API 文档编写工具

如果采用 OpenAPI 规范，你可以采用以下 3 种 API 文档编写方式：

- 基于本地编辑器 / IDE 编写 YAML 格式的 OpenAPI 文档；
- 基于 [Swagger Editor](https://link.juejin.cn/?target=https%3A%2F%2Feditor-next.swagger.io%2F) 编写 OpenAPI 文档；
- 基于 [Swagger Hub](https://link.juejin.cn/?target=https%3A%2F%2Fswagger.io%2Ftools%2Fswaggerhub%2F) 编写 OpenAPI 文档；
- 基于代码标注生成 OpenAPI 文档，例如：

![202407092231431](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111909026.webp)

> 提示：SwaggerHub 是一个 API 设计和文档平台，为团队打造，以推动其 API 开发工作流程的一致性和规范性。

推荐编写方法：

- 如果 API 接口文档可以暴露在 SwaggerHub 平台，建议基于 SwaggerHub 平台来编写，因为 SwaggerHub 平台具备 API 编辑、展示、Mock、保存等功能，并能很方便地进行 API 共享。
- 如果 API 接口文档比较敏感，则可以基于本地编辑器编辑，并将 API 接口文档粘贴在 [Swagger Editor](https://link.juejin.cn/?target=https%3A%2F%2Feditor-next.swagger.io%2F) 进行正确性校验。
- 不建议基于代码标注生成，因为基于代码标注生成，往往说明接口实现已经开发好，再基于接口生成 API 文档，违反接口定义先行的原则，不利于并行开发以提高开发效率；
- 文档编写工具也在不断发展，如果你有更好编辑方式，也可以采用。

### miniblog API 文档编写和展示

因为 OpenAPI 文档内容比较多，并且网上有很多易读的文档，所以本课程不再介绍，具体语法可参考官方文档进行学习：[OpenAPI Specification](https://link.juejin.cn/?target=https%3A%2F%2Fspec.openapis.org%2Foas%2Flatest.html)（一个不错的中文翻译文档：[开放 API 规范中文翻译](https://link.juejin.cn/?target=https%3A%2F%2Ffishead.gitbook.io%2Fopenapi-specification-zhcn-translation%2F3.0.0.zhcn)）。

无需从零编写 OpenAPI 文档，可以基于模板进行修改编写，步骤如下：

1. 打开 [Swagger Editor](https://link.juejin.cn/?target=https%3A%2F%2Feditor-next.swagger.io%2F) 在线编辑器；
2. 选择 **Edit** -> **Load OpenAPI 3.0 Petstore Fixture**，载入 **Swagger Petstore** 文档模板，
3. 为了防止在线编辑内容丢失，可以选择 **File** -> **Save (as YAML)** 将模板保存在本地，使用本地编辑器进行编辑；
4. 编辑之后，可以将内容粘贴在 Swagger Editor 中以检查文档是否正确。

### 在线展示

1. 安装 swagger 工具，安装命令如下：

```Go
go
复制代码$ go install github.com/go-swagger/go-swagger/cmd/swagger@latest
```

1. 运行 swagger 命令：

```Bash
bash复制代码$ swagger serve -F=swagger --no-open --port 65534 ./api/openapi/openapi.yaml
2022/11/22 21:19:49 serving docs at http://localhost:65534/docs
```

1. 在浏览器中打开 `http://localhost:65534/docs`，效果如下图所示：

![202407092228444](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111910372.webp)

这里需要注意：使用 `swagger serve` 渲染 OpenAPI 文档需要确保 OpenAPI 文档版本为：`swagger: "2.0"`，例如：

```YAML
yaml复制代码swagger: "2.0"
servers:
  - url: http://127.0.0.1:8080/v1
    description: development server
info:
  version: "1.0.0"
  title: miniblog api definition
```

否则 `swagger serve` 命令会渲染失败。

编写后的 OpenAPI 文档需要根据目录规范存放在：`api/openapi` 目录下。

## 版权声明

### 添加 `LICENSE` 文件

如果你的项目是一个开源项目或者未来准备开源，那么还需要给项目添加一些版权声明，主要包括：

1. 存放在项目根目录下的 `LICENSE` 文件，用来声明项目遵循的开源协议；
2. 项目源文件中的版权头信息，用来说明文件所遵循的开源协议。

添加版权声明的第一步就是选择一个开源协议，当前有上百种开源协议可供选择，常用的有 6 种，miniblog 项目使用了最宽松的 MIT 协议。更多协议可参考 **附录 C：开源规范协议介绍**。

一般项目的根目录下会存放一个 `LICENSE` 文件用来声明本项目所遵循的协议，使用 `license` 工具来生成，具体操作命令如下：

```Shell
$ go install github.com/nishanths/license/v5@latest
$ license -list # 查看支持的代码协议
$ license -n 'colin404(孔令飞) <colin404@foxmail.com>' -o LICENSE mit # 在 miniblog 项目根目录下执行
$ ls LICENSE 
LICENSE
```

可以看到上述命令成功生成了一个内容为 MIT 协议的 [LICENSE ](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs01%2FLICENSE)文件。

### 给源文件添加添加版权头信息

接下来，我们还需要给项目中的源文件添加版权头信息，用来声明文件所遵循的开源协议。miniblog 的版权头信息保存在 [boilerplate.txt](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Fmaster%2Fscripts%2Fboilerplate.txt) 文件中。

> 提示：版权头信息保存的文件名，通常命名为：boilerplate。

有了版权头信息，我们在新建文件时，就需要将这些信息放在文件头中，如果手动添加，不仅容易出错，还容易漏文件。最好的方法是通过自动化的方法来追加版权头信息。追加方法如下：

1. 安装 `addlicense` 工具。

安装命令如下：

```Ruby
 go install github.com/marmotedu/addlicense@latest
```

1. 运行 `addlicense` 工具添加版权头信息。

运行命令如下：

```Bash
$ addlicense -v -f ./scripts/boilerplate.txt --skip-dirs=third_party,vendor,_output .
cmd/miniblog/main.go added license
```

可以看到 `main.go` 文件已经被追加上了版权头信息，内容如下：

```Go
go复制代码// Copyright 2022 Innkeeper Belm(孔令飞) <nosbelm@qq.com>. All rights reserved.
// Use of this source code is governed by a MIT style
// license that can be found in the LICENSE file. The original repo for
// this file is https://github.com/marmotedu/miniblog.

package main

import "fmt"

// Go 程序的默认入口函数(主函数).
func main() {
    fmt.Println("Hello MiniBlog!")
}
```

## make

```Makefile
# ==============================================================================
# 定义全局 Makefile 变量方便后面引用

COMMON_SELF_DIR := $(dir $(lastword $(MAKEFILE_LIST)))
# 项目根目录
ROOT_DIR := $(abspath $(shell cd $(COMMON_SELF_DIR)/ && pwd -P))
# 构建产物、临时文件存放目录
OUTPUT_DIR := $(ROOT_DIR)/_output

# ==============================================================================
# 定义 Makefile all 伪目标，执行 `make` 时，会默认会执行 all 伪目标
.PHONY: all
all: add-copyright format build

# ==============================================================================
# 定义其他需要的伪目标

.PHONY: build
build: tidy # 编译源码，依赖 tidy 目标自动添加/移除依赖包.
        @go build -v -o $(OUTPUT_DIR)/myblog $(ROOT_DIR)/cmd/myblog/main.go

.PHONY: format
format: # 格式化 Go 源码.
        @gofmt -s -w ./

.PHONY: add-copyright
add-copyright: # 添加版权头信息.
        @addlicense -v -f $(ROOT_DIR)/scripts/boilerplate.txt $(ROOT_DIR) --skip-dirs=third_party,vendor,$(OUTPUT_DIR)

.PHONY: swagger
swagger: # 启动 swagger 在线文档.
        @swagger serve -F=swagger --no-open --port 65534 $(ROOT_DIR)/api/openapi/openapi.yaml

.PHONY: tidy
tidy: # 自动添加/移除依赖包.
        @go mod tidy

.PHONY: clean
clean: # 清理构建产物、临时文件等.
        @-rm -vrf $(OUTPUT_DIR)
```

这个 Makefile 文件主要用于构建和管理 Go 项目，并定义了以下几个伪目标（Phony Targets）：

1. `all`: 默认伪目标，执行 `make` 命令时会执行此目标的依赖动作。
2. `build`: 编译源码并生成可执行二进制文件，使用 `go build` 命令，生成的二进制文件存放在 `$(OUTPUT_DIR)/myblog` 中。
3. `format`: 格式化 Go 源码，使用 `gofmt` 命令进行格式化。
4. `add-copyright`: 添加版权头信息，使用 `addlicense` 工具，版权头信息从 `$(ROOT_DIR)/scripts/boilerplate.txt` 中获取。
5. `swagger`: 启动 Swagger 在线文档，使用 `swagger` 命令，Swagger 文件为 `$(ROOT_DIR)/api/openapi/openapi.yaml`。
6. `tidy`: 自动添加/移除依赖包，使用 `go mod tidy` 命令。
7. `clean`: 清理构建产物、临时文件等，使用 `-rm -vrf $(OUTPUT_DIR)` 命令。

这些伪目标可通过 `make` 命令来执行，例如执行 `make build` 编译项目，执行 `make format` 格式化源码等。同时，`make all` 会按照顺序执行 `add-copyright`、`format` 和 `build` 这三个目标。

请注意，在 Makefile 中，每个命令行前必须有一个制表符（`\t`），否则会导致错误。

## 日志

##### 类别

| 日志包                                                       | Star数 | 描述                                                         |
| ------------------------------------------------------------ | ------ | ------------------------------------------------------------ |
| [logrus](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fsirupsen%2Flogrus) | 21693  | logrus 功能强大、性能高效、高度灵活，还提供了自定义插件的功能 |
| [zap](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fuber-go%2Fzap) | 17476  | zap 是 uber 开源的日志包，以高性能著称，很多公司的日志包都是基于 zap 改造而来。zap 除了具有日志基本的功能之外，还具有很多强大的特性，例如：性能非常好、支持预设日志字段、支持结构化记录、支持设置调用堆栈等 |
| [zerolog](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Frs%2Fzerolog) | 7256   | zerolog 只专注于记录 JSON 格式的日志，号称 0 内存分配，性能更加极致 |
| [glog](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fgolang%2Fglog) | 3258   | glog 是 Google 推出的日志包，跟标准库 log 包一样，是一个轻量级的日志包，使用简单方便，但要比标准库 log 包提供更多的功能 |
| [go-logging](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fop%2Fgo-logging) | 1756   | 又一个好用的日志包，可以自定义日志输出的格式和颜色，支持并设置多个日志记录后端 |
| [seelog](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fcihub%2Fseelog) | 1620   | Seelog 是一个功能强大且易于学习的日志记录框架，它提供了灵活的调度、过滤和格式化日志消息的功能 |
| [apex/log](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fapex%2Flog) | 1271   | 实现了一个简单的结构化日志记录 API，其灵感来自 logrus，在设计时考虑到了集中化 |
| [log15](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Finconshreveable%2Flog15) | 1071   | 结构化、可组合日志记录的日志包                               |

这么多的开源日志包，该如何选择呢？这里我提供给你一个思路。

- **logrus：** logrus 功能强大、使用简单，不仅实现了日志包的基本功能，还有很多高级特性，适合一些大型项目，尤其是需要结构化日志记录的项目。因为 logrus 封装了很多能力，性能一般。
- **zap：** zap 提供了很强大的日志功能，性能高，内存分配次数少，适合对日志性能要求很高的项目。另外，zap 包中的子包 zapcore，提供了很多底层的日志接口，适合用来做二次封装。例如，miniblog 项目的日志包就是基于 zap 和 zapcore 进行封装而来。zap 使用起来也比较简单。
- **zerolog：** zap 和 zerolog 的性能都很好, 但是 zap 更加易用。
- **标准库 log 包：** 标准库 log 包不支持日志级别、日志分割、日志格式等功能，所以在大型项目中很少直接使用，通常用于一些短小的程序，比如：用于生成 JWT Token 的 `main.go` 文件中。标准库日志包也很适合一些简短的代码，用于快速调试和验证。
- **glog：** glog 实现了日志包的基本功能，对于一些对日志功能要求不多的小型项目非常适合。
- [Golang 库 - 日志库 logrus](https://link.juejin.cn/?target=http%3A%2F%2Fwww.manongjc.com%2Fdetail%2F56-aetzsoxzxdpncng.html)、[第三方日志库logrus使用](https://link.juejin.cn/?target=https%3A%2F%2Fwww.cnblogs.com%2FbinHome%2Fp%2F12027471.html)；
- [zap包介绍](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fgeekbang-go%2Fblob%2Fmaster%2F优秀开源日志包使用教程.md%23zap包介绍)、[在Go语言项目中使用Zap日志库](https://link.juejin.cn/?target=https%3A%2F%2Fwww.liwenzhou.com%2Fposts%2FGo%2Fzap%2F)；
- [Go 每日一库之 zerolog](https://link.juejin.cn/?target=https%3A%2F%2Fwww.codercto.com%2Fa%2F110146.html)；
- [标准库log包使用](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fgeekbang-go%2Fblob%2Fmaster%2F优秀开源日志包使用教程.md%23标准库log包使用)；
- [glog使用](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fgeekbang-go%2Fblob%2Fmaster%2F优秀开源日志包使用教程.md%23glog)。

在做企业级 Go 应用开发时，如果要选择一个开源日志库，基本上会在 logrus、zap、zerolog 三者之间选择。这里我的建议如下：

- 如果对性能要求不高，追求使用简单，可以选择 logrus；
- 如果对性能要求较高，并且追求相对方便的使用方式，可以选择 zap；
- 如果对性能要求非常高，相对于使用便捷度，更关注性能，可以选择 zerolog。

miniblog 项目选择了 zap，因为 zap 性能高、使用便捷。实际上，zap 也可以作为你今后 Go 项目开发中的首选日志包。

##### 如何保存日志？

我们可以将日志保存在需要的任何地方，通常有以下几个地方：

- **标准输出：** 开发测试时经常用到，主要是方便。
- **日志文件：** 生产环境部署时最常见的方式，保存的日志可能后续会被 Filebeat、Fluentd 这类日志采集组件采集，并保存到 Elasticsearch；
- **消息中间件：** 例如 kafka。日志包会直接通过调用 API 接口的形式，将日志保存在 kafka 中，为了提高性能，通常有个异步任务队列，异步保存。这种情况下，异步上报逻辑需要开发，重启服务日志可能会丢失，所以这种方式很少采用。

当前比较受欢迎的日志包，例如：zap、logrus 等都支持同时将日志保存在多个位置，例如 miniblog 项目的日志包底层封装了 zap，zap 支持将日志同时输出在标准输出和日志文件中。

如果你的应用采用容器化部署，其实更建议**将日志输出到标准输出**。容器平台一般都具有采集容器日志的能力。采集日志时，可以选择从标准输出采集或者容器中的日志文件采集，如果是从日志文件进行采集，通常需要配置日志采集路径，但如果是从标准输出采集，则不用。所以，如果将日志直接输出到标准输出，则可以不加配置直接复用容器平台已有的能力，做到记录日志和采集日志完全解耦。

在 Kubernetes 最新的日志设计方案中，也是建议应用直接将日志输出到标准输出中。

##### 使用

###### 标准库log包使用

标准库log包功能非常简单，提供了开箱，仅提供了Print、Panic和Fatal三类函数用于日志输出。因为是标准库自带的，所以不需要我们下载安装，使用起来非常方便。标准库log包只有不到400行的代码量，如果读者想研究如何实现一个日志包，阅读标准库log包是一个不错的开始。Go的标准库大量使用了log包，例如：net/http、net/rpc等。

**log包使用**

在使用log包时，需要首先创建一个*log. Logger类型的log实例，所有的日志输出都是通过该实例提供的方法来完成的。

1.全局的log

可以使用log包提供的全局全局变量std，std定义如下（位于Go标准包log目录下的log.go文件中）：

```Go
//var std = New(os.Stderr, "", LstdFlags)//这是在源码中的定义
//实际使用：
        log.SetOutput(os.Stdout)
        log.Println("This is a log message")
//输出：2023/08/04 23:52:33 This is a log message
```

2.使用log.New函数创建自己的logger，在创建时，可以指定输出的位置、每行日志的前缀和日志属性，例如：

```Go
logger := log.New(logFile, "[Debug]", log.Lshortfile)
```

有如下几种日志属性可供选择：

- Ldate：当前时区的日期，格式是：2009/01/23。
- Ltime：当前时区的时间，格式是：01:23:23，精确到秒。
- Lmicroseconds：当前时区的时间，格式是：01:23:23.862600，精确到微妙。
- Llongfile：全文件名和行号。
- Lshortfile：当前文件名和行号，会覆盖Llongfile。
- LUTC：使用UTC而非本地时区。
- Lmsgprefix：将“前缀”从行的开头移至消息之前。
- LstdFlags：标准Logger的默认值（Ldate、Ltime）。

除了在执行log.New时配置log.Logger之外，创建之后还可以通过log.Logger提供的3种方法来改变log.Logger的配置：

- SetOutput：指定输出的位置。
- SetPrefix：设置每行日志的前缀。
- SetFlags：设置日志属性。

log.Logger提供了Print、Panic、Fatal函数来记录日志：

- Print：打印日志，例如：log.Print("call Print: line1")
- Panic：打印日志后执行panic(s)，s为日志内容。
- Fatal：打印日志后执行os.Exit(1)。

Print、Panic、Fatal函数还提供Println、Printf、Panicln、Panicf、Fatalln、Fatalf来格式化打印日志。Print底层调用`fmt.Sprint(v...)`，Println底层调用`fmt.Sprintln(v...)`，Printf底层调用了`fmt.Sprintf(format, v...)`。

```Go
func main() {
    // 输出到文件
    logFile, err := os.Create("./log.log")
    defer logFile.Close()
    if err != nil {
        log.Fatalln("create file log.log failed")
    }
    logger := log.New(logFile, "[Debug] ", log.Lshortfile)
    logger.SetOutput(os.Stdout)
    logger.Print("call Print: line1")
    logger.Println("call Println: line2")

    // 修改日志配置
    logger.SetPrefix("[Info] ")
    logger.SetFlags(log.Ldate)
    logger.SetOutput(os.Stdout)
    logger.Print("Info check stdout")
}
```

执行如下命令执行上述程序：

```Bash
$ go run main.go
[Debug] main.go:17: call Print: line1
[Debug] main.go:18: call Println: line2
[Info] 2020/11/28 Info check stdout
```



###### glog

[glog](https://github.com/golang/glog)是Google推出的日志包，跟标准库log包一样，是一个轻量级的日志包，使用简单方便，但要比标准库log包提供更多的功能，glog具有如下特性：

- 支持4种日志级别：INFO、WARNING、ERROR、FATAL。
- 支持命令行选项，例如：`-alsologtostderr`、`-log_backtrace_at`、`-log_dir`、`-logtostderr`、`-v`等，每个参数实现某种功能。
- 支持根据文件大小切割日志文件。
- 支持日志按级别分类输出。
- 支持V level，V level特性可以使开发者自定义日志级别。
- 支持vmodule，vmodule可以使开发者对不同的文件使用不同的日志级别。
- 支持traceLocation，traceLocation可以打印出指定位置的栈信息。

kubernetes项目就使用了基于glog封装的klog作为其日志库。

**glog使用方法**

glog使用非常简单，常见的用法如下。

1. 基本用法

glog的最常用的使用方法：

```Go
package main

import (
    "flag"

    "github.com/golang/glog"
)

func main() {
    glog.MaxSize = 1024 * 1024 * 1024 // 1G自动分割
    flag.Parse()
    defer glog.Flush()

    glog.Info("This is info message")
    glog.Infof("This is info message: %v", 123)

    glog.Warning("This is warning message")
    glog.Warningf("This is warning message: %v", 123)

    glog.Error("This is error message")
    glog.Errorf("This is error message: %v", 123)

    //glog.Fatal("This is fatal message")
    //glog.Fatalf("This is fatal message: %v", 123)
}
```

glog支持4种日志级别，从低到高依次为：INFO、WARNING、ERROR、FATAL。glog支持命令行参数，在程序中，只需要在使用glog之前调用flag.Parse()即可，支持如下7个命令行参数：

- `-alsologtostderr`：同时将日志打印到文件和标准错误输出。
- `-log_backtrace_at value`：指定代码运行到指定行时，把该代码的栈信息打印出来。
- `-log_dir`：指定日志存储的文件夹。
- `-logtostderr`：日志打印到标准错误输出，而不是文件中。
- `-stderrthreshold value`：指定大于或者等于该级别的日志才会被输出到标准错误输出，默认为ERROR。
- `-v value`：指定日志级别。
- `-vmodule value`：对不同的文件使用不同的日志级别。

执行上述代码（假设保存在example1.go文件中）：

```Bash
$ mkdir -p log && go run example1.go -log_dir=log -alsologtostderr
I1202 09:43:49.618480   26223 example1.go:14] This is info message
I1202 09:43:49.618781   26223 example1.go:15] This is info message: 123
W1202 09:43:49.618792   26223 example1.go:17] This is warning message
W1202 09:43:49.618830   26223 example1.go:18] This is warning message: 123
E1202 09:43:49.618840   26223 example1.go:20] This is error message
E1202 09:43:49.618877   26223 example1.go:21] This is error message: 123
```

以上命令会同时将日志打印在log目录和标准错误输出中（`-alsologtostderr`），log目录下文件列表为：

```Plaintext
main.colin.colin.log.ERROR.20201202-081133.24123
main.colin.colin.log.INFO.20201202-081133.24123
main.colin.colin.log.WARNING.20201202-081133.24123
main.ERROR -> main.colin.colin.log.ERROR.20201202-081133.24123
main.INFO -> main.colin.colin.log.INFO.20201202-081133.24123
main.WARNING -> main.colin.colin.log.WARNING.20201202-081133.24123
```

main.INFO文件是一个软链接，链接到最新的INFO级别的日志文件，低优先级的日志文件包含高优先级的日志，例如INFO级别的日志文件中包含WARNING、ERROR、FATAL级别的日志。默认情况下，当单个日志文件达到1.8G时,，glog会对日志文件进行转存：关闭当前的文件，新建日志文件，可以通过glog.MaxSize设置转存阈值。

从上面的输出可以发现，glog的日志输出格式为：`<header>] <message>`，其中header的格式为：`Lmmdd hh:mm:ss.uuuuuu threadid file:line`：

- Lmmdd：L代表了glog的日志级别：I -> INFO、W -> WARNING、E -> ERROR、F -> FATAL。
- hh:mm:ss.uuuuuu：代表了时间信息，例如10:12:32.995956。
- threadid，是进程PID，即os.Getpid()的返回值。
- file:line：指明了打印日志的位置：文件名和行号。

使用glog.Info、glog.Warning等函数记录日志后，为了提高性能，这些日志会暂存在内存的buffer中，而不是直接写入文件中，只有显式的调用glog.Flush()，数据才会被写入文件。glog的init函数中启动了一个goroutine来周期性的调用glog.Flush()，默认的flush间隔为30秒。如果程序退出，自上次glog.Flush()函数执行之后产生的日志，就会被丢失，所以在程序退出时，需要调用glog.Flush()将日志刷新到磁盘文件中。

这里要注意，调用glog.Fatal函数后，glog会打印日志并退出程序，在程序退出前，会将缓存中的所有日志都写入日志，但是对于glog.Info、glog.Warning、glog.Error函数则不会。

1. vmodule功能

glog 最常用的就是 V level 的功能，V越小，说明日志级别越高。示例如下：（保存在example2.go文件中）：

```Go
package main

import (
    "flag"

    "github.com/golang/glog"
)

func main() {
    flag.Parse()
    defer glog.Flush()

    glog.V(3).Info("LEVEL 3 message") // 使用日志级别 3
    glog.V(5).Info("LEVEL 5 message") // 使用日志级别 5
    glog.V(7).Info("LEVEL 7 message") // 使用日志级别 7
    glog.V(8).Info("LEVEL 8 message") // 使用日志级别 8
}
```

执行上述代码：

```Bash
$ go run example2.go -log_dir=log -alsologtostderr
```

上面的命令不会有任何输出，因为日志级别不够，可以通过`-v`设置日志级别：

```Bash
$ go run example2.go -log_dir=log -alsologtostderr -v=5
I1202 09:52:44.163989   29042 example2.go:13] LEVEL 3 message
I1202 09:52:44.164335   29042 example2.go:14] LEVEL 5 message
```

此时，日志级别高于或者等于5（V值小于或者等于5）的日志将被打印出来。

glog还支持对不同的文件使用不同的日志级别（`-vmodule`），例如：

```Bash
$ go run main.go foo.go -v=3 -log_dir=log -alsologtostderr -vmodule=foo=5
```

通过指定`-vmodule=foo=5`参数，可以设置对foo.go文件使用5级别，对其它文件使用3级别。`-vmodule`的输入参数省去了.go后缀，语法格式为：`-vmodule=file1=2,file2=1,fs*=3`。

1. traceLocation功能

traceLocation可以打印出指定位置的栈信息（`-log_backtrace_at=filename:line_number`），例如有如下代码：

```Go
package main

import (
    "flag"

    "github.com/golang/glog"
)

func main() {
    glog.MaxSize = 1024 * 1024 * 1024 // 1G自动分割
    flag.Parse()
    defer glog.Flush()

    glog.Info("This is info message")
}
```

执行以上代码（保存在example3.go文件中）：

```Plaintext
$ go run example3.go -log_dir=log -alsologtostderr -log_backtrace_at=example3.go:13
I1202 10:12:41.304582    1340 example3.go:13] This is info message
goroutine 1 [running]:
... 打印backtrace，此处省略 ...
I1202 10:12:41.304779    1340 example3.go:14] This is info message: 123
```





###### logrus介绍

[logrus](https://github.com/sirupsen/logrus)是目前Github上star数量最多的日志包，功能强大、性能高效、高度灵活，还提供了自定义插件的功能。很多优秀的开源项目，例如：docker、prometheus等都使用了logrus。logrus除了具有日志的基本功能外，还具有如下特性：

- 支持常用的日志级别，logrus支持如下日志级别：Debug、Info、Warn、Error、Fatal和Panic。
- 可扩展，logrus的hook机制允许使用者通过hook的方式将日志分发到任意地方，例如：本地文件、标准输出、elasticsearch、logstash、kafka等。
- 支持自定义日志格式，logrus内置了2种格式：JSONFormatter和TextFormatter。除此之外，logrus允许使用者通过实现Formatter接口，来自定义日志格式。
- 结构化日志记录，logrus的Field机制可以允许使用者自定义日志字段，而不是通过冗长的消息来记录日志。
- 预设日志字段，logrus的Default Fields机制可以给一部分或者全部日志统一添加共同的日志字段，例如给某次HTTP请求的所有日志添加X-Request-ID字段。
- Fatal handlers：logrus允许注册一个或多个handler，当发生fatal级别的日志时调用。当我们的程序需要优雅关闭时，该特性会非常有用。

logrus使用方法如下：

1. 基本用法

logrus可以通过简单的配置，来定义输出、格式或者日志级别等，示例如下：

```Go
package main

import (
    "os"

    "github.com/sirupsen/logrus"
)

func main() {
    // logrus设置
    logrus.SetFormatter(&logrus.JSONFormatter{})
    logrus.SetOutput(os.Stdout)
    logrus.SetLevel(logrus.WarnLevel)

    // logrus使用
    logrus.Debug("Useful debugging information.")
    logrus.Info("Something noteworthy happened!")
    logrus.Warn("You should probably take a look at this.")
    logrus.Error("Something failed but I'm not quitting.")

    logrus.WithFields(logrus.Fields{
        "animal": "walrus",
        "size":   10,
    }).Info("A group of walrus emerges from the ocean")

    logrus.WithFields(logrus.Fields{
        "omg":    true,
        "number": 122,
    }).Warn("The group's number increased tremendously!")
}
```

可以通过logrus.SetFormatter设置输出的日志格式，logrus自带有JSONFormatter和TextFormatter。通过logrus.SetLevel来设置日志级别，通过logrus.SetOutput设置日志输出等。

假设上述代码保存在example1.go文件中，运行代码：

```Bash
$ go run example1.go
{"level":"warning","msg":"You should probably take a look at this.","time":"2020-12-03T22:35:35+08:00"}
{"level":"error","msg":"Something failed but I'm not quitting.","time":"2020-12-03T22:35:35+08:00"}
{"level":"warning","msg":"The group's number increased tremendously!","number":122,"omg":true,"time":"2020-12-03T22:35:35+08:00"}
```

1. Default Fields

通常，在一个应用中、或者应用的一部分中，始终附带一些固定的记录字段会很有帮助。比如在处理用户HTTP请求时，上下文中所有的日志都会有request_id。为了避免每次记录日志都要使用：

```Go
logrus.WithFields(logrus.Fields{"request_id”", request_id})
```

我们可以创建一个logrus.Entry实例，为这个实例设置默认Fields，把logrus.Entry实例设置到记录器Logger，再记录日志时每次都会附带上这些默认的字段。

```Go
logger := log.WithFields(log.Fields{"request_id": request_id})
logger.Info("something happened on that request") // 也会记录request_id
logger.Warn("something not great happened")
```

1. Hook接口

logrus具有hook能力，允许我们自定义一些日志处理逻辑，实现一个hook只需要实现如下接口：

```Go
// logrus在记录Levels()返回的日志级别的消息时会触发HOOK,
// 按照Fire方法定义的内容修改logrus.Entry.
type Hook interface {
    Levels() []Level
    Fire(*Entry) error
}
```

一个简单自定义hook如下，DefaultFieldHook定义会在所有级别的日志消息中加入默认字段`myHook="MyHookTest"`:

```Go
type DefaultFieldHook struct {
}

func (hook *DefaultFieldHook) Fire(entry *log.Entry) error {
    entry.Data["myHook"] = " MyHookTest "
    return nil
}

func (hook *DefaultFieldHook) Levels() []log.Level {
    return log.AllLevels
}
```

实现了hook之后，只需要调用log.AddHook(hook)即可将自定义的hook注册到logrus中。通过hook可以实现很多强大的日志处理功能，比较常见的用法是，当有指定级别的日志产生时，邮件通知或者告警给相关负责人。

###### zap包介绍

[zap](https://github.com/uber-go/zap)是uber开源的日志包，以高性能著称，很多公司的日志包都是基于zap改造而来。zap除了具有日志基本的功能之外，还具有很多强大的特性：

- 支持常用的日志级别，例如：Debug、Info、Warn、Error、DPanic、Panic、Fatal。
- 性能非常高，zap具有非常高的性能，适合对性能要求比较高的场景。
- 像logrus一样，支持结构化的日志记录。
- 支持预设日志字段。
- 支持针对特定的日志级别，输出调用堆栈。
- 支持hook。



**zap使用方法**

1.基本用法

zap使用方法跟其他日志包使用方法比较类似，如下是一个常见的用法：

```Go
package main

import (
        "time"

        "go.uber.org/zap"
)

func main() {
        logger, _ := zap.NewProduction(zap.AddCaller()) // 创建一个Zap日志记录器,并增加行号和文件名
        defer logger.Sync()                             // 刷新磁盘

        url := "http://marmotedu.com"
        logger.Info("failed to fetch URL", // 结构化日志记录 1
                zap.String("url", url),
                zap.Int("attempt", 3),
                zap.Duration("backoff", time.Second),
        )
        logger.Info("hello world") // 使用日志记录器输出日志 2

        sugar := logger.Sugar()
        sugar = sugar.With(zap.String("name", "lmy")) // 添加公共字段。

        sugar.Infow("failed to fetch URL", //3
                "url", url,
                "attempt", 3,
                "backoff", time.Second,
        )
        sugar.Infof("Failed to fetch URL: %s", url) //4

        logger.Sugar().Infow("This is an info message with fields", //5   使用键值对方式记录结构化日志的方法
                "key1", "value1",
                "key2", "value2",
        )
        logger.Sugar().Infow("This is an info message with a dynamic value: %d", 42) //6 一个格式化字符串方式记录日志的方法

}
```

将上述代码保存在example1.go文件中，运行：

```JSON
{"level":"info","ts":1698110186.749606,"caller":"emzmple1/main.go:14","msg":"failed to fetch URL","url":"http://marmotedu.com","attempt":3,"backoff":1}
{"level":"info","ts":1698110186.7496521,"caller":"emzmple1/main.go:19","msg":"hello world"}
{"level":"info","ts":1698110186.7496665,"caller":"emzmple1/main.go:24","msg":"failed to fetch URL","name":"lmy","url":"http://marmotedu.com","attempt":3,"backoff":1}
{"level":"info","ts":1698110186.7496862,"caller":"emzmple1/main.go:29","msg":"Failed to fetch URL: http://marmotedu.com","name":"lmy"}
{"level":"info","ts":1698110186.7496963,"caller":"emzmple1/main.go:31","msg":"This is an info message with fields","key1":"value1","key2":"value2"}
{"level":"error","ts":1698110186.7497144,"caller":"zap@v1.26.0/sugar.go:224","msg":"Ignored key without a value.","ignored":42,"stacktrace":"go.uber.org/zap.(*SugaredLogger).Infow\n\t/home/goer/workspace/golang/pkg/mod/go.uber.org/zap@v1.26.0/sugar.go:224\nmain.main\n\t/home/goer/workspace/exercise/emzmple1/main.go:35\nruntime.main\n\t/home/goer/go/go1.21.3/src/runtime/proc.go:267"}
{"level":"info","ts":1698110186.7497098,"caller":"emzmple1/main.go:35","msg":"This is an info message with a dynamic value: %d"}
```

默认的日志输出格式为JSON格式，并记录了文件名和行号。



上述代码通过zap.NewProduction()创建了一个logger，zap还提供了zap.NewExample()、zap.NewDevelopment()来快速创建一个logger，不同方法创建的logger具有不同的设置，

Example适合用在测试代码中，Development在开发环境中使用，Production用在生产环境。如果想自定义logger，可以调用zap.New()方法来创建。logger提供了Debug、Info、Warn、Error、Panic、Fatal等方法，用来记录不同级别的日志。

在程序退出时，注意要调用defer logger.Sync()将缓存中的日志刷新到磁盘文件中。

当我们对日志的性能要求比较高时，可以使用Logger而非SugaredLogger，Logger性能更好，内存分配次数更少。为了提高性能，Logger没有使用interface和反射，并且Logger只支持结构化的日志，所以在使用Logger时，需要指定具体的类型和key-value格式的日志字段，例如：

```Go
logger.Info("failed to fetch URL",
    zap.String("url", url),
    zap.Int("attempt", 3),
    zap.Duration("backoff", time.Second),
)
```

如果觉得Logger的日志格式比较繁琐，可以使用更加便捷的SugaredLogger，调用logger.Sugar()即可创建SugaredLogger。SugaredLogger的使用比Logger简单，但性能比Logger低 50% 左右，可以用在调用次数不高的函数中，调用方式如下：

```Go
sugar := logger.Sugar()
    sugar.Infow("failed to fetch URL",
    "url", url,
    "attempt", 3,
    "backoff", time.Second,
)
sugar.Infof("Failed to fetch URL: %s", url)
```

2.定制Logger

可以使用NexExample()/NewDevelopment()/NewProduction()函数创建默认的Logger，每种方法创建的Logger配置不一样，也可以创建一个定制化的Logger，创建方式如下：

```Go
func main() {
    rawJSON := []byte(`{
    "level":"debug",
    "encoding":"json",
    "outputPaths": ["stdout", "test.log"],
    "errorOutputPaths": ["stderr"],
    "initialFields":{"name":"dj"},
    "encoderConfig": {
      "messageKey": "message",
      "levelKey": "level",
      "levelEncoder": "lowercase"
    }
  }`)

    var cfg zap.Config
    if err := json.Unmarshal(rawJSON, &cfg); err != nil {
        panic(err)
    }
    logger, err := cfg.Build()
    if err != nil {
        panic(err)
    }
    defer logger.Sync()

    logger.Info("server start work successfully!")
}
```

以上示例调用zap.Config的Build方法创建了一个输出到标准输出和文件test.log的Logger，将上述代码保存在example2.go文件中，运行：

```Bash
$ go run example2.go
{"level":"info","message":"server start work successfully!","name":"dj"}
```

zap.Config定义如下：

```Go
type Config struct {
    Level AtomicLevel
    Development bool
    DisableCaller bool
    DisableStacktrace bool
    Sampling *SamplingConfig
    Encoding string
    EncoderConfig zapcore.EncoderConfig
    OutputPaths []string
    ErrorOutputPaths []string
    InitialFields map[string]interface{}
    // 指定日志显示格式，可选值：console, json
        Format string
}
```

Config结构体，各字段说明如下：

- Level：日志级别。
- Development：设置Logger的模式为development模式。
- DisableCaller：禁用调用信息. 该字段值为 true 时, 日志中将不再显示该日志所在的函数调用信息。
- DisableStacktrace：禁用自动堆栈跟踪捕获。
- Sampling：流控配置, 也叫采样. 单位是每秒钟, 作用是限制日志在每秒钟内的输出数量, 以防止CPU和IO被过度占用。
- Encoding：指定日志编码器, 目前仅支持两种编码器：console和json，默认为json。
- EncoderConfig：编码配置。
- OutputPaths：配置日志标准输出，可以配置多个日志输出路径, 一般情况可以仅配置标准输出或输出到文件, 如有需求的话, 也可以两者同时配置。
- ErrorOutputPaths：错误输出路径，可以是多个。
- InitialFields：初始化字段配置, 该配置的字段会以结构化的形式打印在每条日志输出中。

调用zap.Config的Build()方法，可以使用zap.Config配置创建一个Logger。

其中EncoderConfig为编码配置：

```Go
type EncoderConfig struct {
    MessageKey    string `json:"messageKey" yaml:"messageKey"`
    LevelKey      string `json:"levelKey" yaml:"levelKey"`
    TimeKey       string `json:"timeKey" yaml:"timeKey"`
    NameKey       string `json:"nameKey" yaml:"nameKey"`
    CallerKey     string `json:"callerKey" yaml:"callerKey"`
    FunctionKey   string `json:"functionKey" yaml:"functionKey"`
    StacktraceKey string `json:"stacktraceKey" yaml:"stacktraceKey"`
    LineEnding    string `json:"lineEnding" yaml:"lineEnding"`
    EncodeLevel    LevelEncoder    `json:"levelEncoder" yaml:"levelEncoder"`
    EncodeTime     TimeEncoder     `json:"timeEncoder" yaml:"timeEncoder"`
    EncodeDuration DurationEncoder `json:"durationEncoder" yaml:"durationEncoder"`
    EncodeCaller   CallerEncoder   `json:"callerEncoder" yaml:"callerEncoder"`
    EncodeName NameEncoder `json:"nameEncoder" yaml:"nameEncoder"`
    ConsoleSeparator string `json:"consoleSeparator" yaml:"consoleSeparator"`
}
```

常用的设置如下：

- MessageKey：日志中信息的键名，默认为msg。
- LevelKey：日志中级别的键名，默认为level。
- EncodeLevel：日志中级别的格式，默认为小写，如debug/info。

1. 选项

zap支持多种选项，选项的使用方式如下：

```Go
func main() {
    logger, _ := zap.NewProduction(zap.AddCaller())


    defer logger.Sync()

    logger.Info("hello world")
}
```

将上述代码保存在example3.go中，执行：

```Bash
$ go run "/home/goer/workspace/lanmengyou/myblog/myblog.go"
{"level":"info","ts":1691172108.8064196,"caller":"myblog/myblog.go:15","msg":"hello world"}
```

上述日志输出了日志的调用信息（文件名:行号）`"caller":"zap/example3.go:9"`。zap提供了多个选项可供选择：

- `zap.AddCaller()`：与zap.WithCaller(true)等价，指定在日志输出内容中增加行号和文件名。
- `Fields(fs ...Field)`：添加公共字段。
- `zap.WithCaller(enabled bool)`：指定是否在日志输出内容中增加文件名和行号。
- `AddStacktrace(lvl zapcore.LevelEnabler)`：用来在指定级别及以上级别输出调用堆栈。
- `zap. AddCallerSkip(skip int)`：指定在调用栈中跳过的调用深度，否则通过调用栈获得的行号可能总是日志组件中的行号。
- `zap. IncreaseLevel(lvl zapcore.LevelEnabler)`：提高日志级别，如果传入的lvl比当前logger的级别低，则不会改变日志级别。
- `ErrorOutput(w zapcore.WriteSyncer)`：指定日志组件中出现异常时的输出位置。
- `Hooks(hooks ...func(zapcore.Entry) error)`：注册钩子函数，用来在日志打印时同时调用hook方法。
- `WrapCore(f func(zapcore.Core) zapcore.Core)`：替换Logger的zapcore.Core。 -`Development()`：将Logger修改为Development模式。

1. 添加日志字段

每条日志加一些公共字段，例如requestID，

```Go
func main() {
        //1.创建Logger时使用Fields(fs ...Field)选项
        logger := zap.NewExample(zap.Fields(
                zap.Int("userID", 10),
                zap.String("requestID", "fbf54504"),
        ))
        logger.Info("This is a info message")

        //2. 不更改原始日志记录器的情况下，为特定的日志记录添加  logger.With
        //logger, _ := zap.NewProduction(zap.Fields(zap.String("name", "dj"))) 已被废弃，推荐使用
        logger = logger.With(zap.String("app", "myapp"))
        logger.Info("This is a info message")
    
    //logger.With(zap.Any(known.XRequestIDKey, requestID))
}
```

将上述代码保存到preset_field.go文件中，运行：

```Bash
{"level":"info","msg":"This is a info message","userID":10,"requestID":"fbf54504"}
{"level":"info","msg":"This is a info message","userID":10,"requestID":"fbf54504","app":"myapp"}
```

1. 全局Logger

zap提供了2个全局Logger，可以方便我们调用：

- `*zap.Logger`：可通过zap.L()获得，提供了Debug()、Info()、Warn()、Error()、Panic()、DPanic()、Fatal()方法来记录日志。
- `*zap.SugaredLogger`：可通过zap.S()获得，提供了Debugf()、Debugw()、Infof()、Infow()、Warnf()、Warnw()、Errorf()、Errorw()、Panicf()、Panicw()、DPanicf()、DPanicw()、Fatalf()、Fatalw()方法来记录日志。

//——》默认的全局Logger不会记录任何日志，它是一个无用的Logger，例如zap.L()返回了名为_globalL的Logger，_globalL定义为：

```Go
//不用掌握
_globalL  = NewNop()
func NewNop() *Logger {
    return &Logger{
        core:        zapcore.NewNopCore(),
        errorOutput: zapcore.AddSync(ioutil.Discard),
        addStack:    zapcore.FatalLevel + 1,
    }
}
```

`zapcore.NewNopCore()`函数定义为：

```Go
//不用掌握
type nopCore struct{}

// NewNopCore returns a no-op Core.
func NewNopCore() Core                                        { return nopCore{} }
func (nopCore) Enabled(Level) bool                            { return false }
func (n nopCore) With([]Field) Core                           { return n }
func (nopCore) Check(_ Entry, ce *CheckedEntry) *CheckedEntry { return ce }
func (nopCore) Write(Entry, []Field) error                    { return nil }
func (nopCore) Sync() error                                   { return nil }

// NewCore creates a Core that writes logs to a WriteSyncer.
func NewCore(enc Encoder, ws WriteSyncer, enab LevelEnabler) Core {
    return &ioCore{
        LevelEnabler: enab,
        enc:          enc,
        out:          ws,
    }
}
```

可以看到NewNop()创建一个不记录任何日志、任何内部错误、不执行任何钩子的Logger。可以使用ReplaceGlobals函数将全局Logger替换为我们创建的Logger，例如：

```Go
//不怎么用
func main() {
    zap.L().Info("default global Logger")//没输出
    zap.S().Info("default global SugaredLogger") //没输出

    logger := zap.NewExample()
    defer logger.Sync()

    zap.ReplaceGlobals(logger)
    zap.L().Info("replaced global Logger")
    zap.S().Info("replaced global SugaredLogger")
}
```

假设上述代码保存在`global_logger.go`文件中，运行：

```Bash
$ go run global_logger.go
{"level":"info","msg":"replaced global Logger"}
{"level":"info","msg":"replaced global SugaredLogger"}
```

可以看到在`zap.ReplaceGlobals(logger)`之前的日志，并没有被打印出来。《————

##### 开源日志包选择

我们介绍了很多日志包，每种日志包使用的场景不同，你可以根据自己的需求结合日志包的特性进行选择：

- **标准库log包：** 标准库log包不支持日志级别、日志分割、日志格式等功能，所以在大型项目中很少直接使用，通常用于一些短小的程序，比如：用于生成JWT Token的main.go文件中。标准库日志包也很适合一些简短的代码，用于快速调试和验证。
- **glog：** glog实现了日志包的基本功能，对于一些对日志功能要求不多的小型项目非常适合。
- **logrus：** logrus功能强大，不仅实现了日志包的基本功能，还有很多高级特性，适合一些大型项目，尤其是需要结构化日志记录的项目。
- **zap：** zap提供了很强大的日志功能，性能高，内存分配次数少，适合对日志性能要求很高的项目。另外，zap包中的子包zapcore，提供了很多底层的日志接口，适合用来做二次封装。例如笔者就基于zap和zapcore封装了[marmotedu/log](https://github.com/marmotedu/log)日志包，该日志包可以很好的兼容glog，封装背景是因为在做容器云平台开发时，发现kubernetes源码中大量使用了glog，需要日志包能够兼容glog。







## 错误码

### 区别

日志（Log）和错误码（Error Code）是软件开发和系统管理中常见的概念，它们有不同的含义和用途。

日志是记录软件运行过程中关键事件和信息的记录。它用于跟踪应用程序、系统或服务的状态、行为和异常情况。日志可以包含各种信息，如程序的执行路径、警告、错误、异常堆栈跟踪、用户操作、网络请求和响应等。日志对于故障排除、性能优化、安全审计和行为分析等方面都非常有用。它们可以在软件开发和运维过程中用于查找问题、诊断错误和监控系统。

错误码是一种用于标识和表示特定错误或异常情况的数字或代码。它们通常作为函数或方法的返回值，用于指示操作是否成功以及出现了哪种类型的错误。错误码可以提供有关错误类型、错误级别和导致错误的具体原因的信息。它们对于开发人员和系统管理员来说是一种标准化的方式，用于识别和处理不同类型的错误。错误码可以被程序捕获并处理，或者被报告给用户或系统管理员以指示发生了什么问题。

因此，日志和错误码有以下主要区别：

- 日志是记录软件运行过程中的事件和信息，而错误码是标识和表示特定错误或异常情况的代码。
- 日志用于跟踪和记录系统的状态、行为和异常情况，而错误码用于指示操作是否成功以及出现了哪种类型的错误。
- 日志可以包含多种信息，如警告、错误、异常堆栈跟踪等，而错误码通常是一个简单的标识或代码。
- 日志可以用于故障排除、性能优化和安全审计等方面，而错误码主要用于程序的错误处理和用户或管理员的错误诊断。

在实际应用中，日志和错误码通常是结合使用的。当发生错误时，程序可以生成相应的错误码，并记录错误信息到日志中，以便开发人员或管理员进行错误分析和排查。

### error

在 Go 语言中，error 是一个内置的接口类型，用于表示错误。它定义了一个方法 `Error()`，返回一个描述错误信息的字符串。任何实现了 `Error()` 方法的类型都可以被视为 `error` 类型的值。

`error` 接口的定义如下：

```Go
type error interface {
    Error() string
}
```

`error` 接口只有一个方法 `Error()`，返回类型是字符串。当一个函数需要返回错误时，通常会返回一个 `error` 类型的值，这样调用者就可以通过调用 `Error()` 方法获取错误的描述信息。

- `error` 是一个内置的接口类型，只有一个方法 `Error()`，返回错误的描述信息。
- Go 中的函数通常使用 `error` 类型来表示错误，并通过返回 `nil` 表示没有错误发生。
- 调用者通常使用条件语句来检查返回的错误，并根据错误信息进行适当的错误处理。

### 自定义错误类型

在 Go 中，自定义错误类型是通过实现 `error` 接口来创建的。`error` 接口是一个内置接口，只包含一个方法 `Error()`，该方法返回一个表示错误的字符串。

自定义错误类型一般是一个结构体，其中包含了错误的相关信息，并实现了 `error` 接口的 `Error()` 方法，使其成为一个合法的错误类型。

以下是一个示例，演示如何自定义一个简单的错误类型：

```Go
// 自定义错误类型 MyError，实现 error 接口
type MyError struct {
        Message string
}

func (err *MyError) Error() string {
        return err.Message
}

func main() {
        // 创建一个 MyError 实例并设置错误信息
        err := &MyError{
                Message: "This is a custom error.",
        }

        // 打印错误信息
        fmt.Println(err.Error()) // 输出："This is a custom error."
}
```

当程序需要返回错误时，我们可以创建一个 `MyError` 的实例，并将错误信息设置到 `Message` 字段中。随后，我们可以像处理其他错误一样处理这个自定义错误，并在需要时通过调用 `Error()` 方法获取错误信息。

### err 和 error

1. `err`：
   1. `err` 是一个通常用于表示函数执行状态或结果的变量名。它是程序员在代码中定义的一个变量，用于存储函数执行过程中可能发生的错误。`err` 变量通常是一个 `error` 类型的值，因为在 Go 中习惯将错误信息存储在 `error` 类型变量中。
   2. 当函数执行过程中发生错误时，通常会将错误信息赋值给 `err` 变量，然后通过检查 `err` 变量来判断函数是否执行成功。如果 `err` 变量为 `nil`，表示函数执行成功，否则表示函数执行出现了错误。
   3. 例如：
   4. ```Go
      result, err := someFunction()
      if err != nil {
          // 处理错误
      } else {
          // 使用结果 result
      }
      ```
2. `error`：
   1. `error` 是 Go 语言中的一个内置接口类型，用于表示错误信息。它定义了一个 `Error()` 方法，当实现了该方法的类型被赋值给 `error` 类型变量时，可以通过调用 `Error()` 方法来获取错误的描述信息。
   2. `error` 接口定义：
   3. ```Go
      type error interface {
          Error() string
      }
      ```

   4. Go 标准库中的许多函数都使用 `error` 类型作为返回值，以便返回函数执行过程中的错误信息。

所以，`err` 是程序员自定义的一个变量用于保存函数执行过程中的错误，而 `error` 是 Go 语言内置的接口类型，用于表示错误信息，并且通常与 `err` 变量关联使用。

## 版本号

### SemVer 版本规范格式

SemVer 规范格式为：`[name]x.y.z-[state+buildmetadata]`，例如：`v2.1.5`、`v1.2.3-alpha.1+001`。每一部分代表的含义如下：

- `name`：可选段，一般为 `v`，表示 Version。SemVer 2.0.0 规范中 `name` 不会出现，但一般会加上，以明确表示这是一个版本号；
- `x`（主版本号，MAJOR）：在做了不兼容的 API 修改时递增；
- `y`（次版本号，MINOR）：在做了向下兼容的功能性新增及修改时递增。一般偶数为稳定版本，奇数为开发版本；
- `z`（修订号，PATCH）：在做了向下兼容的问题修正时递增；
- `state`：可选段，用来表示当前软件的状态。例如：`alpha` 表示 alpha 版，即内测版。state 标识可参考 **附录A：版本状态段规则；**
- `buildmetadata`：可选段，用来标识某次编译信息，一般是编译器在编译过程中自动生成的。

> 提示：`[x]`代表其内的内容（`x`）是可选的。

![202407092232435](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407112001783.webp)

> 提示：`0.Y.Z` 表示当前软件处于研发阶段，软件并不稳定；`1.0.0` 表示当前软件为初始的稳定版，后续的更新都基于此版本。

使用 `go build -ldflags "-X importpath.name=value"` 可以实现给应用程序添加版本号的功能。

`-ldflags` 是一个常用的编译标志，用于向编译器传递链接选项和链接符号。通过使用 `-ldflags` 标志，您可以在编译时设置程序中的变量值。其中，`-X` 标志用于设置 Go 程序的字符串变量。

```Go
var (
    // GitVersion 是语义化的版本号.
    GitVersion = "v0.0.0-master+$Format:%h$"
    // BuildDate 是 ISO8601 格式的构建时间, $(date -u +'%Y-%m-%dT%H:%M:%SZ') 命令的输出.
    BuildDate = "1970-01-01T00:00:00Z"
)

func main() {
    version := flag.Bool("version", false, "Print version info.")
    flag.Parse()

    if *version {
        fmt.Println("GitVersion", GitVersion)
        fmt.Println("BuildDate", BuildDate)
    }

    fmt.Println("ok")
}
```

编译并运行：

```Shell
$ go build -ldflags "-X main.GitVersion=v1.0.0 -X main.BuildDate=$(date +%F)" -o version main.go
$ ./version -version
GitVersion v1.0.0
BuildDate 2022-11-25
ok
```

## 数据库

1. 创建数据库和数据库表。

创建数据库：

```Go
go复制代码CREATE DATABASE `miniblog`;
USE `miniblog`;
```

创建 `user` 表，创建 SQL 语句为：

```SQL
sql复制代码CREATE TABLE `user` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `username` varchar(255) NOT NULL,
  `password` varchar(255) NOT NULL,
  `nickname` varchar(30) NOT NULL,
  `email` varchar(256) NOT NULL,
  `phone` varchar(16) NOT NULL,
  `createdAt` timestamp NOT NULL DEFAULT current_timestamp(),
  `updatedAt` timestamp NOT NULL DEFAULT current_timestamp() ON UPDATE current_timestamp(),
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=MyISAM AUTO_INCREMENT=27 DEFAULT CHARSET=utf8;
```

### 根据数据库表生成 Model 文件

执行以下命令生成：

```CSS
$ mkdir -p internal/pkg/model
$ cd internal/pkg/model
$ db2struct --gorm --no-json -H 127.0.0.1 -d miniblog -t user --package model --struct UserM -u miniblog -p 'miniblog1234' --target=user.go
$ db2struct --gorm --no-json -H 127.0.0.1 -d miniblog -t post --package model --struct PostM -u miniblog -p 'miniblog1234' --target=post.go
```

`db2struct` 命令行参数说明如下：

```Lua
lua复制代码$ db2struct  -h
Usage of db2struct:
        db2struct [-H] [-p] [-v] --package pkgName --struct structName --database databaseName --table tableName
Options:
  -H, --host=         Host to check mariadb status of
  --mysql_port=3306   Specify a port to connect to
  -t, --table=        Table to build struct from
  -d, --database=nil  Database to for connection
  -u, --user=user     user to connect to database
  -v, --verbose       Enable verbose output
  --package=          name to set for package
  --struct=           name to set for struct
  --json              Add json annotations (default)
  --no-json           Disable json annotations
  --gorm              Add gorm annotations (tags)
  --guregu            Add guregu null types
  --target=           Save file path
  -p, --password=     Mysql password
  -h, --help          Show usage message
  --version           Show version
```

生成后的文件见：[user.go](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs14%2Finternal%2Fpkg%2Fmodel%2Fuser.go)、[post.go](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs14%2Finternal%2Fpkg%2Fmodel%2Fpost.go)。

### SQL 语句保存

最后，为了以后的部署，我们使用 `mysqldump` 将创建数据库和表的 SQL 语句保存在 `configs` 目录下供以后部署使用：

```CSS
mysqldump -h127.0.0.1 -uminiblog --databases miniblog -p'miniblog1234' --add-drop-database --add-drop-table --add-drop-trigger --add-locks --no-data > configs/miniblog.sql
```

修改生成的 Go 代码。

### 读写分离

读写分离（Read/Write Splitting）是一种在数据库管理系统中的分布式架构或负载均衡中使用的技术。它通常用于提高数据库系统的性能和可伸缩性，尤其是在面对高读取和写入负载的情况下。

读写分离的基本思想是将读操作和写操作分开处理，以减轻主数据库服务器的负载。通常，数据库服务器会面临来自应用程序的读取查询和写入操作。读操作通常比写操作频繁，因此可以将读取请求分发给一个或多个只处理读取操作的从数据库服务器，而将写入请求发送到主数据库服务器。

以下是读写分离的一些关键要点：

1. 主数据库服务器：这是应用程序的主要写入点，负责处理所有写入操作（例如插入、更新和删除）。主数据库通常是高可用性的，并具备数据保护机制。
2. 从数据库服务器：这些服务器专门用于处理读取操作，如查询。它们从主数据库服务器复制数据，并定期更新以保持数据的一致性。通常，从数据库服务器可以有多个，以分散读取请求的负载。
3. 负载均衡器：位于应用程序和数据库服务器之间的负载均衡器用于根据请求类型（读取或写入）将请求路由到适当的数据库服务器。负载均衡器可以采用不同的策略，如轮询、随机分配或基于权重的分配，以确保负载均衡。
4. 数据同步：为了确保数据的一致性，从数据库服务器需要定期从主数据库服务器同步数据。这可以通过复制、镜像、日志传输等技术来实现。

优势和挑战：

- 优势：读写分离可以提高数据库性能和可伸缩性，通过将读取操作分散到多个从服务器上，减轻了主服务器的负载。这有助于提高应用程序的响应时间和容量。
- 挑战：实施读写分离需要解决数据一致性和同步的问题，以确保从服务器上的数据与主服务器保持一致。此外，复杂的配置和管理可能会增加系统的复杂性。

总之，读写分离是一种用于改善数据库性能和可伸缩性的重要技术，特别是对于高流量的应用程序。它需要谨慎的规划和配置，以确保数据一致性和高可用性。

考虑连接池、错误处理、数据同步等更多因素是非常重要的，尤其是在实际生产环境中使用读写分离时。下面是一个更完善的示例，考虑了这些因素：

```Go
package main

import (
        "database/sql"
        "fmt"
        "log"
        "sync"

        _ "github.com/go-sql-driver/mysql"
)

var (
        masterDB *sql.DB
        slaveDB  *sql.DB
)

func init() {
        // 初始化主数据库连接池
        var err error
        masterDB, err = sql.Open("mysql", "username:password@tcp(master_server:3306)/database_name")
        if err != nil {
                log.Fatal(err)
        }

        // 初始化从数据库连接池
        slaveDB, err = sql.Open("mysql", "username:password@tcp(slave_server:3306)/database_name")
        if err != nil {
                log.Fatal(err)
        }
}

func main() {
        defer masterDB.Close()
        defer slaveDB.Close()

        // 设置连接池的最大连接数和空闲连接数
        masterDB.SetMaxOpenConns(10)
        masterDB.SetMaxIdleConns(5)
        slaveDB.SetMaxOpenConns(10)
        slaveDB.SetMaxIdleConns(5)

        var wg sync.WaitGroup

        // 示例：从从数据库读取数据
        wg.Add(1)
        go func() {
                defer wg.Done()

                query := "SELECT * FROM your_table"
                rows, err := slaveDB.Query(query)
                if err != nil {
                        log.Fatal(err)
                }
                defer rows.Close()

                for rows.Next() {
                        var id int
                        var name string
                        err := rows.Scan(&id, &name)
                        if err != nil {
                                log.Fatal(err)
                        }
                        fmt.Printf("Read from slave - ID: %d, Name: %s\n", id, name)
                }
        }()

        // 示例：向主数据库写入数据
        wg.Add(1)
        go func() {
                defer wg.Done()

                insertQuery := "INSERT INTO your_table (name) VALUES (?)"
                _, err := masterDB.Exec(insertQuery, "New Data")
                if err != nil {
                        log.Fatal(err)
                }

                fmt.Println("Write to master - Data inserted into the master database.")
        }()

        wg.Wait()
}
```

这个示例中，我们使用了连接池来管理数据库连接，设置了最大连接数和空闲连接数以避免资源泄漏。同时，我们启动了两个并发的 goroutine，一个从从数据库读取数据，另一个向主数据库写入数据。这个示例还包括了错误处理来捕获潜在的问题。

数据同步的部分通常是由数据库管理系统本身处理的，例如 MySQL 的主从复制。你需要配置数据库以确保数据在主数据库上的写入会被复制到从数据库上，以保持数据一致性。这不在这个示例的范围内，因为这通常是数据库管理员的任务。

请确保根据你的实际需求和系统配置进行适当的调整和优化。

## X-Request-ID

在实际应用开发中，经常会有这么一种场景：一个用户执行某次操作失败，这时候找你定位、修复问题。然后会提供给你一些基本的请求信息，供你定位。

定位问题的时候，绝大部分情况下，都需要查找日志，发现问题。但是，用户给你的信息，可能不足以查找到问题，也可能查找到的日志，并不是他需要定位的那次请求，这个时候该怎么办呢？

当前最好的方法，是在每次请求中都注入一个 RequestID，并且在每条日志中，输出该 RequestID。这样用户只需要提供给你一个唯一的 RequestID，你就能够定位到跟这次请求相匹配的所有日志，加快问题修复速度和准度。所以，这时候我们需要实现以下部分功能：

1. 在请求中注入 RequestID；
2. 在日志中打印 RequestID。

### 给请求添加 X-Request-ID

要在请求中注入 RequestID，根据 HTTP 请求/返回头的格式，我们需要一个 Header Key。为了便于大家理解哪个 Header Key 指代的是 RequestID，我们采用当前用的最多的 Header Key 命名：`X-Request-ID`。

`X-Request-ID` 可以是任何全局唯一的值，实际开发中，通常使用 32 位的 UUID，例如：`b55696f0-dac9-47d3-a3ed-00db20685295`。

你可以使用 `github.com/google/uuid` 包提供的 `New` 方法来生成。当然，社区有很多包可以生成 UUID，当前我喜欢使用 `github.com/google/uuid` 来生成，因为该包使用起来很简单。

那么， 我现在有了 UUID，如何开发一个 Gin 中间件，将 `X-Request-ID` 注入到请求头中呢？这里，我们先来看下 `r.Use` 方法的入参格式：

```SCSS
scss
复制代码Use(middleware ...HandlerFunc) IRoutes
```

`Use` 方法的入参是一个 Gin 中间件，从 `Use` 的入参我们知道，Gin 中间件，其实是一个 `type HandlerFunc func(*Context)` 类型的函数。所以，我们只需要返回一个 `gin.HandlerFunc` 类型的 function 即可。也可以这么来实现：

```Go
go复制代码package middleware

import (
    "github.com/gin-gonic/gin"    
    "github.com/google/uuid"        
)                      

func RequestID() gin.HandlerFunc {        
    return func(c *gin.Context) {                    
        requestID := c.Request.Header.Get("X-Request-ID")                              

        if requestID == "" {                            
            requestID = uuid.New().String()                                                  
        }                                                              

        // 将 RequestID 保存在 gin.Context 中，方便后边程序使用                                                            
        c.Set("X-Request-ID", requestID)                                                                              

        // 将 RequestID 保存在 HTTP 返回头中，Header 的键为 `X-Request-ID`                                                                            
        c.Writer.Header().Set("X-Request-ID", requestID)                                                                                              
    }                                                                                                      
}  
```

上述代码创建了一个 32 位的 UUID，并分别设置在 `*gin.Context` 和 HTTP 返回头中。

上面，我们分析过，我们也需要在日志中打印这个 `X-Request-ID`，为了方便从 `*gin.Context` 中获取 `X-Request-ID`，我们将其 Key 名字保存在一个共享包中 `known` 中，见：[known.go#L10](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs11%2Finternal%2Fpkg%2Fknown%2Fknown.go%23L10)。

所以，最后我们开发的 RequestID 中间件代码如下：

```SCSS
scss复制代码// RequestID 是一个 Gin 中间件，用来在每一个 HTTP 请求的 context, response 中注入 `X-Request-ID` 键值对.
func RequestID() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 检查请求头中是否有 `X-Request-ID`，如果有则复用，没有则新建
        requestID := c.Request.Header.Get(known.XRequestIDKey)

        if requestID == "" {
            requestID = uuid.New().String()
        }

        // 将 RequestID 保存在 gin.Context 中，方便后边程序使用
        c.Set(known.XRequestIDKey, requestID)

        // 将 RequestID 保存在 HTTP 返回头中，Header 的键为 `X-Request-ID`
        c.Writer.Header().Set(known.XRequestIDKey, requestID)
        c.Next()
    }
}
```

这里，你可能发现，上述代码中有一个 `c.Next()` 调用。Gin 为中间件功能提供了 2 个核心方法，在开发中间件时会经常被用到：

- `c.Next()`：在中间件中调用 `Next()` 方法，`Next()` 方法之前的代码会在到达请求方法前执行，`Next()` 方法之后的代码则在请求方法处理后执行，例如：

```SCSS
scss复制代码func MyMiddleware(c *gin.Context){
    //请求前
    c.Next()
    //请求后
}
```

- `c.Abort()`：在中间件中调用 `Abort()` 方法，会直接终止请求。

> 提示：`RequestID()` 中间件中的 `c.Next()` 之后，并没有处理逻辑，这里只起到示例作用。

### 在日志中打印 X-Request-ID

那么如何在日志中，输出每一次请求的 `X-Request-ID` 呢？这时候，我们就需要定制化日志包，这也是我们为什么要基于开源日志包定制化开发项目独有日志包的一个原因。

这里，我们介绍下 miniblog 的实现方式，这种方式也是业界最普遍的实现方式，你也可以理解为最佳实践。实现思路如下：在日志包中添加 `C(ctx context.Context) *zapLogger` 方法，`C` 方法中尝试从 `ctx` 中获取期望的 Key，如果值不为空，则调用 `*zap.Logger` 的 `With` 方法，将 `X-Request-ID` 添加到日志输出中。实现代码如下：

```Go
go复制代码// C 解析传入的 context，尝试提取关注的键值，并添加到 zap.Logger 结构化日志中.
func C(ctx context.Context) *zapLogger {                              
    return std.C(ctx)                               
}                                                   
          
func (l *zapLogger) C(ctx context.Context) *zapLogger {                    
    lc := l.clone()                                    
                                                               
    if requestID := ctx.Value(known.XRequestIDKey); requestID != nil {
        lc.z = lc.z.With(zap.Any(known.XRequestIDKey, requestID))
    }                                                                 
                                                    
    return lc                                                                
}                          
                                                                              
// clone 深度拷贝 zapLogger.            
func (l *zapLogger) clone() *zapLogger {                       
    lc := *l           
    return &lc                     
}
```

这里需要注意，因为 `log` 包被多个请求并发调用，为了防止 `X-Request-ID` 污染，针对每一个请求，我们都深拷贝一个 `*zapLogger` 对象，然后再添加 `X-Request-ID`。

### 添加 RequestID 中间件

在我们开发完了 `RequestID` 中间件之后，还需要通过 Gin 框架提供的 `Use` 方法加载这个中间件。为了使所有的请求都具有 `X-Request-ID`，我们将 `RequestID` 设置为全局中间。加载方法用伪代码展示如下：

```Go
go复制代码import mw "github.com/marmotedu/miniblog/internal/pkg/middleware"

g := gin.New()
mws := []gin.HandlerFunc{mw.RequestID()}
g.Use(mws...)
```

miniblog 最终加载 `RequestID` 中间件的代码实现见：[internal/miniblog/miniblog.go#L88](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fmarmotedu%2Fminiblog%2Fblob%2Ffeature%2Fs11%2Finternal%2Fminiblog%2Fminiblog.go%23L88)。

### 测试 `X-Request-ID` 输出

这里，我们编写代码来测试日志输出中是否被正确添加了 `X-Request-ID` 字段。我们改造 `/healthz` 路由方法，当 `/healthz` 被调用时，打印一条调用日志：

```JavaScript
javascript复制代码    // 注册 /healthz handler.
    g.GET("/healthz", func(c *gin.Context) {
        log.C(c).Infow("Healthz function called")

        c.JSON(http.StatusOK, gin.H{"status": "ok"})
    })
```

编译启动服务并测试：

```Shell
shell复制代码$ make
$ _output/miniblog -c configs/miniblog.yaml
```

打开另外一个 Linux 终端，请求 `/healthz`：

```Ruby
ruby复制代码$ curl http://127.0.0.1:8080/healthz
{"status":"ok"}
```

查看 miniblog 服务输出，发现 `X-Request-ID` 字段被成功添加到了日志输出中：

```Bash
bash复制代码$ _output/miniblog -c configs/miniblog.yaml 
2022/11/30 16:00:26 maxprocs: Leaving GOMAXPROCS=16: CPU quota undefined
[GIN-debug] [WARNING] Running in "debug" mode. Switch to "release" mode in production.
 - using env:        export GIN_MODE=release
 - using code:        gin.SetMode(gin.ReleaseMode)

[GIN-debug] GET    /healthz                  --> github.com/marmotedu/miniblog/internal/miniblog.run.func2 (6 handlers)
2022-11-30 16:00:26.662        info        miniblog/miniblog.go:114        Start to listening the incoming requests on http address        {"addr": ":8080"}
2022-11-30 16:01:24.960        info        miniblog/miniblog.go:104        Healthz function called        { "X-Request-ID" : "abcba2c3-0099-42e1-95cd-893c88a31a6c" } 
```

## 跨域

### 为什么会出现跨域

先来看下，为什么会出现跨域。原因如下：

- 出于浏览器的同源策略限制。同源策略（Sameoriginpolicy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说 Web 是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。同源策略会阻止一个域的 javascript 脚本和另外一个域的内容进行交互；
- 所谓同源（即指在同一个域）就是两个页面具有**相同的协议（protocol），主机（host）和端口号（port）**；
- 非同源限制：
  - 无法读取非同源网页的 Cookie、LocalStorage 和 IndexedDB；
  - 无法接触非同源网页的 DOM；
  - 无法向非同源地址发送 AJAX 请求。

简单来说就是：当一个资源去访问另一个不同源资源时，就会发出跨域请求。如果此时另一个资源不允许其进行跨域资源访问，那么访问的那个资源就会遇到跨域问题。

### **使用跨域资源共享（CORS）来跨域**

解决跨域问题的方法有多种，例如：CORS、Nginx 反向代理、JSONP 跨域等。在 Go 后端服务开发中，通常可以使用 CORS 来解决跨域问题。

CORS 是一个 W3C 标准，全称是"跨域资源共享"（Cross-origin resource sharing）。它允许浏览器向跨域服务器，发出 AJAX 请求，从而克服了 AJAX 只能同源使用的限制。例如：当一个请求 URL 的协议、域名、端口三者之间任意一个与当前页面的 URL 不同即为跨域。案例如下：

| 当前页面 URL                                                 | 被请求页面 URL                                               | 是否跨域 | 原因                           |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- | ------------------------------ |
| [www.example.com/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%2F) | [www.example.com/index.html](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%2Findex.html) | 否       | 同源（协议、域名、端口号相同） |
| [www.example.com/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%2F) | [www.example.com/index.html](https://link.juejin.cn/?target=https%3A%2F%2Fwww.example.com%2Findex.html) | 跨域     | 协议不同（HTTP / HTTPS）       |
| [www.example.com/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%2F) | [www.baidu.com/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.baidu.com%2F) | 跨域     | 主域名不同（example / baidu）  |
| [www.example.com/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%2F) | [blog.example.com/](https://link.juejin.cn/?target=http%3A%2F%2Fblog.example.com%2F) | 跨域     | 子域名不同（www / blog）       |
| [www.example.com:8080/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%3A8080%2F) | [www.example.com:7001/](https://link.juejin.cn/?target=http%3A%2F%2Fwww.example.com%3A7001%2F) | 跨域     | 端口号不同（8080 / 7001）      |

在使用 CORS 的时候，HTTP 请求会被划分为两类：简单请求和复杂请求，而这两种请求的区别主要在于是否会触发 CORS 预检请求。简单请求和复杂请求具体定义如下：

- **简单请求：** 请求方法是 `GET`、`HEAD` 或者 `POST`，并且 HTTP 请求头中只有 `Accept/Accept-Language/Content-Language/Last-Event-ID/Content-Type` 6 种类型，且 `Content-Type` 只能是 `application/x-www-form-urlencoded`, `multipart/form-data` 或着 `text` / `plain` 中的一个值。简单请求会在发送时自动在 HTTP 请求头加上 `Origin` 字段，来标明当前是哪个源(协议 + 域名 + 端口)，服务端来决定是否放行。
- **复杂请求：** 如果一个请求不是简单请求，则为复杂请求。

CORS 需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能。浏览器一旦发现 AJAX 请求跨源，就会自动添加一些附加的头信息，复杂请求还会多出一次附加的预检请求，但用户不会有感觉。因此，实现 CORS 通信的关键是服务器。只要服务器实现了 CORS 接口，就可以跨源通信（在 Header 中设置：`Access-Control-Allow-Origin`）



### 简单请求的 CORS 跨域处理

对于简单请求，浏览器直接发出 CORS 请求。具体来说，就是在头信息之中，增加一个 `Origin` 字段：

```Plaintext
origin: https://wetv.vip
```

服务器需要处理这个头部，并填充返回头 `Access-Control-Allow-Origin`：

```Plaintext
arduino
复制代码access-control-allow-origin: https://wetv.vip
```

此头部也可填写为 `*`，表示接受任意域名的请求。如果不返回这个头部，浏览器会抛出跨域错误。（注：服务器端不会报错）



### 复杂请求的 CORS 跨域处理

复杂请求的 CORS 请求，会在正式通信之前，增加一次 HTTP 查询请求，称为"预检"请求（`preflight`）。"预检"请求用的请求方法是`OPTIONS`，表示这个请求是用来询问请求能否安全送出的。

当后端收到预检请求后，可以设置跨域相关 Header 以完成跨域请求。支持的 Header 具体如下表所示：

| 返回头                           | 说明                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| Access-Control-Allow-Origin      | 必选，设置允许访问的域名                                     |
| Access-Control-Allow-Methods     | 必选，逗号分隔的字符串，表明服务器支持的所有跨域请求的方法   |
| Access-Control-Allow-Headers     | 逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在"预检"中请求的字段。如果浏览器请求包括 `Access-Control-Request-Headers` 字段，则此字段是必选的 |
| Access-Control-Allow-Credentials | 可选，布尔值，默认是`false`，表示不允许发送 Cookie           |
| Access-Control-Max-Age           | 指定本次预检请求的有效期，单位为秒。可以避免频繁的预检请求   |

预检通过后，浏览器就正常发起请求和响应，流程和简单请求一致。

```Go
//注意执行的顺序   
mws := []gin.HandlerFunc{ mw.NoCache, mw.Cors, mw.Secure}
    g.Use(mws...)

// NoCache 是一个 Gin 中间件，用来禁止客户端缓存 HTTP 请求的返回结果.确保每次请求都从服务器获取最新的数据。
func NoCache(c *gin.Context) {
        c.Header("Cache-Control", "no-cache, no-store, max-age=0, must-revalidate, value")
        c.Header("Expires", "Thu, 01 Jan 1970 00:00:00 GMT")
        c.Header("Last-Modified", time.Now().UTC().Format(http.TimeFormat))
        c.Next()
}

// Cors 是一个 Gin 中间件，用来设置 options 请求的返回头，然后退出中间件链，并结束请求(浏览器跨域设置).
//如果 HTTP 请求不是 OPTIONS 跨域请求，则继续处理 HTTP 请求；
//如果 HTTP 请求时 OPTIONS 跨域请求，则设置跨域 Header，并返回。
func Cors(c *gin.Context) {
        if c.Request.Method != "OPTIONS" {
                c.Next()
        } else {
                c.Header("Access-Control-Allow-Origin", "*")
                c.Header("Access-Control-Allow-Methods", "GET,POST,PUT,PATCH,DELETE,OPTIONS")
                c.Header("Access-Control-Allow-Headers", "authorization, origin, content-type, accept")
                c.Header("Allow", "HEAD,GET,POST,PUT,PATCH,DELETE,OPTIONS")
                c.Header("Content-Type", "application/json")
                c.AbortWithStatus(200)
        }
}

// Secure 是一个 Gin 中间件，用来添加一些安全和资源访问相关的 HTTP 头.
func Secure(c *gin.Context) {
        c.Header("Access-Control-Allow-Origin", "*")
        c.Header("X-Frame-Options", "DENY")
        c.Header("X-Content-Type-Options", "nosniff")
        c.Header("X-XSS-Protection", "1; mode=block")
        if c.Request.TLS != nil {
                c.Header("Strict-Transport-Security", "max-age=31536000")
        }
}
```



## 优雅关停





## JWT认证

在企业应用开发中，保证应用的安全至关重要，通常通过以下 3 种手段来保证应用的安全：

- **认证（Authentication，简称 Authn）：** 一般指身份验证，指通过一定的手段，完成对用户身份的确认。认证用来证明你是谁。
- **授权（Authorization，简称 Authz）：** 授权发生在身份认证成功之后，用来确认你对某个资源是否有某类操作权限。授权用来证明你能做什么。
- **网络环境：** 比如将服务部署在一个隔离的网络环境中（物理隔离/软件隔离），对访问应用的来源 IP 设置防火墙限制，或者部署一些网络监控插件，用来监控异常的网络请求等。

本节课我们就来学下，如何实现用户的身份认证。身份认证是最简单，也是最基本的应用安全保障手段，基本上每一个对外的应用都需要实现身份认证功能。

### 常用的身份验证手段

当前业界有很多身份认证手段，例如：基础认证（用户名密码认证）、摘要认证（Digest 认证）、开放授权（OAuth 认证）、令牌认证（Bearer 认证）等。

在前后端分离架构中，最常用的认证方式为基础认证+令牌认证：

- **基础认证：** 通过`<用户名 + 密码>`登录系统；
- **令牌认证：** 令牌认证通过 Token 来进行认证，当前最流行的 Token 编码方式是 JWT。



这里来解释下，为什么在前后端分离架构中需要基础认证 + 令牌认证 2 种认证方式，来共同实现身份认证。

在前后端分离架构中，用户通过控制台登录系统，需要使用一种简单、易用的认证方式，来完成用户身份认证，当前最简单的方式就是 `<用户名 + 密码>` 这种认证方式。当然，这里的用户名也可以是手机号/邮箱。

> 提示：当前还有很多系统使用短信来验证，因为短信验证依赖于第三方接口，不太适合教学项目，所以本实战项目只采用了 `<用户名 + 密码>` 这种形式。

`<用户名 + 密码>` 认证方式的流程为：后台根据用户名查询到用户保存在数据库中加密后的密码串，并加密传入的密码，根据 2 次加密后的密码是否匹配，来验证用户控制台传入的密码是否是设置的密码。

用户登录控制台后，需要做多个操作，如果每次都传入用户名和密码，后台从数据库中查询出已加密的密码并对比，整个过程体验并不友好，并且因为要查询数据进行认证，所以接口性能并不好。那么有没有一种好的方式来解决这种问题呢？

当然是有的，业界当前最通用的方案是：在第一次登录之后产生一个有一定有效期的 token，并将其存储于浏览器的 Cookie 或 LocalStorage 之中，之后的请求都携带该 token，请求到达服务器端后，服务器端用该 token 对请求进行鉴权。

在第一次登录之后，服务器会将这个 token 用文件、数据库或缓存服务器等方法存下来，用于之后请求中的比对。或者，更简单的方法是，直接用密钥对用户信息和时间戳进行签名对称加密，这样就可以省下额外的存储，也可以减少每一次请求时对数据库的查询压力。这种方式，在业界已经有一种标准的实现方式，该方式被称为 JSON Web Token（JWT，音同 jot，详见 [JWT RFC 7519](https://link.juejin.cn/?target=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc7519)）。

> 提示：token 的意思是“令牌”，里面包含了用于认证的信息。这里的 token 是指 JSON Web Token（JWT）。

### JWT 认证流程

学习 JWT 最好的方式是通过其认证流程来学习其原理。认证流程如下图所示：

![202407092233031](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111911409.webp)

1. 客户端（通常是控制台）使用用户名和密码登录；
2. 服务端收到请求后会去验证用户名和密码，如果用户名和密码跟数据库记录不一致，则验证失败，如果一致则验证通过，服务端会签发一个 Token 返回给客户端；
3. 客户端收到请求后会将 Token 缓存起来，比如放在浏览器 Cookie 中或者本地存储中，之后每次请求都会携带该 Token；
4. 服务端收到请求后会验证请求中携带的 Token，验证通过则进行业务逻辑处理并成功返回数据。

### JWT Token 格式

在 JWT 中，Token 有三部分组成，中间用 `.` 隔开，并使用 Base64 编码：

- header；
- payload；
- signature。

如下是 JWT 中的一个 Token 示例：

```Plaintext
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MjgwMTY5MjIsImlkIjowLCJuYmYiOjE1MjgwMTY5MjIsInVzZXJuYW1lIjoiYWRtaW4ifQ.LjxrK9DuAwAzUD8-9v43NzWBN7HXsSLfebw92DKd1JQ
```



#### header 介绍

JWT Token 的 header 中，包含两部分信息：

- Token 的类型；
- Token 所使用的加密算法。

例如：

```JSON
json复制代码{
  "typ": "JWT",
  "alg": "HS256"
}
```

该例说明 Token 类型是 JWT，加密算法是 HS256（alg 算法可以有多种）。



#### Payload 载荷介绍

Payload 中携带 Token 的具体内容，里面有一些标准的字段，当然你也可以添加额外的字段，来表达更丰富的信息，可以用这些信息来做更丰富的处理，比如记录请求用户名，标准字段有：

- `iss`：JWT Token 的签发者；
- `sub`：主题；
- `exp`：JWT Token 过期时间；
- `aud`：接收 JWT Token 的一方；
- `iat`：JWT Token 签发时间；
- `nbf`：JWT Token 生效时间 ；
- `jti`：JWT Token ID。

本例中的 payload 内容为：

```JSON
json复制代码{
  "id": 2,
  "username": "kong",
  "nbf": 1527931805,
  "iat": 1527931805
}
```



"Claims" 和 "Payload"

**"Claims" 是"Payload" 的一部分**，它们包含在令牌或其他数据传输中的有效负载中，用于传递身份和授权信息。"Payload" 是一个更广泛的术语，可用于描述任何数据传输的主要数据部分，而不仅仅是身份验证和授权令牌。

1. "Claims"（声明）:
   1. "Claims" 是一种广泛用于身份验证和授权系统中的术语，通常指代与令牌相关的声明或声明的集合。这些声明可以包括用户的身份信息、访问权限、角色等等。
   2. "Claims" 是一种结构化数据，通常以键-值对的形式存在，用于传递用户信息和授权决策的信息。它们包含在令牌的有效负载中，供应用程序或服务使用。
2. "Payload"（有效负载）:
   1. "Payload" 是一个更通用的术语，通常用于描述数据传输或通信中的有效数据部分。有效负载可以包含各种数据，包括"Claims" 以外的内容。
   2. 在上下文中，"Payload" 可能指代令牌、消息、数据包或其他数据传输中的主要数据部分，包括"Claims" 以及其他相关数据。
   3. "Payload" 不仅用于描述身份验证和授权令牌，还可以用于描述网络通信、数据包传输、文件格式等等。





#### Signature 签名介绍

`Signature` 是 Token 的签名部分，通过如下方式生成：

1. 用 Base64 对 header.payload 进行编码；
2. 用 Secret 对编码后的内容进行加密，加密后的内容即为 `Signature`。

Secret 相当于一个密码，存储在服务端，一般通过配置文件来配置 Secret 的值，本例是配置在 `configs/miniblog.yaml` 配置文件中:

```YAML
yaml复制代码# 通用配置
runmode: debug               # Gin 开发模式, 可选值有：debug, release, test
addr: :8080                  # HTTP 服务器监听地址
jwt-secret:  Rtg8BPKNEf2mB4mgvKONGPZZQSaJWNLijxR42qRgq0iBb5  # JWT 签发密钥
```

最后生成的 Token 像这样：

```Plaintext
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpYXQiOjE1MjgwMTY5MjIsImlkIjowLCJuYmYiOjE1MjgwMTY5MjIsInVzZXJuYW1lIjoiYWRtaW4ifQ.LjxrK9DuAwAzUD8-9v43NzWBN7HXsSLfebw92DKd1JQ
```

#### 验证

签名后服务端会返回生成的 Token，客户端下次请求会携带该 Token，服务端收到 Token 后会解析出 `header.payload`，然后用相同的加密算法和密码对 `header.payload` 再进行一次加密，并对比加密后的 Token 和收到的 Token 是否相同，如果相同则验证通过，不相同则返回 `HTTP 401 Unauthorized` 的错误。

1. 如果两个签名匹配，表示 Token 未被篡改，且数据完整，验证通过。

再次加密的目的是确保客户端传递的 Token 在传输过程中没有被篡改或损坏。如果 Token 是明文传输的，攻击者可能会截取或篡改 Token，导致未经授权的访问或数据泄露。签名验证是一种在不加密整个 Token的情况下验证 Token 完整性的有效方法。



### 请求头格式

```Shell
curl --location 'http://139.224.32.57:8080/v1/users/belma' \
--header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJYLVVzZXJuYW1lIjoiYmVsbWEiLCJleHAiOjIwNTg3NDc4NDcsImlhdCI6MTY5ODc0Nzg0NywibmJmIjoxNjk4NzQ3ODQ3fQ.rDRfy1nms3yLTeDHc3Ugv5RQoLkkRwUaLz1luMh8X1w'
```

在HTTP请求头部中，通常将身份验证令牌（Token）包含在"**Authorization**"字段中。这是一种标准的做法，可以使用不同的身份验证方案来传递令牌。如果您要在GET请求的首部中携带Token，您可以按照以下方式设置Authorization头：

```Plaintext
Authorization: Bearer 1234
```

上面的代码中，"Bearer"是一种常见的身份验证方案，通常用于OAuth和JWT等令牌身份验证方法。您可以将您的Token（这里是1234）替换为您实际的身份验证令牌。这样设置Authorization头后，服务器将能够识别并验证请求中携带的Token。如果您使用其他身份验证方案，可能需要调整Authorization字段的值以匹配该方案的要求。





### 续签

续签一般来说就是检测到token过期时，跳转到重新登录。

复杂一点的，就是签发双token方案，一个token用于发送请求，一个token用于续签token（它的有效期比较长）。请求的token过期时，使用续签的token去重新申请token,如果用于续签的token也过期了，就要重新登录。



------



## FFmpeg/ libx264

### libx264

1. **获取源代码：** 如果您还没有 `libx264` 的源代码，您可以从官方仓库中获取。

```Bash
git clone https://code.videolan.org/videolan/x264.git
cd x264
```

1. **配置和编译：** 进入 `x264` 目录后，运行以下命令进行配置和编译。

```Bash
./configure --prefix=/usr/local --enable-shared
make
```

1. 请注意，`--prefix=/usr/local` 将安装路径设置为 `/usr/local`，您可以根据需要进行调整。
2. **安装：** 编译完成后，运行以下命令安装 `libx264`。

```Bash
sudo make install
```

1. **更新库缓存：** 重新编译安装后，更新库缓存。

```Bash
sudo ldconfig
```

1. **配置 pkg-config：** 确保 `pkg-config` 能够找到 `libx264` 的配置。在 `/usr/local/lib/pkgconfig` 目录中，应该存在一个名为 `x264.pc` 的文件。您可以检查其中的配置是否正确。
2. **重新编译 FFmpeg：** 在重新编译 `libx264` 并安装后，尝试重新运行 FFmpeg 的 `configure` 命令。

```Bash
cd /path/to/ffmpeg  # 进入 FFmpeg 源代码目录
./configure --enable-shared --enable-libx264 --enable-gpl
make
sudo make install
```

1. 7.**指定 x264 的 pkg-config 路径**：如果你安装的 x264 开发包不在默认的 pkg-config 搜索路径中，你可以通过设置 `PKG_CONFIG_PATH` 环境变量来指定 pkg-config 的搜索路径。

```Plaintext
export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
```

将 `/path/to/x264` 替换为实际的 x264 安装路径。 /usr/local/lib

如果重新编译 `libx264` 后问题仍然存在，可能需要进一步检查您的环境和配置。如果问题仍然困扰着您，您可能需要联系 FFmpeg 的支持渠道，以获取更专业的帮助。

### FFmpeg

重新编译 FFmpeg 并启用 libx264 支持需要以下步骤：

1. **下载 FFmpeg 源代码**：首先，你需要获取 FFmpeg 的源代码。你可以从官方网站下载或通过版本控制系统（如 Git）获取。下面是通过 Git 获取源代码的示例：

```Bash
git clone https://github.com/FFmpeg/FFmpeg.git
cd FFmpeg
```

1. **配置 FFmpeg 编译选项**：运行 `./configure` 命令来配置编译选项，并在其中添加 `--enable-libx264` 选项以启用 x264 支持。你可以根据需要添加其他选项。

```Bash
./configure --enable-shared --enable-libx264 --enable-gpl --extra-ldflags=-L/usr/local/lib
```

1. 注意，这里的 `--enable-libx264` 是关键选项，它会启用 x264 支持。
2. **编译 FFmpeg**：运行 `make` 命令来编译 FFmpeg。这个过程可能需要一些时间。

```Bash
make
```

1. **安装 FFmpeg**：运行 `sudo make install` 命令以管理员权限来安装编译好的 FFmpeg。

```Bash
sudo make install
```

1. **验证 x264 支持**：重新编译和安装后，你可以再次运行以下命令来验证 x264 支持是否已启用：

```Bash
ffmpeg -codecs | grep libx264
```

1. 如果输出中包含了类似 `(encoders: libx264 ...)` 的信息，表示 x264 支持已经启用。

请注意，上述步骤可能会因操作系统、软件版本和其他因素而有所不同。确保你已经安装了编译 FFmpeg 所需的依赖项，并根据实际情况调整上述命令。如果你遇到任何问题，可以参考 FFmpeg 官方文档、相关社区或论坛，寻求更多帮助。

### 视频处理

#### 视频压缩

这段代码是一个用于压缩视频的Go函数。视频压缩的质量和压缩率由FFmpeg中的参数来控制。在你的代码中，使用了以下参数：

1. `-i`：指定输入视频文件的路径。
2. `-c:v libx264`：指定视频编码器为libx264，这是一种常用的视频编码器。
3. `-crf 18`：设置视频的压缩质量。CRF（Constant Rate Factor）是一种控制压缩质量的方法，18是一个比较高的质量值，表示相对较低的压缩率，但较高的质量。
4. `-y`：启用了覆盖选项，表示如果输出文件已经存在，将自动覆盖它。
5. `outputVideoPath`：指定输出视频文件的路径，输出文件名是在输入文件名的基础上添加了"CMP"后缀。

CRF（Constant Rate Factor）的值通常在0到51之间，其中0表示无损压缩，51表示最低质量的压缩。一般来说，常见的CRF值范围为18到28之间，这个范围提供了一个很好的平衡，能够在保持相对高质量的同时控制文件大小。

以下是一些常见的CRF值和它们的一般使用场景：

- CRF 0：无损压缩，保持最高质量，但文件大小很大，一般不常用。
- CRF 18-20：非常高质量，适用于对视频质量要求很高的情况，如专业视频制作。
- CRF 21-23：高质量，适用于大多数一般用途，质量良好，文件大小适中。
- CRF 24-28：良好的质量，适用于在线视频分享、YouTube等。
- CRF 29-35：中等质量，适用于需要节省带宽或存储空间的情况。
- CRF 36-51：低质量，文件小，但视频质量明显下降，适用于带宽有限或存储空间有限的情况。

```Go
// 压缩视频
func compressVideo(inputVideoPath string) (string, error) {
        outputVideoPath := strings.TrimSuffix(inputVideoPath, ".mp4") + "CMP.mp4"
        command := []string{
                "-i", inputVideoPath,
                "-c:v", "libx264",
                //"-b:v", "1M", // 使用比特率代替 -crf
                "-crf", "51", //较高的CRF值会减小文件大小但可能降低视频质量
                "-y", // This option enables overwriting without asking
                outputVideoPath,
        }
        cmd := exec.Command("ffmpeg", command...)

        // 打开已存在的日志文件，如果不存在则创建
        logFile, err := os.OpenFile("../logs", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
        if err != nil {
                return outputVideoPath, err
        }
        defer logFile.Close()

        cmd.Stderr = logFile // 将stderr重定向到指定的日志文件
        // cmd.Stderr = os.Stderr // 将stderr重定向到控制台以查看错误消息

        err = cmd.Run()
        if err != nil {
                logger.Debug("Error compressing video:", err)
                return outputVideoPath, err
        }

        return outputVideoPath, nil
}
```

#### 提取封面

```Go
// 截取封面
func generateVideoCover(videoPath string) (string, error) {
        // 使用 ffmpeg 获取视频的第一帧作为封面
        coverFilename := strings.TrimSuffix(videoPath, ".mp4") + "_cover.jpg"
        command := []string{
                "-i", videoPath,
                "-ss", "00:00:01",
                "-vframes", "1",
                coverFilename,
        }
        cmd := exec.Command("ffmpeg", command...)

        // 打开已存在的日志文件，如果不存在则创建
        logFile, err := os.OpenFile("../logs", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
        if err != nil {
                return "", err
        }
        defer logFile.Close()

        cmd.Stderr = logFile // 将stderr重定向到指定的日志文件
        //cmd.Stderr = os.Stderr // Redirect stderr to console for error messages

        err = cmd.Run()
        if err != nil {
                fmt.Println("Error generating cover:", err)
                return "", err
        }
        return coverFilename, nil
}
```

## 权限控制

### 什么是RBAC？

RBAC允许您通过分配一组权限来创建和实施高级访问。权限基于特定用户类别执行其职责所需的访问级别。换句话说，公司中的不同人员可以完全基于其工作职能和职责等因素拥有完全不同的访问权限级别和类型。

例如，人力资源部员工可以查看员工记录，但不能查看客户数据。人力资源经理可以删除或更改人力资源记录，而较低级别的人力资源专家只能查看这些记录。

美国国家标准与技术研究院（NIST）引入了RBAC方法，作为自主访问控制（DAC）的更好替代方案。使用RBAC，可以为每个用户分配一个或多个角色，然后为这些角色分配允许的权限。用户可以是员工、承包商、业务合作伙伴等，这些类别中的每个角色都具有预定义的权限。当个人的职责或职能发生变化时，例如，由于晋升或部门调动，该人员被分配到RBAC系统中的新角色。

#### 什么是RBAC中的角色？

在RBAC框架中，角色是用于构建权限的语义结构。角色可以由任意数量的标准定义，包括权限、职责、成本中心和业务部门。

角色本质上是指用户权限的集合。这与传统的用户群不同，后者是用户的集合。在RBAC的上下文中，权限与角色绑定，而不是与身份直接连接。

角色比组更稳定，因为角色是围绕访问管理组织的，在一个典型的组织中，功能和活动的变化不像身份那样频繁。

#### 什么是RBAC中的权限？

权限（permission）即授予对受保护对象执行操作的批准的权限集。这里的受保护对象指的可以是应用中所有的内容，包括数据、模块、菜单、页面、字段、操作功能（增删改查）等等。同时，对于不同的权限可以使用不同的RBAC模型，分别管理或同一管理（即在一个系统中不一定仅使用一种RBAC模型）。例如在可以将页面访问权限与页面内的增删改查的操作权限一起基于RBAC0管理，数据权限（数据隔离）基于RBAC1实现，再为用户分配几种权限的组合。详情可查看 **RBAC 的实践** 一章。

#### NIST标准包含的4级RBAC模型

**RBAC0（Core RBAC）**：基本模型有三个元素：用户、角色和权限。模型设计基于“多对多”原则，即多个用户可以具有相同的角色，一个用户可以具有多个角色。同样，您可以将同一权限分配给多个角色，也可以将同一角色分配给多个权限。

**RBAC1（Hierarchical RBAC）**：添加了第四个组件-层次结构，它定义了不同角色之间的资历关系。通过允许高级角色自动获取下级角色的权限，可以消除冗余，例如在角色重叠时必须指定某些权限。

分层RBAC支持几种类型的层次结构：

**树**：自底向上的层次结构，树底部的元素将权限授予更高的元素。例如，底部是一个具有常规权限的部门角色，所有权限比较小，上面的节点除了继承底部节点的权限，还可以添加自有的权限，这可以满足不同部门拥有不用的权限也有相同的权限的需求。

![202407092234582](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111911291.webp)

**倒树**：自上而下的层次结构，其中高级角色将其部分权限继承给下级角色。这种结构中层节点的权限均继承于底部节点，所以同层节点不存在共享权限。

![202407092234404](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111912609.webp)

**网格：**自下而上和自上而下的组合，其中每个角色都可以从其下方和上方的节点继承权限。此种结构相对比较灵活，既可以有共享权限，也可以有自有权限，且顶级节点拥有最大的权限。

![202407092234645](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111912662.webp)

**RBAC2（Static separation of duty (SSD) relations）**：为了在存在利益冲突策略的情况下提供帮助，将根据用户分配添加角色之间的关系。例如，作为一个角色的成员的用户将无法被指派为具有利益冲突的角色的成员。

**RBAC3（Dynamic separation of duty (DSD) relations）**：与SSD一样，DSD限制了可用的用户权限，但基于不同的上下文。例如，根据会话期间执行的任务，用户可能需要不同级别的访问，DSD限制会话期间激活的权限。

![202407092234717](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111912157.webp)

#### 使用RBAC的好处有哪些？

RBAC最大的优点之一是它提供了一种系统化的方法，用于定义和维护角色，使您能够仅根据用户需要一致地授予访问权限，从而降低数据泄露或数据丢失的风险。

但RBAC还有很多其他好处，包括：

- 通过根据人力资源属性自动为新员工分配访问权限来加速入职
- 简化IT管理工作，例如，通过在全球范围内跨多个平台和应用程序快速重新分配权限
- 改善对欧盟《一般数据保护规则》（GDPR）或美国《健康保险可移植性和责任法案》（HIPAA）等法规的遵守
- 通过为供应商和业务合作伙伴等外部用户提供预定义的角色来降低第三方风险
- 通过在角色更改时自动更新访问权限来维护“最低权限”的最佳实践
- 降低高级访问控制的成本，尤其是在大型复杂环境中

#### RBAC有哪些缺陷？

**需要了解组织结构知识**

没有一种一刀切的方法来定义角色。在决定如何对角色进行分类以及如何管理这些角色的访问权限时，组织必须跨部门协调。这需要清楚地了解组织的理想结构以及支持它的技术基础设施。

在大型或成长中的组织中，如果IT或安全经理需要在没有人力资源或执行决策者帮助的情况下定义角色，这可能是一项艰巨的任务，会变得更加困难。这种简化实施的常见尝试实际上使问题变得更糟，导致与公司更大的目标不一致。

**需要深思熟虑的实施**

分配角色可能是一项挑战。可能会出现很多问题，答案并不总是清晰的。例如：安全团队是否需要访问他们试图保护的数据，包含哪些访问权限（创建/读取/更新/删除）？是否应为用户分配部门之外的角色，以确保临时访问特权文件？

**缺乏灵活性**

RBAC以过于死板著称，这也难怪。组织成长，团队扩张，访问需求发生变化。在RBAC项目开始时定义的角色可能不再符合公司目标。

结果如何？人员的角色和权限级别可能不一致。例如，一个人可能被赋予过多的角色权限、分配过多的角色，或者两者兼而有之。虽然这些努力可能会起到快速修复的作用，但它们也会造成安全漏洞和法规遵从性挑战，从而打消了您最初实施RBAC的全部原因。

**导致角色爆炸**

一些团队试图通过定义越来越细粒度的角色、在出现新需求时创建临时角色，或将太多的角色分配给单个用户来回避上述问题。虽然这可能会在短期内缓解摩擦，但也会让RBAC变得混乱，难以管理。

这个问题通常被称为角色爆炸，是RBAC最常见的反对意见之一。当现实世界中的角色和访问需求与您的政策文件中概述的角色和访问需求不同时，甚至在很小的程度上也会出现这种情况。而作为临时解决方案创建的角色有时管理员可能会忘记或甚至故意选择保留这些角色，即使为其创建这些角色的人员离开或更换组织内的工作。结果是：特权蔓延和混乱。

#### RBAC 的实践

#### Azure RBAC

Azure RBAC可帮助管理员管理对Azure资源的访问，并准确定义可在其中执行的操作。Azure RBAC是基于Azure资源管理器（ARM）的授权系统。

在Azure中分配角色有三个关键要素。

**主体--**请求资源并被授予访问该资源权限的用户、组、服务主体或托管标识。

**角色定义--**对各种Azure资源的一组权限，与分配给主体的角色相关联。它定义了具有特定角色的主体可以对资源执行的操作。

**作用域--**定义角色提供访问的资源以及一个或多个角色的权限级别。

在Azure中，可以直接在管理组、订阅、资源组或单个资源级别定义作用域。作用域具有父子关系，子资源继承父资源的权限。Azure包括几个基于行业最佳实践和Azure资源结构的内置角色。Azure还提供了基于组织角色的自定义RBAC兼容性。

定义角色并将作用域映射到这些角色后，管理员可以使用角色分配来授予对一个或多个安全原则的角色作用域的访问权限。如果组织需要删除访问权限，他们还可以取消角色分配。因此，作用域使权限管理变得更容易。

AWS RBAC与亚马逊Cognito

亚马逊云通过亚马逊Cognito服务提供RBAC。Cognito支持移动和web应用程序的身份验证、授权和用户管理。

Cognito使用用户池的概念，用户池是受管理的用户目录，身份池允许用户访问其他AWS服务。身份池授予用户访问AWS资源的临时有限权限。这些权限是通过Amazon IAM角色创建的。您可以使用令牌将角色分配给应用程序的用户，并利用基于规则的映射将角色分配给用户。

#### RBAC vs. ABAC vs. ACL vs. PBAC

有效的访问控制是在不给用户造成摩擦的情况下保护网络安全的任何方法。虽然RBAC仍然是限制访问的常用方法，但您可能需要考虑其他选项。基于属性的访问控制（ABAC）、访问控制列表（ACL）和基于策略的访问控制（PBAC）是三种选择。

#### RBAC vs. ABAC

组织使用ABAC来实现更细粒度的访问控制，作为RBAC的替代或补充。与RBAC不同的是，ABAC依靠属性组合来匹配用户完成工作所需的资源。关于ABAC的详细内容可参考下文：

[李敢敢：理解ABAC（Attribute based access control）及企业级ABAC架构4 赞同 · 0 评论文章](https://zhuanlan.zhihu.com/p/585968345)

![202407092234077](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111912596.png)

#### RBAC vs. ACL

访问控制列表（ACL）控制或限制数字环境中的流量。ACL规则允许或拒绝两种一般类别的访问：

- 文件系统ACL适用于文件和/或目录。ACL指定允许哪个主体（人类用户或机器/系统进程）访问对象，以及允许对这些对象执行哪些操作。
- 网络ACL适用于网络路由器和交换机。ACL指定可以访问网络的流量类型以及允许的活动。

组织使用ACL和VPN来管理流量。这样做可以提高网络性能，提高安全性，并允许在入口和出口点进行更细粒度的监控。这使得ACL适合保护单个用户和低级数据，但在大多数业务应用程序中，它可能不是访问管理的最佳方法。

#### RBAC vs. PBAC

基于策略的访问控制（PBAC）是另一种侧重于授权的访问管理策略。RBAC基于静态角色限制用户访问，而PBAC基于规则和策略动态确定访问权限。尽管PBAC与ABAC非常相似，但随着所需属性数量的增加，ABAC需要更多的IT和开发资源（例如XML编码）。

PBAC的一些关键好处包括：

- 细粒度或粗粒度的灵活性。
- 能够快速添加、删除或修改权限。
- 环境和上下文控制（例如，有时间或位置限制的访问）。
- 了解身份和资源之间的关系。

这些好处可能会使访问控制更加灵活，尤其是在组织不断发展和变化的情况下。但每个门禁系统都需要一定的管理和周到的实施。

#### RBAC & IAM

IAM是一个政策、流程和技术框架，使企业能够管理数字身份并控制用户对关键企业信息的访问。通过为用户分配特定角色，并确保他们有权访问公司资源和网络，IAM提高了安全性和用户体验，实现了更好的业务成果，并提高了移动和远程工作以及云应用的可行性。

IAM平台的核心目标是为每个个人或设备分配一个数字身份。从这里开始，解决方案在每个用户的访问生命周期中维护、修改和监控访问级别和权限。

IAM系统的核心职责是：

- 根据个人角色和背景信息（如地理位置、时间或（受信任的）网络）验证和认证个人
- 捕获并记录用户登录事件
- 管理并授予企业用户身份数据库的可见性
- 管理用户访问权限的分配和删除
- 使系统管理员能够在监视用户权限更改的同时管理和限制用户访问

IAM框架不仅对控制用户对关键信息的访问至关重要，而且对实现基于角色的访问控制也至关重要。这使系统管理员能够根据单个用户的角色来管理对公司网络或系统的访问，这些角色由其职务、权限级别和企业内部的责任来定义。

### Go 每日一库之 casbin

#### 简介

权限管理在几乎每个系统中都是必备的模块。如果项目开发每次都要实现一次权限管理，无疑会浪费开发时间，增加开发成本。因此，`casbin`库出现了。`casbin`是一个强大、高效的访问控制库。支持常用的多种访问控制模型，如`ACL/RBAC/ABAC`等。可以实现灵活的访问权限控制。同时，`casbin`支持多种编程语言，`Go/Java/Node/PHP/Python/.NET/Rust`。我们只需要**一次学习，多处运用**。

#### 快速使用

我们依然使用 Go Module 编写代码，先初始化：

```Plaintext
复制代码$ mkdir casbin && cd casbin
$ go mod init github.com/darjun/go-daily-lib/casbin
```

然后安装`casbin`，目前是`v2`版本：

```Plaintext
复制代码$ go get github.com/casbin/casbin/v2
```

权限实际上就是控制**谁**能对**什么资源**进行什么操作。`casbin`将访问控制模型抽象到一个基于 PERM（Policy，Effect，Request，Matchers） 元模型的配置文件（模型文件）中。因此切换或更新授权机制只需要简单地修改配置文件。

`policy`是策略或者说是规则的定义。它定义了具体的规则。

`request`是对访问请求的抽象，它与`e.Enforce()`函数的参数是一一对应的

`matcher`匹配器会将请求与定义的每个`policy`一一匹配，生成多个匹配结果。

`effect`根据对请求运用匹配器得出的所有结果进行汇总，来决定该请求是**允许**还是**拒绝**。

下面这张图很好地描绘了这个过程：

![202407092235673](https://raw.githubusercontent.com/lanyoumeng/Drawing-bed/main/docs/202407111913825.webp)

我们首先编写模型文件：

```Plaintext
[request_definition]
r = sub, obj, act

[policy_definition]
p = sub, obj, act

[matchers]
m = r.sub == p.sub && r.obj == p.obj && r.act == p.act

[policy_effect]
e = some(where (p.eft == allow))//这里空格必须有，不然不生效
```

上面模型文件规定了权限由`sub,obj,act`三要素组成，只有在策略列表中有和它完全相同的策略时，该请求才能通过。匹配器的结果可以通过`p.eft`获取，`some(where (p.eft == allow))`表示只要有一条策略允许即可。

然后我们策略文件（即谁能对什么资源进行什么操作）：

```Plaintext
复制代码p, dajun, data1, read
p, lizi, data2, write
```

上面`policy.csv`文件的两行内容表示`dajun`对数据`data1`有`read`权限，`lizi`对数据`data2`有`write`权限。

接下来就是使用的代码：

```Plaintext
复制代码package main

import (
  "fmt"
  "log"

  "github.com/casbin/casbin/v2"
)

func check(e *casbin.Enforcer, sub, obj, act string) {
  ok, _ := e.Enforce(sub, obj, act)
  if ok {
    fmt.Printf("%s CAN %s %s\n", sub, act, obj)
  } else {
    fmt.Printf("%s CANNOT %s %s\n", sub, act, obj)
  }
}

func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "dajun", "data1", "read")
  check(e, "lizi", "data2", "write")
  check(e, "dajun", "data1", "write")
  check(e, "dajun", "data2", "read")
}
```

代码其实不复杂。首先创建一个`casbin.Enforcer`对象，加载模型文件`model.conf`和策略文件`policy.csv`，调用其`Enforce`方法来检查权限。运行程序：

```Plaintext
复制代码$ go run main.go
dajun CAN read data1
lizi CAN write data2
dajun CANNOT write data1
dajun CANNOT read data2
```

请求必须完全匹配某条策略才能通过。`("dajun", "data1", "read")`匹配`p, dajun, data1, read`，`("lizi", "data2", "write")`匹配`p, lizi, data2, write`，所以前两个检查通过。第 3 个因为`"dajun"`没有对`data1`的`write`权限，第 4 个因为`dajun`对`data2`没有`read`权限，所以检查都不能通过。输出结果符合预期。

`sub/obj/act`依次对应传给`Enforce`方法的三个参数。实际上这里的`sub/obj/act`和`read/write/data1/data2`是我自己随便取的，你完全可以使用其它的名字，只要能前后一致即可。

上面例子中实现的就是`ACL`（access-control-list，访问控制列表）。`ACL`显示定义了每个主体对每个资源的权限情况，未定义的就没有权限。我们还可以加上超级管理员，超级管理员可以进行任何操作。假设超级管理员为`root`，我们只需要修改匹配器：

```Plaintext
复制代码[matchers]
e = r.sub == p.sub && r.obj == p.obj && r.act == p.act || r.sub == "root"
```

只要访问主体是`root`一律放行。

验证：

```Plaintext
复制代码func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "root", "data1", "read")
  check(e, "root", "data2", "write")
  check(e, "root", "data1", "execute")
  check(e, "root", "data3", "rwx")
}
```

因为`sub = "root"`时，匹配器一定能通过，运行结果：

```Plaintext
复制代码$ go run main.go
root CAN read data1
root CAN write data2
root CAN execute data1
root CAN rwx data3
```

#### RBAC 模型

`ACL`模型在用户和资源都比较少的情况下没什么问题，但是用户和资源量一大，`ACL`就会变得异常繁琐。想象一下，每次新增一个用户，都要把他需要的权限重新设置一遍是多么地痛苦。`RBAC`（role-based-access-control）模型通过引入角色（`role`）这个中间层来解决这个问题。每个用户都属于一个角色，例如开发者、管理员、运维等，每个角色都有其特定的权限，权限的增加和删除都通过角色来进行。这样新增一个用户时，我们只需要给他指派一个角色，他就能拥有该角色的所有权限。修改角色的权限时，属于这个角色的用户权限就会相应的修改。

在`casbin`中使用`RBAC`模型需要在模型文件中添加`role_definition`模块：

```Plaintext
复制代码[role_definition]
g = _, _

[matchers]
m = g(r.sub, p.sub) && r.obj == p.obj && r.act == p.act
```

`g = _,_`定义了用户——角色，角色——角色的映射关系，前者是后者的成员，拥有后者的权限。然后在匹配器中，我们不需要判断`r.sub`与`p.sub`完全相等，只需要使用`g(r.sub, p.sub)`来判断请求主体`r.sub`是否属于`p.sub`这个角色即可。最后我们修改策略文件添加用户——角色定义：

```Plaintext
复制代码p, admin, data, read
p, admin, data, write
p, developer, data, read
g, dajun, admin
g, lizi, developer
```

上面的`policy.csv`文件规定了，`dajun`属于`admin`管理员，`lizi`属于`developer`开发者，使用`g`来定义这层关系。另外`admin`对数据`data`用`read`和`write`权限，而`developer`对数据`data`只有`read`权限。

```Plaintext
复制代码package main

import (
  "fmt"
  "log"

  "github.com/casbin/casbin/v2"
)

func check(e *casbin.Enforcer, sub, obj, act string) {
  ok, _ := e.Enforce(sub, obj, act)
  if ok {
    fmt.Printf("%s CAN %s %s\n", sub, act, obj)
  } else {
    fmt.Printf("%s CANNOT %s %s\n", sub, act, obj)
  }
}

func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "dajun", "data", "read")
  check(e, "dajun", "data", "write")
  check(e, "lizi", "data", "read")
  check(e, "lizi", "data", "write")
}
```

很显然`lizi`所属角色没有`write`权限：

```Plaintext
复制代码dajun CAN read data
dajun CAN write data
lizi CAN read data
lizi CANNOT write data
```

##### 多个`RBAC`

`casbin`支持同时存在多个`RBAC`系统，即用户和资源都有角色：

```Plaintext
复制代码[role_definition]
g=_,_
g2=_,_

[matchers]
m = g(r.sub, p.sub) && g2(r.obj, p.obj) && r.act == p.act
```

上面的模型文件定义了两个`RBAC`系统`g`和`g2`，我们在匹配器中使用`g(r.sub, p.sub)`判断请求主体属于特定组，`g2(r.obj, p.obj)`判断请求资源属于特定组，且操作一致即可放行。

策略文件:

```Plaintext
复制代码p, admin, prod, read
p, admin, prod, write
p, admin, dev, read
p, admin, dev, write
p, developer, dev, read
p, developer, dev, write
p, developer, prod, read
g, dajun, admin
g, lizi, developer
g2, prod.data, prod
g2, dev.data, dev
```

先看角色关系，即最后 4 行，`dajun`属于`admin`角色，`lizi`属于`developer`角色，`prod.data`属于生产资源`prod`角色，`dev.data`属于开发资源`dev`角色。`admin`角色拥有对`prod`和`dev`类资源的读写权限，`developer`只能拥有对`dev`的读写权限和`prod`的读权限。

```Plaintext
复制代码check(e, "dajun", "prod.data", "read")
check(e, "dajun", "prod.data", "write")
check(e, "lizi", "dev.data", "read")
check(e, "lizi", "dev.data", "write")
check(e, "lizi", "prod.data", "write")
```

第一个函数中`e.Enforce()`方法在实际执行的时候先获取`dajun`所属角色`admin`，再获取`prod.data`所属角色`prod`，根据文件中第一行`p, admin, prod, read`允许请求。最后一个函数中`lizi`属于角色`developer`，而`prod.data`属于角色`prod`，所有策略都不允许，故该请求被拒绝：

```Plaintext
复制代码dajun CAN read prod.data
dajun CAN write prod.data
lizi CAN read dev.data
lizi CAN write dev.data
lizi CANNOT write prod.data
```

##### 多层角色

`casbin`还能为角色定义所属角色，从而实现多层角色关系，这种权限关系是可以传递的。例如`dajun`属于高级开发者`senior`，`seinor`属于开发者，那么`dajun`也属于开发者，拥有开发者的所有权限。我们可以定义开发者共有的权限，然后额外为`senior`定义一些特殊的权限。

模型文件不用修改，策略文件改动如下：

```Plaintext
复制代码p, senior, data, write
p, developer, data, read
g, dajun, senior
g, senior, developer
g, lizi, developer
```

上面`policy.csv`文件定义了高级开发者`senior`对数据`data`有`write`权限，普通开发者`developer`对数据只有`read`权限。同时`senior`也是`developer`，所以`senior`也继承其`read`权限。`dajun`属于`senior`，所以`dajun`对`data`有`read`和`write`权限，而`lizi`只属于`developer`，对数据`data`只有`read`权限。

```Plaintext
复制代码check(e, "dajun", "data", "read")
check(e, "dajun", "data", "write")
check(e, "lizi", "data", "read")
check(e, "lizi", "data", "write")
```

##### `RBAC` domain

在`casbin`中，角色可以是全局的，也可以是特定`domain`（领域）或`tenant`（租户），可以简单理解为**组**。例如`dajun`在组`tenant1`中是管理员，拥有比较高的权限，在`tenant2`可能只是个弟弟。

使用`RBAC domain`需要对模型文件做以下修改：

```Plaintext
复制代码[request_definition]
r = sub, dom, obj, act

[policy_definition]
p = sub, dom, obj, act

[role_definition]
g = _,_,_

[matchers]
m = g(r.sub, p.sub, r.dom) && r.dom == p.dom && r.obj == p.obj && r.act == p.obj
```

`g=_,_,_`表示前者在后者中拥有中间定义的角色，在匹配器中使用`g`要带上`dom`。

```Plaintext
复制代码p, admin, tenant1, data1, read
p, admin, tenant2, data2, read
g, dajun, admin, tenant1
g, dajun, developer, tenant2
```

在`tenant1`中，只有`admin`可以读取数据`data1`。在`tenant2`中，只有`admin`可以读取数据`data2`。`dajun`在`tenant1`中是`admin`，但是在`tenant2`中不是。

```Plaintext
复制代码func check(e *casbin.Enforcer, sub, domain, obj, act string) {
  ok, _ := e.Enforce(sub, domain, obj, act)
  if ok {
    fmt.Printf("%s CAN %s %s in %s\n", sub, act, obj, domain)
  } else {
    fmt.Printf("%s CANNOT %s %s in %s\n", sub, act, obj, domain)
  }
}

func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "dajun", "tenant1", "data1", "read")
  check(e, "dajun", "tenant2", "data2", "read")
}
```

结果不出意料：

```Plaintext
复制代码dajun CAN read data1 in tenant1
dajun CANNOT read data2 in tenant2
```

#### ABAC

`RBAC`模型对于实现比较规则的、相对静态的权限管理非常有用。但是对于特殊的、动态的需求，`RBAC`就显得有点力不从心了。例如，我们在不同的时间段对数据`data`实现不同的权限控制。正常工作时间`9:00-18:00`所有人都可以读写`data`，其他时间只有数据所有者能读写。这种需求我们可以很方便地使用`ABAC`（attribute base access list）模型完成：

```Plaintext
复制代码[request_definition]
r = sub, obj, act

[policy_definition]
p = sub, obj, act

[matchers]
m = r.sub.Hour >= 9 && r.sub.Hour < 18 || r.sub.Name == r.obj.Owner

[policy_effect]
e = some(where (p.eft == allow))
```

该规则不需要策略文件：

```Plaintext
复制代码type Object struct {
  Name  string
  Owner string
}

type Subject struct {
  Name string
  Hour int
}

func check(e *casbin.Enforcer, sub Subject, obj Object, act string) {
  ok, _ := e.Enforce(sub, obj, act)
  if ok {
    fmt.Printf("%s CAN %s %s at %d:00\n", sub.Name, act, obj.Name, sub.Hour)
  } else {
    fmt.Printf("%s CANNOT %s %s at %d:00\n", sub.Name, act, obj.Name, sub.Hour)
  }
}

func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  o := Object{"data", "dajun"}
  s1 := Subject{"dajun", 10}
  check(e, s1, o, "read")

  s2 := Subject{"lizi", 10}
  check(e, s2, o, "read")

  s3 := Subject{"dajun", 20}
  check(e, s3, o, "read")

  s4 := Subject{"lizi", 20}
  check(e, s4, o, "read")
}
```

显然`lizi`在`20:00`不能`read`数据`data`：

```Plaintext
复制代码dajun CAN read data at 10:00
lizi CAN read data at 10:00
dajun CAN read data at 20:00
lizi CANNOT read data at 20:00
```

我们知道，在`model.conf`文件中可以通过`r.sub`和`r.obj`，`r.act`来访问传给`Enforce`方法的参数。实际上`sub/obj`可以是结构体对象，得益于`govaluate`库的强大功能，我们可以在`model.conf`文件中获取这些结构体的字段值。如上面的`r.sub.Name`、`r.Obj.Owner`等。`govaluate`库的内容可以参见我之前的一篇文章[《Go 每日一库之 govaluate》](https://link.juejin.cn/?target=https%3A%2F%2Fdarjun.github.io%2F2020%2F04%2F01%2Fgodailylib%2Fgovaluate%2F)。

使用`ABAC`模型可以非常灵活的权限控制，但是一般情况下`RBAC`就已经够用了。

#### 模型存储

上面代码中，我们一直将模型存储在文件中。`casbin`也可以实现在代码中动态初始化模型，例如`get-started`的例子可以改写为：

```Go
func main() {
  m := model.NewModel()
  m.AddDef("r", "r", "sub, obj, act")
  m.AddDef("p", "p", "sub, obj, act")
  m.AddDef("e", "e", "some(where (p.eft == allow))")//e=some(where (p.eft == allow))
  m.AddDef("m", "m", "r.sub == g.sub && r.obj == p.obj && r.act == p.act")

  a := fileadapter.NewAdapter("./policy.csv")
  e, err := casbin.NewEnforcer(m, a)
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "dajun", "data1", "read")
  check(e, "lizi", "data2", "write")
  check(e, "dajun", "data1", "write")
  check(e, "dajun", "data2", "read")
}
```

同样地，我们也可以从字符串中加载模型：

```Plaintext
复制代码func main() {
  text := `
  [request_definition]
  r = sub, obj, act
  
  [policy_definition]
  p = sub, obj, act
  
  [policy_effect]
  e = some(where (p.eft == allow))
  
  [matchers]
  m = r.sub == p.sub && r.obj == p.obj && r.act == p.act
  `

  m, _ := model.NewModelFromString(text)
  a := fileadapter.NewAdapter("./policy.csv")
  e, _ := casbin.NewEnforcer(m, a)

  check(e, "dajun", "data1", "read")
  check(e, "lizi", "data2", "write")
  check(e, "dajun", "data1", "write")
  check(e, "dajun", "data2", "read")
}
```

但是这两种方式并不推荐。

#### 策略存储

在前面的例子中，我们都是将策略存储在`policy.csv`文件中。一般在实际应用中，很少使用文件存储。`casbin`以第三方适配器的方式支持多种存储方式包括`MySQL/MongoDB/Redis/Etcd`等，还可以实现自己的存储。完整列表看这里[casbin.org/docs/en/ada…](https://link.juejin.cn/?target=https%3A%2F%2Fcasbin.org%2Fdocs%2Fen%2Fadapters)。下面我们介绍使用`Gorm Adapter`。先连接到数据库，执行下面的`SQL`：

```Plaintext
复制代码CREATE DATABASE IF NOT EXISTS casbin;

USE casbin;

CREATE TABLE IF NOT EXISTS casbin_rule (
  p_type VARCHAR(100) NOT NULL,
  v0 VARCHAR(100),
  v1 VARCHAR(100),
  v2 VARCHAR(100),
  v3 VARCHAR(100),
  v4 VARCHAR(100),
  v5 VARCHAR(100)
);

INSERT INTO casbin_rule VALUES
('p', 'dajun', 'data1', 'read', '', '', ''),
('p', 'lizi', 'data2', 'write', '', '', '');
```

然后使用`Gorm Adapter`加载`policy`，`Gorm Adapter`默认使用`casbin`库中的`casbin_rule`表：

```Plaintext
复制代码package main

import (
  "fmt"

  "github.com/casbin/casbin/v2"
  gormadapter "github.com/casbin/gorm-adapter/v2"
  _ "github.com/go-sql-driver/mysql"
)

func check(e *casbin.Enforcer, sub, obj, act string) {
  ok, _ := e.Enforce(sub, obj, act)
  if ok {
    fmt.Printf("%s CAN %s %s\n", sub, act, obj)
  } else {
    fmt.Printf("%s CANNOT %s %s\n", sub, act, obj)
  }
}

func main() {
  a, _ := gormadapter.NewAdapter("mysql", "root:12345@tcp(127.0.0.1:3306)/")
  e, _ := casbin.NewEnforcer("./model.conf", a)

  check(e, "dajun", "data1", "read")
  check(e, "lizi", "data2", "write")
  check(e, "dajun", "data1", "write")
  check(e, "dajun", "data2", "read")
}
```

运行：

```Plaintext
dajun CAN read data1
lizi CAN write data2
dajun CANNOT write data1
dajun CANNOT read data2
```

#### 使用函数

我们可以在匹配器中使用函数。`casbin`内置了一些函数`keyMatch/keyMatch2/keyMatch3/keyMatch4`都是匹配 URL 路径的，`regexMatch`使用正则匹配，`ipMatch`匹配 IP 地址。参见[casbin.org/docs/en/fun…](https://link.juejin.cn/?target=https%3A%2F%2Fcasbin.org%2Fdocs%2Fen%2Ffunction)。使用内置函数我们能很容易对路由进行权限划分：

```Plaintext
复制代码[matchers]
m = r.sub == p.sub && keyMatch(r.obj, p.obj) && r.act == p.act
复制代码p, dajun, user/dajun/*, read
p, lizi, user/lizi/*, read
```

不同用户只能访问其对应路由下的 URL：

```Plaintext
复制代码func main() {
  e, err := casbin.NewEnforcer("./model.conf", "./policy.csv")
  if err != nil {
    log.Fatalf("NewEnforecer failed:%v\n", err)
  }

  check(e, "dajun", "user/dajun/1", "read")
  check(e, "lizi", "user/lizi/2", "read")
  check(e, "dajun", "user/lizi/1", "read")
}
```

输出：

```Plaintext
复制代码dajun CAN read user/dajun/1
lizi CAN read user/lizi/2
dajun CANNOT read user/lizi/1
```

我们当然也可以定义自己的函数。先定义一个函数，返回 bool：

```Plaintext
复制代码func KeyMatch(key1, key2 string) bool {
  i := strings.Index(key2, "*")
  if i == -1 {
    return key1 == key2
  }

  if len(key1) > i {
    return key1[:i] == key2[:i]
  }

  return key1 == key2[:i]
}
```

这里实现了一个简单的正则匹配，只处理`*`。

然后将这个函数用`interface{}`类型包装一层：

```Plaintext
复制代码func KeyMatchFunc(args ...interface{}) (interface{}, error) {
  name1 := args[0].(string)
  name2 := args[1].(string)

  return (bool)(KeyMatch(name1, name2)), nil
}
```

然后添加到权限认证器中：

```Plaintext
复制代码e.AddFunction("my_func", KeyMatchFunc)
```

这样我们就可以在匹配器中使用该函数实现正则匹配了：

```Plaintext
复制代码[matchers]
m = r.sub == p.sub && my_func(r.obj, p.obj) && r.act == p.act
```

接下来我们在策略文件中为`dajun`赋予权限：

```Plaintext
复制代码p, dajun, data/*, read
```

`dajun`对匹配模式`data/*`的文件都有`read`权限。

验证一下：

```Plaintext
复制代码check(e, "dajun", "data/1", "read")
check(e, "dajun", "data/2", "read")
check(e, "dajun", "data/1", "write")
check(e, "dajun", "mydata", "read")
```

`dajun`对`data/1`没有`write`权限，`mydata`不符合`data/*`模式，也没有`read`权限：

```Plaintext
复制代码dajun CAN read data/1
dajun CAN read data/2
dajun CANNOT write data/1
dajun CANNOT read mydata
```

#### 参考

1. casbin GitHub：[github.com/casbin/casb…](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fcasbin%2Fcasbin)
2. casbin 官网：[casbin.org/](https://link.juejin.cn?target=https%3A%2F%2Fcasbin.org%2F)
3. 一种基于元模型的访问控制策略描述语言：[www.jos.org.cn/html/2020/2…](https://link.juejin.cn?target=http%3A%2F%2Fwww.jos.org.cn%2Fhtml%2F2020%2F2%2F5624.htm)
4. Go 每日一库 GitHub：[github.com/darjun/go-d…](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fdarjun%2Fgo-daily-lib)

### go使用

"Gorm Adapter" 通常是指用于将 Casbin（访问控制框架）与 Gorm（Go编程语言中的对象关系映射库）集成的适配器。这种适配器允许 Casbin 使用 Gorm 连接到数据库，以存储和检索策略数据。Gorm Adapter 提供了一种将 Casbin 与数据库进行交互的方式，使你可以在应用程序中使用 Gorm 来管理 Casbin 的访问控制策略。

以下是使用 Gorm Adapter 的一些步骤：

1. **安装 Gorm 和 Casbin**： 在 Go 项目中，首先确保已安装 Gorm 和 Casbin 库。你可以使用以下命令安装它们：

```Shell
go get -u github.com/jinzhu/gorm
go get -u github.com/casbin/casbin/v2
```

1. **创建 Casbin Model 文件**： 创建 Casbin 模型文件（通常以 .conf 文件扩展名结束），该文件定义了策略的结构和规则。
2. **创建 Gorm 数据库连接**： 在你的应用程序中，使用 Gorm 创建数据库连接，并建立数据库表以存储 Casbin 的策略数据。
3. **初始化 Casbin Enforcer**： 创建 Casbin Enforcer 实例并指定 Gorm 数据库连接。然而在多线程或多协程的环境中，对访问控制策略进行修改或更新可能会引发并发问题。
4. `SyncedEnforcer` 的目的是确保 Casbin 在多线程环境中的安全性，允许多个线程同时进行访问控制检查和策略更新，而不会导致数据不一致或竞争条件。

```Go
import (
    "github.com/casbin/casbin/v2"
    "github.com/casbin/gorm-adapter/v3"
)

// 创建 Gorm 数据库连接
db, err := gorm.Open("mysql", "user:password@tcp(localhost:3306)/database")

// 初始化 Gorm Adapter
adapter, err := gormadapter.NewAdapter(db)

// 初始化 Casbin Enforcer 使用 Gorm Adapter
//1.e, err := casbin.NewEnforcer("casbin_model.conf", adapter)
  2.enforcer, err := casbin.NewSyncedEnforcer(m, adapter)
```

1. **使用 Casbin 进行访问控制**： 使用 Casbin Enforcer 对用户、角色和资源执行访问控制操作，例如检查用户是否有权限执行特定操作。
2. **执行访问控制操作**：
3. 现在，你可以使用 Casbin Enforcer 来执行访问控制操作。以下是一些常见的操作示例：
   1. **检查权限**：判断某个主体是否有权限执行某个操作。
   2. ```Go
      codeallowed, err := e.Enforce("user123", "data1", "read")
      if err != nil {
          // 处理错误
      }
      if allowed {
          // 允许访问
      } else {
          // 拒绝访问
      }
      ```

   3. **添加策略规则**：将访问控制规则（策略）添加到策略存储中。
   4. ```Go
      e.AddPolicy("admin", "data1", "write")
      //创建用户时
      ```

   5. **删除策略规则**：从策略存储中删除访问控制规则。
   6. ```Go
      e.RemovePolicy("admin", "data1", "write")
      //删除用户时
      ```

   7. **获取策略规则**：获取匹配给定条件的策略规则。
   8. ```Go
      policies := e.GetFilteredPolicy(0, "data1", "read")
      ```

## 服务运行

### 后台运行

要使这个项目在后台一直运行，你可以使用操作系统提供的一些工具或技巧来实现。以下是一些常见的方法，可以根据你的需求选择其中之一：

1. 使用 nohup 命令：
2. 在终端中运行以下命令来启动你的项目，并使其在后台一直运行：

```Plaintext
nohup go run main.go(实际) > output.log 2>&1 &
disown
```

1. 这会将项目的输出保存到名为 `output.log` 的文件中，并且项目将在后台运行。你可以使用 `ps` 命令来查看项目的进程号，并使用 `kill` 命令来停止它。
2. 使用 systemd（适用于 Linux）：
3. 创建一个 systemd 服务单元文件，以便管理你的 Go 项目。首先，在 `/etc/systemd/system/` 目录下创建一个 `.service` 文件，例如 `myproject.service`，并在文件中定义你的服务：

```Plaintext
[Unit]
Description=My Go Project

[Service]
ExecStart=/path/to/your/go/executable /path/to/main.go
WorkingDirectory=/path/to/your/project
Restart=always

[Install]
WantedBy=multi-user.target
```

1. 保存并关闭文件后，运行以下命令来启动你的服务：

```Plaintext
sudo systemctl start myproject
```

1. 这将启动你的 Go 项目，并且它将在后台一直运行。你可以使用 `systemctl` 命令来控制服务的启动、停止和重启。
   1. 停止服务：
   2. ```Plaintext
      arduinoCopy code
      sudo systemctl stop myproject
      ```

   3. 重启服务：
   4. ```Plaintext
      Copy code
      sudo systemctl restart myproject
      ```

   5. 查看服务状态：
   6. ```Plaintext
      luaCopy code
      sudo systemctl status myproject
      ```

   7. 启用自启动：
   8. 如果你希望系统启动时自动启动你的服务，可以运行以下命令：
   9. ```Plaintext
      bashCopy code
      sudo systemctl enable myproject
      ```
2. 这样，你的 Go 项目将在系统启动时自动启动。
3. 使用 nohup + systemd 组合：
4. 你还可以将 `nohup` 和 `systemd` 结合使用，以便更好地管理你的项目。你可以使用 `nohup` 来启动项目，然后将 `nohup` 的进程包装成一个 systemd 服务。
5. 这些方法中的任何一个都可以使你的项目在后台一直运行。选择其中一个取决于你的需求和操作系统。

### 停止8080

要查看在 Linux 上运行的监听端口 8080 的应用程序，你可以使用一些命令来检查正在使用该端口的进程。以下是一些可能有助于你的命令：

1. **使用** **`netstat`** **命令：**
2. 使用 `netstat` 命令可以列出当前正在运行的网络连接和监听端口。要查找监听端口 8080 的应用程序，运行以下命令：

```Bash
netstat -tuln | grep 8080
```

1. 这将列出所有正在监听端口 8080 的进程。
2. **使用** **`ss`** **命令：**
3. `ss` 命令类似于 `netstat`，可以用来查看网络连接和监听端口。要查找监听端口 8080 的应用程序，运行以下命令：

```Bash
ss -tuln | grep 8080
```

1. 这将列出所有正在监听端口 8080 的进程。
2. **使用** **`lsof`** **命令：**
3. `lsof` 命令可以列出打开的文件和进程信息，包括网络连接。要查找监听端口 8080 的应用程序，运行以下命令：

```Bash
sudo lsof -i :8080
```

1. 这将列出所有使用端口 8080 的进程和相关信息。你可能需要使用 `sudo` 权限来查看所有进程。
2. **使用** **`ps`** **命令：**
3. 你还可以使用 `ps` 命令来查找特定端口的进程。假设你想查找端口 8080 的进程，你可以运行以下命令：

```Bash
ps aux | grep 8080
```

1. 这将列出包含 8080 关键字的进程，你可以查看相关信息以确定哪个进程在使用该端口。

一旦你找到了使用端口 8080 的进程，你可以进一步查看有关该进程的详细信息，以确定是哪个应用程序在监听该端口。如果需要停止或管理该应用程序，你可以使用先前提到的 `kill` 命令。

### 停止miniblog

要关闭这个程序，您可以使用 `systemctl` 命令来停止和禁用 `miniblog` 服务。以下是一些常用的 `systemctl` 命令：

1. 停止 `miniblog` 服务：

```Plaintext
sudo systemctl stop miniblog
```

1. 这会停止当前正在运行的 `miniblog` 服务。
2. 启动 `miniblog` 服务：

```Plaintext
sudo systemctl start miniblog
```

1. 这会启动 `miniblog` 服务，如果它当前没有运行。
2. 重启 `miniblog` 服务：

```Plaintext
sudo systemctl restart miniblog
```

1. 这会先停止当前运行的 `miniblog` 服务，然后再启动它。
2. 查看 `miniblog` 服务状态：

```Plaintext
sudo systemctl status miniblog
```

1. 这会显示 `miniblog` 服务的运行状态，包括是否正在运行以及相关的进程信息。
2. 禁用 `miniblog` 服务开机启动：

```Plaintext
sudo systemctl disable miniblog
```

1. 这会禁用 `miniblog` 服务在系统开机时自动启动。

请根据您的需求使用适当的命令来管理 `miniblog` 服务。如果您想停止 `miniblog` 并阻止它在开机时自动启动，可以依次执行以下命令：

```Bash
sudo systemctl stop miniblog
sudo systemctl disable miniblog
```

这样就可以停止并禁用 `miniblog` 服务。

## 项目注意

### 用户名和昵称

是两个不同的概念，尤其在网络和社交媒体的上下文中有着不同的含义：

1. **用户名（Username）：** 用户名通常是一个唯一的标识符，用于识别用户的身份。它通常用于登录网站、应用程序或在线平台，并用于创建个人账户。用户名通常是独一无二的，以确保每个用户都有一个唯一的标识符。用户名通常是字符、数字和符号的组合，通常不包含空格。例如，您在社交媒体、电子邮件、网上银行或在线游戏中使用的用户名。
2. **昵称（Nickname）：** 昵称是一个用户自行选择的名称，用于表示他们的身份，但不一定是唯一的。昵称通常更加个性化，可以反映用户的兴趣、性格或其他特征。昵称可以包含空格，也可以更自由地选择。在社交媒体或聊天应用程序中，人们通常使用昵称来互相称呼，而不一定使用他们的真实姓名或用户名。

总的来说，用户名通常用于唯一标识用户，并用于登录和账户管理，而昵称是用户自己选择的、更个性化的称呼，通常用于社交交流和展示个性。在某些情况下，人们可能使用相同的用户名和昵称，但这两者的含义和用途是不同的。
